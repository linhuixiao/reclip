(pytorch_clip) lhxiao@pcl-SYS-4028GR-TR:~/pcl_experiment_202203/reclip$ python main.py --input_file /hdd/lhxiao/reclip/reclip_data/refcocog_test.jsonl --image_root /hdd/lhxiao/ref_dataset/coco_image/train2014 --method parse --gradcam_alpha 0.5 0.5 --box_method_aggregator sum
Square size!
Square size!
  0%|                                                                                                                                                                                                                              | 0/5023 [00:00<?, ?it/s]This is the original CLIP result:
tensor([ 76.0000, 100.5000,  83.8750,  91.8750, 109.6250,  78.7500],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.4934503e-15 1.0889691e-04 6.5594852e-12 1.9553550e-08 9.9989104e-01
 3.9004126e-14]
predicts:  4
The Final Result:  {'probs': array([2.4934503e-15, 1.0889691e-04, 6.5594852e-12, 1.9553550e-08,
       9.9989104e-01, 3.9004126e-14], dtype=float32), 'pred': 4, 'box': Box(x=416.16, y=95.57, w=66.98, h=58.28), 'texts': ['the man in yellow coat']}
the man in yellow coat
This is the original CLIP result:
tensor([117.7500, 130.5000, 100.5625, 116.2500, 104.1250,  82.6250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.9023104e-06 9.9999654e-01 9.9611027e-14 6.4759297e-07 3.5114099e-12
 1.6149169e-21]
predicts:  1
The Final Result:  {'probs': array([2.9023104e-06, 9.9999654e-01, 9.9611027e-14, 6.4759297e-07,
       3.5114099e-12, 1.6149169e-21], dtype=float32), 'pred': 1, 'box': Box(x=374.31, y=65.06, w=136.04, h=201.94), 'texts': ['skiier in red pants.']}
skiier in red pants.
predicate correct
  0%|                                                                                                                                                                                                                      | 1/5023 [00:00<46:15,  1.81it/s]This is the original CLIP result:
tensor([109.8125, 100.4375,  93.7500,  89.0625], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [9.99915004e-01 8.48110212e-05 1.05708025e-07 9.73537362e-10]
predicts:  0
The Final Result:  {'probs': array([9.99915004e-01, 8.48110212e-05, 1.05708025e-07, 9.73537362e-10],
      dtype=float32), 'pred': 0, 'box': Box(x=93.95, y=83.29, w=504.61, h=290.57), 'texts': ['there is red colored truck in between the other trucks']}
there is red colored truck in between the other trucks
predicate correct
This is the original CLIP result:
tensor([136.5000,  95.2500,  90.0000,  83.8125], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.0000000e+00 1.2171738e-18 6.3871421e-21 1.3125307e-23]
predicts:  0
The Final Result:  {'probs': array([1.0000000e+00, 1.2171738e-18, 6.3871421e-21, 1.3125307e-23],
      dtype=float32), 'pred': 0, 'box': Box(x=93.95, y=83.29, w=504.61, h=290.57), 'texts': ['a shiny red vintage pickup truck']}
a shiny red vintage pickup truck
predicate correct
  0%|                                                                                                                                                                                                                      | 2/5023 [00:00<37:51,  2.21it/s]This is the original CLIP result:
tensor([110.3750, 120.8125, 103.5000, 120.9375, 104.0000, 102.6875,  89.9375,
         95.8750,  97.8750,  93.2500,  89.8750,  90.2500,  90.0625,  89.0625,
         91.8125,  89.3750,  89.5000,  96.2500,  88.6875,  94.8750],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.3741189e-05 4.6878415e-01 1.4198737e-08 5.3120208e-01 2.3409759e-08
 6.3006516e-09 1.8286510e-14 6.9303361e-12 5.1208641e-11 5.0203179e-13
 1.7178587e-14 2.4994695e-14 2.0721330e-14 7.6229509e-15 1.1924301e-13
 1.0419339e-14 1.1806657e-14 1.0083580e-11 5.2391719e-15 2.5495283e-12]
predicts:  3
The Final Result:  {'probs': array([1.3741189e-05, 4.6878415e-01, 1.4198737e-08, 5.3120208e-01,
       2.3409759e-08, 6.3006516e-09, 1.8286510e-14, 6.9303361e-12,
       5.1208641e-11, 5.0203179e-13, 1.7178587e-14, 2.4994695e-14,
       2.0721330e-14, 7.6229509e-15, 1.1924301e-13, 1.0419339e-14,
       1.1806657e-14, 1.0083580e-11, 5.2391719e-15, 2.5495283e-12],
      dtype=float32), 'pred': 3, 'box': Box(x=338.8, y=82.19, w=147.34, h=157.37), 'texts': ['a apple desktop computer']}
a apple desktop computer
predicate correct
This is the original CLIP result:
tensor([110.5625, 118.7500,  94.8750, 125.0625,  93.7500, 100.5625,  84.7500,
         92.3750,  94.3750,  90.6250,  88.2500,  91.3750,  85.5000,  82.7500,
         87.3750,  84.5625,  84.5625,  92.5625,  83.5000,  88.1875],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [5.0343436e-07 1.8102101e-03 7.7436945e-14 9.9818927e-01 2.5140095e-14
 2.2855887e-11 3.1025342e-18 6.3564118e-15 4.6967882e-14 1.1045786e-15
 1.0274183e-16 2.3383931e-15 6.5680651e-18 4.1988233e-19 4.2829165e-17
 2.5720912e-18 2.5720912e-18 7.6672965e-15 8.8889087e-19 9.6517015e-17]
predicts:  3
The Final Result:  {'probs': array([5.0343436e-07, 1.8102101e-03, 7.7436945e-14, 9.9818927e-01,
       2.5140095e-14, 2.2855887e-11, 3.1025342e-18, 6.3564118e-15,
       4.6967882e-14, 1.1045786e-15, 1.0274183e-16, 2.3383931e-15,
       6.5680651e-18, 4.1988233e-19, 4.2829165e-17, 2.5720912e-18,
       2.5720912e-18, 7.6672965e-15, 8.8889087e-19, 9.6517015e-17],
      dtype=float32), 'pred': 3, 'box': Box(x=338.8, y=82.19, w=147.34, h=157.37), 'texts': ['the white imac computer that is also turned on']}
the white imac computer that is also turned on
predicate correct
  0%|▏                                                                                                                                                                                                                   | 3/5023 [00:02<1:21:16,  1.03it/s]This is the original CLIP result:
tensor([ 72.4375, 107.6250,  87.1250,  73.0625,  84.6250,  77.1250,  71.7500,
         75.4375,  77.3750,  86.7500,  70.5000,  80.8750,  74.1250,  71.7500,
         89.4375,  69.1250,  84.0000,  92.2500], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [5.2271240e-16 9.9999976e-01 1.2501524e-09 9.7655530e-16 1.0261877e-10
 5.6756839e-14 2.6283631e-16 1.0498959e-14 7.2877224e-14 8.5921636e-10
 7.5303856e-17 2.4133620e-12 2.8257568e-15 2.6283631e-16 1.2626095e-08
 1.9039797e-17 5.4927871e-11 2.1024333e-07]
predicts:  1
The Final Result:  {'probs': array([5.2271240e-16, 9.9999976e-01, 1.2501524e-09, 9.7655530e-16,
       1.0261877e-10, 5.6756839e-14, 2.6283631e-16, 1.0498959e-14,
       7.2877224e-14, 8.5921636e-10, 7.5303856e-17, 2.4133620e-12,
       2.8257568e-15, 2.6283631e-16, 1.2626095e-08, 1.9039797e-17,
       5.4927871e-11, 2.1024333e-07], dtype=float32), 'pred': 1, 'box': Box(x=45.2, y=166.76, w=147.45, h=179.73), 'texts': ['a girl wearing glasses and a pink shirt']}
a girl wearing glasses and a pink shirt
predicate correct
This is the original CLIP result:
tensor([ 69.6250, 120.0625, 117.4375,  76.3125,  86.2500,  78.7500,  76.2500,
         75.3750,  79.8750,  88.7500,  74.0625,  83.3750,  75.5625,  69.7500,
         94.4375,  94.8125,  93.1875,  87.6250], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.16117902e-22 9.32453275e-01 6.75466955e-02 9.31630001e-20
 1.92772438e-15 1.06619414e-18 8.75185458e-20 3.64831596e-20
 3.28410907e-18 2.34844882e-14 9.81930919e-21 1.08754756e-16
 4.40070910e-20 1.31578806e-22 6.93155949e-12 1.00853605e-11
 1.98592531e-12 7.62429772e-15]
predicts:  1
The Final Result:  {'probs': array([1.16117902e-22, 9.32453275e-01, 6.75466955e-02, 9.31630001e-20,
       1.92772438e-15, 1.06619414e-18, 8.75185458e-20, 3.64831596e-20,
       3.28410907e-18, 2.34844882e-14, 9.81930919e-21, 1.08754756e-16,
       4.40070910e-20, 1.31578806e-22, 6.93155949e-12, 1.00853605e-11,
       1.98592531e-12, 7.62429772e-15], dtype=float32), 'pred': 1, 'box': Box(x=45.2, y=166.76, w=147.45, h=179.73), 'texts': ['an asian girl with a pink shirt eating at the table']}
an asian girl with a pink shirt eating at the table
predicate correct
  0%|▏                                                                                                                                                                                                                   | 4/5023 [00:04<1:38:13,  1.17s/it]This is the original CLIP result:
tensor([ 85.5000,  98.7500, 120.9375,  89.3750,  89.1250,  90.1250,  90.2500,
         90.6875], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [4.0708893e-16 2.3125502e-10 1.0000000e+00 1.9614644e-14 1.5275900e-14
 4.1524198e-14 4.7053083e-14 7.2877244e-14]
predicts:  2
The Final Result:  {'probs': array([4.0708893e-16, 2.3125502e-10, 1.0000000e+00, 1.9614644e-14,
       1.5275900e-14, 4.1524198e-14, 4.7053083e-14, 7.2877244e-14],
      dtype=float32), 'pred': 2, 'box': Box(x=496.24, y=82.81, w=82.8, h=168.71), 'texts': ['woman in coveralls']}
woman in coveralls
predicate correct
This is the original CLIP result:
tensor([ 89.3750, 102.1250, 128.6250,  87.8750,  92.7500,  88.0000,  97.5000,
         94.2500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [8.9937652e-18 3.0988192e-12 1.0000000e+00 2.0067803e-18 2.6283636e-16
 2.2739801e-18 3.0379751e-14 1.1779508e-15]
predicts:  2
The Final Result:  {'probs': array([8.9937652e-18, 3.0988192e-12, 1.0000000e+00, 2.0067803e-18,
       2.6283636e-16, 2.2739801e-18, 3.0379751e-14, 1.1779508e-15],
      dtype=float32), 'pred': 2, 'box': Box(x=496.24, y=82.81, w=82.8, h=168.71), 'texts': ['a person wearing overalls']}
a person wearing overalls
predicate correct
  0%|▏                                                                                                                                                                                                                   | 5/5023 [00:04<1:19:36,  1.05it/s]This is the original CLIP result:
tensor([110.6875, 108.7500,  81.3750,  83.3750], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [8.7407720e-01 1.2592277e-01 1.6266449e-13 1.2019371e-12]
predicts:  0
The Final Result:  {'probs': array([8.7407720e-01, 1.2592277e-01, 1.6266449e-13, 1.2019371e-12],
      dtype=float32), 'pred': 0, 'box': Box(x=375.98, y=196.78, w=61.71, h=178.22), 'texts': ['a man standing next to a young girl on a grassy hillside']}
a man standing next to a young girl on a grassy hillside
predicate correct
This is the original CLIP result:
tensor([99.6250, 80.8750, 78.1875, 79.3750], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.000000e+00 7.194133e-09 4.895669e-10 1.605228e-09]
predicts:  0
The Final Result:  {'probs': array([1.000000e+00, 7.194133e-09, 4.895669e-10, 1.605228e-09],
      dtype=float32), 'pred': 0, 'box': Box(x=375.98, y=196.78, w=61.71, h=178.22), 'texts': ['a man in a black jacket.']}
a man in a black jacket.
predicate correct
  0%|▎                                                                                                                                                                                                                   | 6/5023 [00:04<1:02:44,  1.33it/s]This is the original CLIP result:
tensor([122.9375, 116.2500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.9987551  0.00124484]
predicts:  0
The Final Result:  {'probs': array([0.9987551 , 0.00124484], dtype=float32), 'pred': 0, 'box': Box(x=39.28, y=157.15, w=255.05, h=196.25), 'texts': ['the adult giraffe.']}
the adult giraffe.
predicate correct
This is the original CLIP result:
tensor([119.0000, 109.8750], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9989104e-01 1.0889691e-04]
predicts:  0
The Final Result:  {'probs': array([9.9989104e-01, 1.0889691e-04], dtype=float32), 'pred': 0, 'box': Box(x=39.28, y=157.15, w=255.05, h=196.25), 'texts': ['a mother giraffe lickicking her baby.']}
a mother giraffe lickicking her baby.
predicate correct
  0%|▎                                                                                                                                                                                                                     | 7/5023 [00:05<48:14,  1.73it/s]This is the original CLIP result:
tensor([118.9375, 110.9375, 114.3125,  94.6250,  80.5000,  78.6250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.8996264e-01 3.3209549e-04 9.7052529e-03 2.7342247e-11 2.0064328e-17
 3.0769644e-18]
predicts:  0
The Final Result:  {'probs': array([9.8996264e-01, 3.3209549e-04, 9.7052529e-03, 2.7342247e-11,
       2.0064328e-17, 3.0769644e-18], dtype=float32), 'pred': 0, 'box': Box(x=182.85, y=191.93, w=100.03, h=155.69), 'texts': ['a lady in blue t-shirt and white shorts sitting on a park bench.']}
a lady in blue t-shirt and white shorts sitting on a park bench.
predicate correct
This is the original CLIP result:
tensor([111.1875, 105.9375, 102.5000,  91.3750,  80.1250,  76.8125],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9461305e-01 5.2192500e-03 1.6777251e-04 2.4728324e-09 3.2164870e-14
 1.1716053e-15]
predicts:  0
The Final Result:  {'probs': array([9.9461305e-01, 5.2192500e-03, 1.6777251e-04, 2.4728324e-09,
       3.2164870e-14, 1.1716053e-15], dtype=float32), 'pred': 0, 'box': Box(x=182.85, y=191.93, w=100.03, h=155.69), 'texts': ['a couple of friends are sitting on a bench and hanging out.']}
a couple of friends are sitting on a bench and hanging out.
predicate correct
  0%|▎                                                                                                                                                                                                                     | 8/5023 [00:05<47:58,  1.74it/s]This is the original CLIP result:
tensor([104.2500,  67.8750, 104.5000,  78.2500], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [4.378235e-01 6.979708e-17 5.621765e-01 2.236879e-12]
predicts:  2
The Final Result:  {'probs': array([4.378235e-01, 6.979708e-17, 5.621765e-01, 2.236879e-12],
      dtype=float32), 'pred': 2, 'box': Box(x=39.2, y=334.05, w=114.38, h=239.16), 'texts': ['a blonde woman in a white shirt and long black skirt.']}
a blonde woman in a white shirt and long black skirt.
This is the original CLIP result:
tensor([117.1250, 124.8125,  90.3750,  95.0000], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [4.5831292e-04 9.9954176e-01 1.1060752e-15 1.1282275e-13]
predicts:  1
The Final Result:  {'probs': array([4.5831292e-04, 9.9954176e-01, 1.1060752e-15, 1.1282275e-13],
      dtype=float32), 'pred': 1, 'box': Box(x=129.15, y=1.47, w=318.76, h=440.95), 'texts': ['there is one small girl wearing white top is touching the elephant']}
there is one small girl wearing white top is touching the elephant
  0%|▍                                                                                                                                                                                                                     | 9/5023 [00:06<44:04,  1.90it/s]This is the original CLIP result:
tensor([108.5625, 109.7500], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([117.6250, 112.6250], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([117.6250, 112.6250], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [0.23370634 0.76629364]
parser result:  [1. 0.]
clip * parser result:  [0.23370634 0.        ]
CLIP result after softmax:  [0.23370634 0.        ]
predicts:  0
The Final Result:  {'probs': array([0.23370634, 0.        ]), 'pred': 0, 'box': Box(x=305.65, y=213.04, w=333.63, h=198.03), 'texts': (['the truck covered in the snow furthest', 'sup:right'], [([0.9933071732521057, 0.006692850962281227], [0.9933071732521057, 0.006692850962281227]), ([1.0, 0.0], None)], ('the truck', 'the truck', 'the snow furthest', 'the snow furthest', 'the snow furthest', 'the right', 'the right'))}
the truck covered in the snow furthest to the right.
predicate correct
This is the original CLIP result:
tensor([133.8750, 121.5000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9999583e-01 4.2228335e-06]
predicts:  0
The Final Result:  {'probs': array([9.9999583e-01, 4.2228335e-06], dtype=float32), 'pred': 0, 'box': Box(x=305.65, y=213.04, w=333.63, h=198.03), 'texts': ['an old truck covered in snow except for the grill and door']}
an old truck covered in snow except for the grill and door
predicate correct
  0%|▍                                                                                                                                                                                                                    | 10/5023 [00:06<42:16,  1.98it/s]This is the original CLIP result:
tensor([106.5625,  84.6250,  87.1250,  84.7500, 119.5625], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [2.2603242e-06 6.7117467e-16 8.1765818e-15 7.6054051e-16 9.9999774e-01]
predicts:  4
The Final Result:  {'probs': array([2.2603242e-06, 6.7117467e-16, 8.1765818e-15, 7.6054051e-16,
       9.9999774e-01], dtype=float32), 'pred': 4, 'box': Box(x=392.41, y=187.79, w=184.67, h=213.14), 'texts': ['a brown bear near a soda bottle']}
a brown bear near a soda bottle
predicate correct
This is the original CLIP result:
tensor([ 88.8125, 103.0000,  93.0000, 116.0000, 121.0000], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.0428693e-14 1.5128046e-08 6.8681231e-13 6.6928510e-03 9.9330717e-01]
predicts:  4
The Final Result:  {'probs': array([1.0428693e-14, 1.5128046e-08, 6.8681231e-13, 6.6928510e-03,
       9.9330717e-01], dtype=float32), 'pred': 4, 'box': Box(x=392.41, y=187.79, w=184.67, h=213.14), 'texts': ['a without hairy brown color teddy bear']}
a without hairy brown color teddy bear
predicate correct
  0%|▍                                                                                                                                                                                                                    | 11/5023 [00:07<42:05,  1.98it/s]This is the original CLIP result:
tensor([ 79.8750, 108.5000,  98.6875,  87.1250,  86.8125,  90.5000,  92.6250,
         91.1250,  86.4375,  91.3125,  94.2500,  94.4375, 103.6250,  83.0625,
         97.9375,  97.9375,  96.8750,  85.8750,  87.8125,  85.5000,  89.9375,
         92.7500,  83.3125,  93.1250, 102.9375], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [3.6586023e-13 9.8854113e-01 5.4135249e-05 5.1516957e-10 3.7690609e-10
 1.5055461e-08 1.2605784e-07 2.8127305e-08 2.5904354e-10 3.3928007e-08
 6.4017451e-07 7.7219784e-07 7.5476044e-03 8.8639825e-12 2.5571682e-05
 2.5571682e-05 8.8373363e-06 1.4759856e-10 1.0245370e-09 1.0144290e-10
 8.5783434e-09 1.4284224e-07 1.1381578e-11 2.0783423e-07 3.7951737e-03]
predicts:  1
The Final Result:  {'probs': array([3.6586023e-13, 9.8854113e-01, 5.4135249e-05, 5.1516957e-10,
       3.7690609e-10, 1.5055461e-08, 1.2605784e-07, 2.8127305e-08,
       2.5904354e-10, 3.3928007e-08, 6.4017451e-07, 7.7219784e-07,
       7.5476044e-03, 8.8639825e-12, 2.5571682e-05, 2.5571682e-05,
       8.8373363e-06, 1.4759856e-10, 1.0245370e-09, 1.0144290e-10,
       8.5783434e-09, 1.4284224e-07, 1.1381578e-11, 2.0783423e-07,
       3.7951737e-03], dtype=float32), 'pred': 1, 'box': Box(x=56.13, y=169.4, w=582.37, h=256.6), 'texts': ['a table with pizza, drinks, and seasonings on it']}
a table with pizza, drinks, and seasonings on it
predicate correct
This is the original CLIP result:
tensor([ 66.8750, 120.6250,  87.0625,  85.9375,  87.2500,  97.6250,  77.1250,
         76.7500,  69.8125,  84.1875,  76.0000,  82.5000,  85.6250,  74.8750,
         87.3750,  85.3750,  77.6250,  70.3750,  78.9375,  75.1250,  81.0625,
         87.6250,  68.5625,  79.6875,  90.6875], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [4.53598452e-24 1.00000000e+00 2.65455319e-15 8.61807214e-16
 3.20200244e-15 1.02618795e-10 1.28289186e-19 8.81717794e-20
 8.55877542e-23 1.49759660e-16 4.16493969e-20 2.77027502e-17
 6.30511685e-16 1.35215806e-20 3.62834398e-15 4.91042999e-16
 2.11513107e-19 1.50211183e-22 7.85866508e-19 1.73620542e-20
 6.57997982e-18 4.65888577e-15 2.45213011e-23 1.66367952e-18
 9.96113728e-14]
predicts:  1
The Final Result:  {'probs': array([4.53598452e-24, 1.00000000e+00, 2.65455319e-15, 8.61807214e-16,
       3.20200244e-15, 1.02618795e-10, 1.28289186e-19, 8.81717794e-20,
       8.55877542e-23, 1.49759660e-16, 4.16493969e-20, 2.77027502e-17,
       6.30511685e-16, 1.35215806e-20, 3.62834398e-15, 4.91042999e-16,
       2.11513107e-19, 1.50211183e-22, 7.85866508e-19, 1.73620542e-20,
       6.57997982e-18, 4.65888577e-15, 2.45213011e-23, 1.66367952e-18,
       9.96113728e-14], dtype=float32), 'pred': 1, 'box': Box(x=56.13, y=169.4, w=582.37, h=256.6), 'texts': ['a table of food, with plates, a pizza, pitchers, and glasses.']}
a table of food, with plates, a pizza, pitchers, and glasses.
predicate correct
  0%|▌                                                                                                                                                                                                                  | 12/5023 [00:09<1:24:28,  1.01s/it]This is the original CLIP result:
tensor([110.6250, 105.1875, 111.6250, 100.3750, 107.4375,  85.1250,  81.4375,
         89.0000, 115.2500, 104.2500,  89.5000, 109.6250], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([108.1250, 106.6250, 109.6875, 102.7500, 106.5000,  85.1250,  83.3125,
         88.1250, 114.6875, 105.2500,  90.1250, 108.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([108.1250, 106.6250, 109.6875, 102.7500, 106.5000,  85.1250,  83.3125,
         88.1250, 114.6875, 105.2500,  90.1250, 108.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([94.8750, 92.6250, 97.6250, 92.0000, 94.8750, 91.2500, 91.0000, 95.5000,
        95.5000, 93.9375, 95.1250, 95.8125], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [9.4218478e-03 4.0988289e-05 2.5611237e-02 3.3313299e-07 3.8888608e-04
 7.9364588e-14 1.9868538e-15 3.8239997e-12 9.6105456e-01 1.6051246e-05
 6.3047102e-12 3.4661039e-03]
parser result:  [4.44691308e-02 4.69397435e-03 6.90968262e-01 2.51228919e-03
 4.41598636e-02 0.00000000e+00 1.32592528e-16 8.31955880e-02
 1.78528406e-12 1.74388556e-02 9.54234613e-15 1.12562037e-01]
clip * parser result:  [4.18981381e-04 1.92397976e-07 1.76965517e-02 8.36926405e-10
 1.71731563e-05 0.00000000e+00 2.63441975e-31 3.18139905e-13
 1.71575539e-12 2.79915368e-07 6.01617272e-26 3.90151717e-04]
CLIP result after softmax:  [4.18981381e-04 1.92397976e-07 1.76965517e-02 8.36926405e-10
 1.71731563e-05 0.00000000e+00 2.63441975e-31 3.18139905e-13
 1.71575539e-12 2.79915368e-07 6.01617272e-26 3.90151717e-04]
predicts:  2
The Final Result:  {'probs': array([4.18981381e-04, 1.92397976e-07, 1.76965517e-02, 8.36926405e-10,
       1.71731563e-05, 0.00000000e+00, 2.63441975e-31, 3.18139905e-13,
       1.71575539e-12, 2.79915368e-07, 6.01617272e-26, 3.90151717e-04]), 'pred': 2, 'box': Box(x=114.78, y=76.14, w=194.79, h=273.23), 'texts': (['lower right', 'couch and black arm'], [([0.03873331844806671, 0.004082461819052696, 0.6058910489082336, 0.002185184508562088, 0.03873331844806671, 0.0010322079760953784, 0.0008038843516260386, 0.07236336916685104, 0.07236336916685104, 0.015168186277151108, 0.04973456263542175, 0.09890899807214737], [0.03873331844806671, 0.004082461819052696, 0.6058910489082336, 0.002185184508562088, 0.03873331844806671, 0.0010322079760953784, 0.0008038843516260386, 0.07236336916685104, 0.07236336916685104, 0.015168186277151108, 0.04973456263542175, 0.09890899807214737]), ([0.04446913081511023, 0.004693974350171847, 0.6909682616057053, 0.002512289190844704, 0.04415986364035466, 0.0, 1.3259252845739854e-16, 0.083195588042169, 1.7852840590058731e-12, 0.017438855616041724, 9.542346130514643e-15, 0.11256203673780744], [0.0013974765315651894, 0.0003118191671092063, 0.006666987668722868, 6.471600045188097e-06, 0.0002751794527284801, 1.434073535920219e-13, 2.3410606610273048e-14, 2.8804137894300474e-12, 0.9894687533378601, 7.884023216320202e-05, 2.1283537432470467e-11, 0.0017943953862413764])], ('lower right', 'lower right', 'couch and black arm', 'couch and black arm', 'couch and black arm', 'couch and black arm', 'chair'))}
lower right of couch and black arm of chair
This is the original CLIP result:
tensor([112.3750, 109.1250, 114.3750, 101.2500, 107.9375,  84.5000,  84.3125,
         89.5000, 106.0000, 107.9375,  84.5000, 106.6250], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.1825387e-01 4.5852000e-03 8.7378448e-01 1.7429675e-06 1.3984070e-03
 9.2652401e-14 7.6811536e-14 1.3750836e-11 2.0145962e-04 1.3984070e-03
 9.2652401e-14 3.7637615e-04]
predicts:  2
The Final Result:  {'probs': array([1.1825387e-01, 4.5852000e-03, 8.7378448e-01, 1.7429675e-06,
       1.3984070e-03, 9.2652401e-14, 7.6811536e-14, 1.3750836e-11,
       2.0145962e-04, 1.3984070e-03, 9.2652401e-14, 3.7637615e-04],
      dtype=float32), 'pred': 2, 'box': Box(x=114.78, y=76.14, w=194.79, h=273.23), 'texts': ['a gray couch']}
a gray couch
  0%|▌                                                                                                                                                                                                                  | 13/5023 [00:11<1:56:15,  1.39s/it]This is the original CLIP result:
tensor([ 95.6250, 120.0625,  84.2500,  98.8750], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [2.4374100e-11 1.0000000e+00 2.7978787e-16 6.2861633e-10]
predicts:  1
The Final Result:  {'probs': array([2.4374100e-11, 1.0000000e+00, 2.7978787e-16, 6.2861633e-10],
      dtype=float32), 'pred': 1, 'box': Box(x=325.54, y=311.24, w=154.46, h=159.08), 'texts': ['a parked white ford suv']}
a parked white ford suv
predicate correct
This is the original CLIP result:
tensor([ 81.1250, 119.8750,  72.0000,  90.7500], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.4828213e-17 1.0000000e+00 1.6149224e-21 2.2447769e-13]
predicts:  1
The Final Result:  {'probs': array([1.4828213e-17, 1.0000000e+00, 1.6149224e-21, 2.2447769e-13],
      dtype=float32), 'pred': 1, 'box': Box(x=325.54, y=311.24, w=154.46, h=159.08), 'texts': ['a light colored ford suv parked along the street.']}
a light colored ford suv parked along the street.
predicate correct
  0%|▌                                                                                                                                                                                                                  | 14/5023 [00:11<1:31:37,  1.10s/it]This is the original CLIP result:
tensor([112.5000, 116.1250, 113.2500, 112.0000, 116.5000, 119.6250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [7.4710808e-04 2.8035022e-02 1.5816278e-03 4.5314393e-04 4.0790718e-02
 9.2839247e-01]
predicts:  5
The Final Result:  {'probs': array([7.4710808e-04, 2.8035022e-02, 1.5816278e-03, 4.5314393e-04,
       4.0790718e-02, 9.2839247e-01], dtype=float32), 'pred': 5, 'box': Box(x=349.45, y=24.11, w=182.66, h=209.5), 'texts': ['a brown horse wearing a mask getting rode by a jockey']}
a brown horse wearing a mask getting rode by a jockey
  0%|▋                                                                                                                                                                                                                  | 15/5023 [00:12<1:11:23,  1.17it/s]This is the original CLIP result:
tensor([121.7500, 131.0000, 114.8750], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([121.7500, 131.0000, 114.8750], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([121.7500, 131.0000, 114.8750], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [9.6102405e-05 9.9990380e-01 9.9302383e-08]
parser result:  [9.6102405e-05 9.9990380e-01 9.9302383e-08]
clip * parser result:  [9.235673e-09 9.998076e-01 9.860964e-15]
CLIP result after softmax:  [9.235673e-09 9.998076e-01 9.860964e-15]
predicts:  1
The Final Result:  {'probs': array([9.235673e-09, 9.998076e-01, 9.860964e-15], dtype=float32), 'pred': 1, 'box': Box(x=62.28, y=142.57, w=205.15, h=337.43), 'texts': (['a chili dog with slices of cheese visible under the chili'], [([9.610240522306412e-05, 0.9999037981033325, 9.930238320521312e-08], [9.610240522306412e-05, 0.9999037981033325, 9.930238320521312e-08])], ('a chili dog', 'a chili dog', 'a chili dog', 'slices', 'cheese', 'the chili', 'the chili'))}
a chili dog with slices of cheese visible under the chili
predicate correct
This is the original CLIP result:
tensor([108.1250, 127.8750, 112.1250], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([108.1250, 127.8750, 112.1250], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([108.1250, 127.8750, 112.1250], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [2.6465734e-09 9.9999988e-01 1.4449800e-07]
parser result:  [2.6465734e-09 9.9999988e-01 1.4449800e-07]
clip * parser result:  [7.0043512e-18 9.9999976e-01 2.0879672e-14]
CLIP result after softmax:  [7.0043512e-18 9.9999976e-01 2.0879672e-14]
predicts:  1
The Final Result:  {'probs': array([7.0043512e-18, 9.9999976e-01, 2.0879672e-14], dtype=float32), 'pred': 1, 'box': Box(x=62.28, y=142.57, w=205.15, h=337.43), 'texts': (['a hot dog with chili on top'], [([2.646573404874175e-09, 0.9999998807907104, 1.4449800289639825e-07], [2.646573404874175e-09, 0.9999998807907104, 1.4449800289639825e-07])], ('a hot dog', 'a hot dog', 'a hot dog', 'chili', 'top'))}
a hot dog with chili on top
predicate correct
  0%|▋                                                                                                                                                                                                                  | 16/5023 [00:13<1:13:55,  1.13it/s]This is the original CLIP result:
tensor([111.5000, 112.6250,  95.3750, 120.8125,  91.8750, 102.0625, 118.6250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [8.1153470e-05 2.4997030e-04 8.0595097e-12 8.9882368e-01 2.4337612e-13
 6.4662569e-09 1.0084522e-01]
predicts:  3
The Final Result:  {'probs': array([8.1153470e-05, 2.4997030e-04, 8.0595097e-12, 8.9882368e-01,
       2.4337612e-13, 6.4662569e-09, 1.0084522e-01], dtype=float32), 'pred': 3, 'box': Box(x=328.15, y=324.19, w=182.43, h=74.75), 'texts': ["the man's skiis"]}
the man's skiis
predicate correct
This is the original CLIP result:
tensor([109.8750, 113.4375,  96.8750, 123.0000,  92.6250, 106.1250, 116.3125],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.9921067e-06 7.0224189e-05 4.5028174e-12 9.9868304e-01 6.4229241e-14
 4.6849859e-08 1.2447535e-03]
predicts:  3
The Final Result:  {'probs': array([1.9921067e-06, 7.0224189e-05, 4.5028174e-12, 9.9868304e-01,
       6.4229241e-14, 4.6849859e-08, 1.2447535e-03], dtype=float32), 'pred': 3, 'box': Box(x=328.15, y=324.19, w=182.43, h=74.75), 'texts': ['the skiis that the man has on']}
the skiis that the man has on
predicate correct
  0%|▋                                                                                                                                                                                                                  | 17/5023 [00:13<1:07:37,  1.23it/s]This is the original CLIP result:
tensor([122.1250,  99.6875,  88.5625], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.0000000e+00 1.8010159e-10 2.6545532e-15]
predicts:  0
The Final Result:  {'probs': array([1.0000000e+00, 1.8010159e-10, 2.6545532e-15], dtype=float32), 'pred': 0, 'box': Box(x=353.19, y=182.13, w=141.78, h=188.76), 'texts': ['a man about to throw a frisbee.']}
a man about to throw a frisbee.
predicate correct
This is the original CLIP result:
tensor([136.2500,  94.6875,  93.8750], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.0000000e+00 8.9050336e-19 3.9515847e-19]
predicts:  0
The Final Result:  {'probs': array([1.0000000e+00, 8.9050336e-19, 3.9515847e-19], dtype=float32), 'pred': 0, 'box': Box(x=353.19, y=182.13, w=141.78, h=188.76), 'texts': ['a man in a blue button down shirt by a lake preparing to throw a teal flying disc to a man far away from him.']}
a man in a blue button down shirt by a lake preparing to throw a teal flying disc to a man far away from him.
predicate correct
  0%|▊                                                                                                                                                                                                                    | 18/5023 [00:14<54:48,  1.52it/s]This is the original CLIP result:
tensor([ 74.1875, 100.1250, 102.3750,  84.6875,  78.6875, 107.5625, 107.1250,
         62.4062,  82.6250,  76.2500, 105.5000,  81.3750,  78.1875],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.7999306e-15 3.3095494e-04 3.1400132e-03 6.5365380e-11 1.6202458e-13
 5.6212652e-01 3.6293614e-01 1.3763342e-20 8.3102752e-12 1.4157550e-14
 7.1466364e-02 2.3809340e-12 9.8272871e-14]
predicts:  5
The Final Result:  {'probs': array([1.7999306e-15, 3.3095494e-04, 3.1400132e-03, 6.5365380e-11,
       1.6202458e-13, 5.6212652e-01, 3.6293614e-01, 1.3763342e-20,
       8.3102752e-12, 1.4157550e-14, 7.1466364e-02, 2.3809340e-12,
       9.8272871e-14], dtype=float32), 'pred': 5, 'box': Box(x=159.87, y=268.35, w=244.1, h=60.83), 'texts': ['a red and white checkered table with two wooden chairs.']}
a red and white checkered table with two wooden chairs.
predicate correct
This is the original CLIP result:
tensor([ 81.5625, 104.6875, 100.3750,  93.7500,  79.1875, 111.3125, 113.2500,
         73.2500,  88.1250,  83.6875, 114.5000,  90.5000,  89.9375],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.7349202e-15 4.1242143e-05 5.5264502e-07 7.3323864e-10 3.4740170e-16
 3.1084377e-02 2.1576832e-01 9.1666036e-19 2.6444712e-12 3.1272101e-14
 7.5310552e-01 2.8430747e-11 1.6199349e-11]
predicts:  10
The Final Result:  {'probs': array([3.7349202e-15, 4.1242143e-05, 5.5264502e-07, 7.3323864e-10,
       3.4740170e-16, 3.1084377e-02, 2.1576832e-01, 9.1666036e-19,
       2.6444712e-12, 3.1272101e-14, 7.5310552e-01, 2.8430747e-11,
       1.6199349e-11], dtype=float32), 'pred': 10, 'box': Box(x=321.2, y=274.24, w=78.82, h=46.43), 'texts': ['attractive, country style, red-check round tablecloth.']}
attractive, country style, red-check round tablecloth.
  0%|▊                                                                                                                                                                                                                  | 19/5023 [00:15<1:01:46,  1.35it/s]This is the original CLIP result:
tensor([116.5625, 113.6875,  96.5000,  86.6250,  89.5625,  88.4375,  87.9375],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([110.7500, 112.1250,  98.6250,  87.2500,  92.1875,  89.8125,  90.5625],
       device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [9.4659668e-01 5.3403325e-02 1.8328710e-09 9.4291796e-14 1.7791555e-12
 5.7760724e-13 3.5033654e-13]
parser result:  [2.01812997e-01 7.98185885e-01 1.09428026e-06 1.25611336e-11
 1.75128900e-09 1.62895239e-10 3.44849233e-10]
clip * parser result:  [1.9103551e-01 4.2625781e-02 2.0056745e-15 1.1844118e-24 3.1158155e-21
 9.4089472e-23 1.2081329e-22]
CLIP result after softmax:  [1.9103551e-01 4.2625781e-02 2.0056745e-15 1.1844118e-24 3.1158155e-21
 9.4089472e-23 1.2081329e-22]
predicts:  0
The Final Result:  {'probs': array([1.9103551e-01, 4.2625781e-02, 2.0056745e-15, 1.1844118e-24,
       3.1158155e-21, 9.4089472e-23, 1.2081329e-22], dtype=float32), 'pred': 0, 'box': Box(x=2.88, y=124.74, w=635.22, h=297.46), 'texts': (['a white train'], [([0.2018129974603653, 0.7981858849525452, 1.0942802646241034e-06, 1.2561133556909798e-11, 1.7512890027049366e-09, 1.6289523896428904e-10, 3.448492325031083e-10], [0.2018129974603653, 0.7981858849525452, 1.0942802646241034e-06, 1.2561133556909798e-11, 1.7512890027049366e-09, 1.6289523896428904e-10, 3.448492325031083e-10])], ('a white train', 'a white train', 'a white train', 'a black top', 'a black top', 'a black top'))}
a white train with a black top
predicate correct
This is the original CLIP result:
tensor([111.1250, 110.7500,  94.0625,  84.2500,  88.7500,  89.0000,  90.1250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [5.9266663e-01 4.0733337e-01 2.3049466e-08 1.2622527e-12 1.1362436e-10
 1.4589656e-10 4.4939302e-10]
predicts:  0
The Final Result:  {'probs': array([5.9266663e-01, 4.0733337e-01, 2.3049466e-08, 1.2622527e-12,
       1.1362436e-10, 1.4589656e-10, 4.4939302e-10], dtype=float32), 'pred': 0, 'box': Box(x=2.88, y=124.74, w=635.22, h=297.46), 'texts': ['a group of trains.']}
a group of trains.
predicate correct
  0%|▊                                                                                                                                                                                                                  | 20/5023 [00:16<1:06:54,  1.25it/s]This is the original CLIP result:
tensor([115.5000, 118.6250, 121.1250, 120.5625,  87.9375, 110.5000,  96.9375,
         93.6250,  86.8125,  90.8750], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([115.2500, 119.8750, 121.3750, 122.6875,  88.3125, 110.2500,  97.7500,
         94.1875,  87.1250,  91.1250], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([115.2500, 119.8750, 121.3750, 122.6875,  88.3125, 110.2500,  97.7500,
         94.1875,  87.1250,  91.1250], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [2.1785358e-03 4.9583245e-02 6.0404760e-01 3.4417593e-01 2.3330449e-15
 1.4678859e-05 1.8904857e-11 6.8860938e-13 7.5742872e-16 4.4021325e-14]
parser result:  [4.4274179e-04 4.5160890e-02 2.0239708e-01 7.5199634e-01 8.8581472e-16
 2.9831704e-06 1.1117242e-11 3.1537189e-13 2.7015822e-16 1.4750140e-14]
clip * parser result:  [9.6452879e-07 2.2392236e-03 1.2225747e-01 2.5881904e-01 2.0666455e-30
 4.3789538e-11 2.1016986e-22 2.1716803e-25 2.0462559e-31 6.4932073e-28]
CLIP result after softmax:  [9.6452879e-07 2.2392236e-03 1.2225747e-01 2.5881904e-01 2.0666455e-30
 4.3789538e-11 2.1016986e-22 2.1716803e-25 2.0462559e-31 6.4932073e-28]
predicts:  3
The Final Result:  {'probs': array([9.6452879e-07, 2.2392236e-03, 1.2225747e-01, 2.5881904e-01,
       2.0666455e-30, 4.3789538e-11, 2.1016986e-22, 2.1716803e-25,
       2.0462559e-31, 6.4932073e-28], dtype=float32), 'pred': 3, 'box': Box(x=0.0, y=243.31, w=90.29, h=65.33), 'texts': (['red motorcycle closest to camera'], [([0.0004427417879924178, 0.045160889625549316, 0.20239707827568054, 0.7519963383674622, 8.858147213212529e-16, 2.9831703614036087e-06, 1.111724167585093e-11, 3.1537188767589985e-13, 2.701582203812233e-16, 1.4750140263928083e-14], [0.0004427417879924178, 0.045160889625549316, 0.20239707827568054, 0.7519963383674622, 8.858147213212529e-16, 2.9831703614036087e-06, 1.111724167585093e-11, 3.1537188767589985e-13, 2.701582203812233e-16, 1.4750140263928083e-14])], ('red motorcycle', 'red motorcycle', 'camera'))}
red motorcycle closest to camera.
This is the original CLIP result:
tensor([104.6250, 113.0625, 113.5625, 114.3125,  81.7500, 104.0000,  87.2500,
         84.6250,  77.2500,  80.1250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.5278870e-05 1.6288245e-01 2.6854777e-01 5.6851566e-01 4.1023085e-15
 1.8883416e-05 1.0038018e-12 7.2715170e-14 4.5572533e-17 8.0779250e-16]
predicts:  3
The Final Result:  {'probs': array([3.5278870e-05, 1.6288245e-01, 2.6854777e-01, 5.6851566e-01,
       4.1023085e-15, 1.8883416e-05, 1.0038018e-12, 7.2715170e-14,
       4.5572533e-17, 8.0779250e-16], dtype=float32), 'pred': 3, 'box': Box(x=0.0, y=243.31, w=90.29, h=65.33), 'texts': ['a red & black color bike in ftont of the three guys']}
a red & black color bike in ftont of the three guys
  0%|▉                                                                                                                                                                                                                  | 21/5023 [00:17<1:29:44,  1.08s/it]This is the original CLIP result:
tensor([ 97.4375, 128.7500, 110.0625, 102.7500, 115.9375], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [2.5185630e-14 9.9999726e-01 7.6580937e-09 5.1090751e-12 2.7264700e-06]
predicts:  1
The Final Result:  {'probs': array([2.5185630e-14, 9.9999726e-01, 7.6580937e-09, 5.1090751e-12,
       2.7264700e-06], dtype=float32), 'pred': 1, 'box': Box(x=85.21, y=268.58, w=392.63, h=152.09), 'texts': ['a drinking glass with a knife resting on it']}
a drinking glass with a knife resting on it
This is the original CLIP result:
tensor([ 95.8750, 130.1250, 115.9375, 110.0625, 120.1875], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.3347277e-15 9.9995100e-01 6.8932775e-07 1.9361797e-09 4.8325604e-05]
predicts:  1
The Final Result:  {'probs': array([1.3347277e-15, 9.9995100e-01, 6.8932775e-07, 1.9361797e-09,
       4.8325604e-05], dtype=float32), 'pred': 1, 'box': Box(x=85.21, y=268.58, w=392.63, h=152.09), 'texts': ['clear glass with knife on it']}
clear glass with knife on it
  0%|▉                                                                                                                                                                                                                  | 22/5023 [00:18<1:14:56,  1.11it/s]This is the original CLIP result:
tensor([ 99.9375, 102.1250,  87.9375,  97.2500,  94.3750,  90.8125,  84.8750,
         86.1250,  79.5625,  91.3125], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 99.9375, 102.1250,  87.9375,  97.2500,  94.3750,  90.8125,  84.8750,
         86.1250,  79.5625,  91.3125], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.0014932e-01 8.9262122e-01 6.1533871e-07 6.8152468e-03 3.8448995e-04
 1.0907140e-05 2.8779775e-08 1.0045129e-07 1.4187242e-10 1.7982835e-05]
parser result:  [7.49627136e-03 9.92473744e-01 6.84169323e-07 2.04786266e-06
 2.72486879e-05 2.04556183e-09 5.35894494e-12 1.87344902e-11
 1.46903332e-09 0.00000000e+00]
clip * parser result:  [7.50746469e-04 8.85903124e-01 4.20995866e-13 1.39566894e-08
 1.04768466e-08 2.23112287e-14 1.54229230e-19 1.88190368e-18
 2.08415307e-19 0.00000000e+00]
CLIP result after softmax:  [7.50746469e-04 8.85903124e-01 4.20995866e-13 1.39566894e-08
 1.04768466e-08 2.23112287e-14 1.54229230e-19 1.88190368e-18
 2.08415307e-19 0.00000000e+00]
predicts:  1
The Final Result:  {'probs': array([7.50746469e-04, 8.85903124e-01, 4.20995866e-13, 1.39566894e-08,
       1.04768466e-08, 2.23112287e-14, 1.54229230e-19, 1.88190368e-18,
       2.08415307e-19, 0.00000000e+00]), 'pred': 1, 'box': Box(x=263.92, y=258.96, w=176.45, h=91.72), 'texts': (['the bigger animal', 'sup:bigger'], [([0.10014931857585907, 0.8926212191581726, 6.153387062113325e-07, 0.006815246772021055, 0.0003844899474643171, 1.090713976736879e-05, 2.8779775007592434e-08, 1.0045128817637305e-07, 1.4187241659247007e-10, 1.7982834833674133e-05], [0.10014931857585907, 0.8926212191581726, 6.153387062113325e-07, 0.006815246772021055, 0.0003844899474643171, 1.090713976736879e-05, 2.8779775007592434e-08, 1.0045128817637305e-07, 1.4187241659247007e-10, 1.7982834833674133e-05]), ([0.007496271360073259, 0.9924737443813058, 6.841693227809133e-07, 2.0478626649992782e-06, 2.7248687944523878e-05, 2.045561827002086e-09, 5.358944936190638e-12, 1.8734490219736594e-11, 1.4690333173449772e-09, 0.0], None)], ('the bigger animal', 'the bigger animal', 'the bigger animal'))}
the bigger animal
predicate correct
  0%|▉                                                                                                                                                                                                                  | 23/5023 [00:19<1:14:17,  1.12it/s]This is the original CLIP result:
tensor([ 86.3750,  86.5000,  88.2500, 102.0000, 101.7500, 102.5000],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 86.4375,  83.9375,  88.1875, 104.0000, 103.2500, 102.7500],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 86.4375,  83.9375,  88.1875, 104.0000, 103.2500, 102.7500],
       device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [4.7771433e-08 5.4132130e-08 3.1150890e-07 2.9175586e-01 2.2721969e-01
 4.8102409e-01]
parser result:  [4.63979991e-08 1.02284104e-09 7.17066768e-08 5.28252129e-01
 0.00000000e+00 4.71747752e-01]
clip * parser result:  [2.21649890e-15 5.53685641e-17 2.23372679e-14 1.54120652e-01
 0.00000000e+00 2.26922031e-01]
CLIP result after softmax:  [2.21649890e-15 5.53685641e-17 2.23372679e-14 1.54120652e-01
 0.00000000e+00 2.26922031e-01]
predicts:  5
The Final Result:  {'probs': array([2.21649890e-15, 5.53685641e-17, 2.23372679e-14, 1.54120652e-01,
       0.00000000e+00, 2.26922031e-01]), 'pred': 5, 'box': Box(x=1.73, y=3.89, w=198.85, h=58.79), 'texts': (['the empty part of the blue plate', 'sup:left'], [([1.3411243671157536e-08, 1.1008618461261221e-09, 7.717638084159262e-08, 0.5685464143753052, 0.26856228709220886, 0.16289125382900238], [1.3411243671157536e-08, 1.1008618461261221e-09, 7.717638084159262e-08, 0.5685464143753052, 0.26856228709220886, 0.16289125382900238]), ([4.639799906158746e-08, 1.0228410410122038e-09, 7.170667683813697e-08, 0.5282521288438197, 0.0, 0.47174775202866337], None)], ('the empty part', 'the empty part', 'the empty part', 'the blue plate', 'the blue plate', 'the blue plate', 'the left', 'the left'))}
the empty part of the blue plate on the left.
  0%|█                                                                                                                                                                                                                  | 24/5023 [00:19<1:09:43,  1.19it/s]This is the original CLIP result:
tensor([ 96.2500,  86.7500,  88.6250,  85.1250, 113.8125, 103.8750,  82.0000,
         79.2500, 126.4375], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [7.7577159e-14 5.8067922e-18 3.7865043e-17 1.1434252e-18 3.2887490e-06
 1.5893857e-10 5.0238598e-20 3.2116461e-21 9.9999666e-01]
predicts:  8
The Final Result:  {'probs': array([7.7577159e-14, 5.8067922e-18, 3.7865043e-17, 1.1434252e-18,
       3.2887490e-06, 1.5893857e-10, 5.0238598e-20, 3.2116461e-21,
       9.9999666e-01], dtype=float32), 'pred': 8, 'box': Box(x=256.16, y=401.06, w=139.29, h=116.22), 'texts': ["pot boiling water with green bell peppers in man's kitchen"]}
pot boiling water with green bell peppers in man's kitchen
predicate correct
This is the original CLIP result:
tensor([ 96.3750,  88.7500,  94.9375,  92.5625, 108.0000,  91.6250,  90.2500,
         83.7500, 111.1250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.7625469e-07 1.8364812e-10 8.9368321e-08 8.3125489e-09 4.2087708e-02
 3.2552410e-09 8.2305374e-10 1.2374112e-12 9.5791179e-01]
predicts:  8
The Final Result:  {'probs': array([3.7625469e-07, 1.8364812e-10, 8.9368321e-08, 8.3125489e-09,
       4.2087708e-02, 3.2552410e-09, 8.2305374e-10, 1.2374112e-12,
       9.5791179e-01], dtype=float32), 'pred': 8, 'box': Box(x=256.16, y=401.06, w=139.29, h=116.22), 'texts': ['a pan with food cooking on the gas.']}
a pan with food cooking on the gas.
predicate correct
  0%|█                                                                                                                                                                                                                  | 25/5023 [00:20<1:10:04,  1.19it/s]This is the original CLIP result:
tensor([131.6250, 114.8750, 117.5625, 118.2500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([129.5000, 113.7500, 117.5000, 117.5000], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([129.5000, 113.7500, 117.5000, 117.5000], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [9.9999762e-01 5.3157727e-08 7.8114704e-07 1.5534963e-06]
parser result:  [9.9998748e-01 1.4449621e-07 6.1441356e-06 6.1441356e-06]
clip * parser result:  [9.9998510e-01 7.6810904e-15 4.7994733e-12 9.5448918e-12]
CLIP result after softmax:  [9.9998510e-01 7.6810904e-15 4.7994733e-12 9.5448918e-12]
predicts:  0
The Final Result:  {'probs': array([9.9998510e-01, 7.6810904e-15, 4.7994733e-12, 9.5448918e-12],
      dtype=float32), 'pred': 0, 'box': Box(x=64.75, y=319.0, w=478.87, h=280.09), 'texts': (['the orange closest to the banana'], [([0.9999874830245972, 1.4449621232870413e-07, 6.144135568320053e-06, 6.144135568320053e-06], [0.9999874830245972, 1.4449621232870413e-07, 6.144135568320053e-06, 6.144135568320053e-06])], ('the orange', 'the orange', 'the banana', 'the banana'))}
the orange closest to the banana.
This is the original CLIP result:
tensor([124.3750, 108.5000, 112.8125, 112.0000], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [9.9998617e-01 1.2751730e-07 9.5162095e-06 4.2227930e-06]
predicts:  0
The Final Result:  {'probs': array([9.9998617e-01, 1.2751730e-07, 9.5162095e-06, 4.2227930e-06],
      dtype=float32), 'pred': 0, 'box': Box(x=64.75, y=319.0, w=478.87, h=280.09), 'texts': ['orange between other oranges and a banana']}
orange between other oranges and a banana
  1%|█                                                                                                                                                                                                                  | 26/5023 [00:21<1:10:56,  1.17it/s]This is the original CLIP result:
tensor([ 79.3750,  94.3750,  96.5000, 100.6250, 107.6875,  84.5000,  98.8750,
         77.1250,  94.9375,  63.1875,  84.1250,  74.9375], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [5.0535092e-13 1.6520009e-06 1.3832034e-05 8.5575762e-04 9.9897718e-01
 8.4986955e-11 1.4870838e-04 5.3263590e-14 2.8993518e-06 4.7146681e-20
 5.8410624e-11 5.9760093e-15]
predicts:  4
The Final Result:  {'probs': array([5.0535092e-13, 1.6520009e-06, 1.3832034e-05, 8.5575762e-04,
       9.9897718e-01, 8.4986955e-11, 1.4870838e-04, 5.3263590e-14,
       2.8993518e-06, 4.7146681e-20, 5.8410624e-11, 5.9760093e-15],
      dtype=float32), 'pred': 4, 'box': Box(x=393.12, y=148.19, w=109.69, h=256.89), 'texts': ['a man in a black suit with a red tie.']}
a man in a black suit with a red tie.
This is the original CLIP result:
tensor([ 79.1250,  98.1875,  89.5000,  96.6250, 101.3750,  79.5000,  93.7500,
         72.8125,  89.8750,  62.3438,  80.0000,  71.3750], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [2.0681398e-10 3.9293297e-02 6.6280404e-06 8.2363216e-03 9.5198941e-01
 3.0091254e-10 4.6466148e-04 3.7505589e-13 9.6437416e-06 1.0655544e-17
 4.9612092e-10 8.9083580e-14]
predicts:  4
The Final Result:  {'probs': array([2.0681398e-10, 3.9293297e-02, 6.6280404e-06, 8.2363216e-03,
       9.5198941e-01, 3.0091254e-10, 4.6466148e-04, 3.7505589e-13,
       9.6437416e-06, 1.0655544e-17, 4.9612092e-10, 8.9083580e-14],
      dtype=float32), 'pred': 4, 'box': Box(x=393.12, y=148.19, w=109.69, h=256.89), 'texts': ['a man with a red and silver power tie.']}
a man with a red and silver power tie.
  1%|█▏                                                                                                                                                                                                                 | 27/5023 [00:22<1:15:28,  1.10it/s]This is the original CLIP result:
tensor([103.5625, 119.1250, 122.8750,  85.6875,  87.5625], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 98.7500, 114.5625, 105.6875,  94.8750,  87.2500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([114.8750, 112.8125, 124.1250,  90.5000,  93.3750], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [4.0049071e-09 2.2977371e-02 9.7702265e-01 6.9115996e-17 4.5069289e-16]
parser result:  [2.70771776e-13 1.69310284e-12 1.00000000e+00 0.00000000e+00
 4.42022778e-14]
clip * parser result:  [1.08441580e-21 3.89030518e-14 9.77022648e-01 0.00000000e+00
 1.99216524e-29]
CLIP result after softmax:  [1.08441580e-21 3.89030518e-14 9.77022648e-01 0.00000000e+00
 1.99216524e-29]
predicts:  2
The Final Result:  {'probs': array([1.08441580e-21, 3.89030518e-14, 9.77022648e-01, 0.00000000e+00,
       1.99216524e-29]), 'pred': 2, 'box': Box(x=198.33, y=216.05, w=185.17, h=191.11), 'texts': (['a catcher', 'the umpire'], [([9.610124106984586e-05, 1.2217900803079829e-05, 0.9998916387557983, 2.493451756172189e-15, 4.419748800884443e-14], [9.610124106984586e-05, 1.2217900803079829e-05, 0.9998916387557983, 2.493451756172189e-15, 4.419748800884443e-14]), ([2.707717762003942e-13, 1.6931028421128443e-12, 0.9999999999979919, 0.0, 4.42022778225163e-14], [1.3572433488207025e-07, 0.9998600482940674, 0.00013982206291984767, 2.8168687382645885e-09, 1.3749001936957939e-12])], ('a catcher', 'a catcher', 'front', 'the umpire', 'the umpire'))}
a catcher crouching in front of the umpire.
predicate correct
This is the original CLIP result:
tensor([102.7500, 110.5000, 112.6250,  87.5000,  84.7500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([83.6250, 80.0000, 85.0000, 87.1250, 83.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([112.8750, 112.0625, 121.6250,  88.5000,  92.3750], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [4.5954064e-05 1.0668569e-01 8.9326835e-01 1.0947957e-11 6.9987944e-13]
parser result:  [6.93835743e-01 3.06164257e-01 0.00000000e+00 2.17839136e-11
 7.20642287e-10]
clip * parser result:  [3.18845723e-05 3.26633452e-02 0.00000000e+00 2.38489348e-22
 5.04362724e-22]
CLIP result after softmax:  [3.18845723e-05 3.26633452e-02 0.00000000e+00 2.38489348e-22
 5.04362724e-22]
predicts:  1
The Final Result:  {'probs': array([3.18845723e-05, 3.26633452e-02, 0.00000000e+00, 2.38489348e-22,
       5.04362724e-22]), 'pred': 1, 'box': Box(x=31.15, y=155.73, w=198.0, h=259.18), 'texts': (['the catcher', 'the plate'], [([0.00015842507127672434, 7.030070992186666e-05, 0.9997712969779968, 4.1105124031382435e-15, 1.9805557476167135e-13], [0.00015842507127672434, 7.030070992186666e-05, 0.9997712969779968, 4.1105124031382435e-15, 1.9805557476167135e-13]), ([0.693835742522464, 0.3061642567351098, 0.0, 2.178391360080805e-11, 7.206422868028858e-10], [0.025722824037075043, 0.0006854900857433677, 0.10173574835062027, 0.8518229722976685, 0.020032957196235657])], ('the catcher', 'the catcher', 'the plate', 'the plate'))}
the catcher behind the plate
  1%|█▏                                                                                                                                                                                                                 | 28/5023 [00:24<1:29:41,  1.08s/it]This is the original CLIP result:
tensor([ 83.4375,  93.6875,  82.7500,  81.7500,  83.5625,  90.7500,  90.3125,
        121.5000,  99.6875], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.9489422e-17 8.3403586e-13 1.4828213e-17 5.4549948e-18 3.3415893e-17
 4.4202279e-14 2.8539139e-14 1.0000000e+00 3.3647407e-10]
predicts:  7
The Final Result:  {'probs': array([2.9489422e-17, 8.3403586e-13, 1.4828213e-17, 5.4549948e-18,
       3.3415893e-17, 4.4202279e-14, 2.8539139e-14, 1.0000000e+00,
       3.3647407e-10], dtype=float32), 'pred': 7, 'box': Box(x=303.75, y=72.88, w=246.76, h=156.29), 'texts': ['the boy sitting against the wall, reading']}
the boy sitting against the wall, reading
predicate correct
This is the original CLIP result:
tensor([ 78.5000,  96.0625,  79.8750,  77.3750,  79.1250,  86.8750,  97.3750,
        122.1250, 113.1250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.1320083e-19 4.7989533e-12 4.4771797e-19 3.6750930e-20 2.1148701e-19
 4.9098244e-16 1.7830274e-11 9.9987662e-01 1.2339458e-04]
predicts:  7
The Final Result:  {'probs': array([1.1320083e-19, 4.7989533e-12, 4.4771797e-19, 3.6750930e-20,
       2.1148701e-19, 4.9098244e-16, 1.7830274e-11, 9.9987662e-01,
       1.2339458e-04], dtype=float32), 'pred': 7, 'box': Box(x=303.75, y=72.88, w=246.76, h=156.29), 'texts': ['a boy sitting on a floor reading something']}
a boy sitting on a floor reading something
predicate correct
  1%|█▏                                                                                                                                                                                                                 | 29/5023 [00:24<1:24:25,  1.01s/it]This is the original CLIP result:
tensor([120.0000,  98.8125,  94.2500,  93.8750,  89.8750,  96.1250,  95.2500,
         93.3750,  93.2500,  89.0625,  93.2500,  93.5000,  93.8750, 113.8750],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([120.0000,  98.8125,  94.2500,  93.8750,  89.8750,  96.1250,  95.2500,
         93.3750,  93.2500,  89.0625,  93.2500,  93.5000,  93.8750, 113.8750],
       device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [9.9781728e-01 6.2724426e-10 6.5458810e-12 4.4989138e-12 8.2400483e-14
 4.2684505e-11 1.7793550e-11 2.7287291e-12 2.4080950e-12 3.6564989e-14
 2.4080950e-12 3.0920553e-12 4.4989138e-12 2.1827165e-03]
parser result:  [9.99999999e-01 2.49917305e-17 2.41138330e-19 1.56438558e-19
 1.24584945e-21 6.46980891e-19 6.72287091e-20 3.01707101e-21
 2.87721911e-20 1.27084282e-21 0.00000000e+00 7.29278515e-21
 5.87278407e-20 7.15583602e-10]
clip * parser result:  [9.97817277e-01 1.56759194e-26 1.57846282e-30 7.03803591e-31
 1.02658597e-34 2.76160592e-29 1.19623737e-30 8.23276957e-33
 6.92861693e-32 4.64683540e-35 0.00000000e+00 2.25496947e-32
 2.64211495e-31 1.56191614e-12]
CLIP result after softmax:  [9.97817277e-01 1.56759194e-26 1.57846282e-30 7.03803591e-31
 1.02658597e-34 2.76160592e-29 1.19623737e-30 8.23276957e-33
 6.92861693e-32 4.64683540e-35 0.00000000e+00 2.25496947e-32
 2.64211495e-31 1.56191614e-12]
predicts:  0
The Final Result:  {'probs': array([9.97817277e-01, 1.56759194e-26, 1.57846282e-30, 7.03803591e-31,
       1.02658597e-34, 2.76160592e-29, 1.19623737e-30, 8.23276957e-33,
       6.92861693e-32, 4.64683540e-35, 0.00000000e+00, 2.25496947e-32,
       2.64211495e-31, 1.56191614e-12]), 'pred': 0, 'box': Box(x=320.02, y=117.7, w=250.53, h=248.7), 'texts': (['the closest cow', 'sup:closest'], [([0.9978172779083252, 6.272442565347092e-10, 6.545881024722089e-12, 4.4989138282824914e-12, 8.240048319238871e-14, 4.268450523592371e-11, 1.7793549619837812e-11, 2.7287291350097664e-12, 2.4080949907745453e-12, 3.656498931761676e-14, 2.4080949907745453e-12, 3.092055257669646e-12, 4.4989138282824914e-12, 0.002182716503739357], [0.9978172779083252, 6.272442565347092e-10, 6.545881024722089e-12, 4.4989138282824914e-12, 8.240048319238871e-14, 4.268450523592371e-11, 1.7793549619837812e-11, 2.7287291350097664e-12, 2.4080949907745453e-12, 3.656498931761676e-14, 2.4080949907745453e-12, 3.092055257669646e-12, 4.4989138282824914e-12, 0.002182716503739357]), ([0.9999999992844163, 2.499173046457643e-17, 2.411383299782938e-19, 1.5643855783294894e-19, 1.2458494491566197e-21, 6.469808911936374e-19, 6.72287091052496e-20, 3.017071012256397e-21, 2.8772191121215405e-20, 1.270842815359378e-21, 0.0, 7.292785147894552e-21, 5.872784073672714e-20, 7.155836015592202e-10], None)], ('the closest cow', 'the closest cow', 'the closest cow'))}
the closest cow
predicate correct
This is the original CLIP result:
tensor([119.2500, 105.6875,  90.6250,  93.6250,  86.2500,  92.0000,  92.1875,
         88.1875,  88.9375,  81.8750,  87.2500,  88.1875,  90.5000, 110.5000],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9984026e-01 1.2876912e-06 3.7004205e-13 7.4324930e-12 4.6581416e-15
 1.4635447e-12 1.7653718e-12 3.2333917e-14 6.8450894e-14 5.8637358e-17
 1.2662142e-14 3.2333917e-14 3.2656096e-13 1.5843601e-04]
predicts:  0
The Final Result:  {'probs': array([9.9984026e-01, 1.2876912e-06, 3.7004205e-13, 7.4324930e-12,
       4.6581416e-15, 1.4635447e-12, 1.7653718e-12, 3.2333917e-14,
       6.8450894e-14, 5.8637358e-17, 1.2662142e-14, 3.2333917e-14,
       3.2656096e-13, 1.5843601e-04], dtype=float32), 'pred': 0, 'box': Box(x=320.02, y=117.7, w=250.53, h=248.7), 'texts': ['the bull seated on the ground facing the camera']}
the bull seated on the ground facing the camera
predicate correct
  1%|█▎                                                                                                                                                                                                                 | 30/5023 [00:26<1:44:33,  1.26s/it]This is the original CLIP result:
tensor([75.4375, 98.0625, 84.1250, 91.0000], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([75.4375, 98.0625, 84.1250, 91.0000], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.4918154e-10 9.9914324e-01 8.8439936e-07 8.5589994e-04]
parser result:  [1.54121697e-13 1.03240402e-03 0.00000000e+00 9.98967596e-01]
clip * parser result:  [2.29921125e-23 1.03151950e-03 0.00000000e+00 8.55016305e-04]
CLIP result after softmax:  [2.29921125e-23 1.03151950e-03 0.00000000e+00 8.55016305e-04]
predicts:  1
The Final Result:  {'probs': array([2.29921125e-23, 1.03151950e-03, 0.00000000e+00, 8.55016305e-04]), 'pred': 1, 'box': Box(x=173.54, y=45.12, w=303.73, h=141.38), 'texts': (['grey table top', 'sup:top'], [([1.4918154211951418e-10, 0.9991432428359985, 8.84399355527421e-07, 0.0008558999397791922], [1.4918154211951418e-10, 0.9991432428359985, 8.84399355527421e-07, 0.0008558999397791922]), ([1.541216974252309e-13, 0.0010324040191172052, 0.0, 0.9989675959807287], None)], ('grey table top', 'grey table top', 'grey table top'))}
grey table top
predicate correct
This is the original CLIP result:
tensor([ 73.2500,  98.9375,  85.2500, 101.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 71.6250,  96.7500,  83.3125, 100.2500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 71.6250,  96.7500,  83.3125, 100.2500], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [5.6116001e-13 8.0357462e-02 9.1331472e-08 9.1964245e-01]
parser result:  [3.5925267e-13 2.9312229e-02 4.2777632e-08 9.7068775e-01]
clip * parser result:  [2.0159822e-25 2.3554564e-03 3.9069441e-15 8.9268565e-01]
CLIP result after softmax:  [2.0159822e-25 2.3554564e-03 3.9069441e-15 8.9268565e-01]
predicts:  3
The Final Result:  {'probs': array([2.0159822e-25, 2.3554564e-03, 3.9069441e-15, 8.9268565e-01],
      dtype=float32), 'pred': 3, 'box': Box(x=0.0, y=0.83, w=200.0, h=216.67), 'texts': (['the corner of the gray table visible to the right of the hand'], [([3.592526666776341e-13, 0.02931222878396511, 4.277763210325247e-08, 0.970687747001648], [3.592526666776341e-13, 0.02931222878396511, 4.277763210325247e-08, 0.970687747001648])], ('the corner', 'the corner', 'the gray table', 'the gray table', 'the gray table', 'the right', 'the right', 'the hand', 'the hand'))}
the corner of the gray table visible to the right of the hand.
  1%|█▎                                                                                                                                                                                                                 | 31/5023 [00:27<1:40:49,  1.21s/it]This is the original CLIP result:
tensor([136.5000, 115.2500,  93.5000, 114.8125,  92.3750,  97.7500,  90.5000,
         95.0625], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.00000000e+00 5.90530402e-10 2.11513107e-19 3.81275067e-10
 6.86682499e-20 1.48282134e-17 1.05306175e-20 1.00907256e-18]
predicts:  0
The Final Result:  {'probs': array([1.00000000e+00, 5.90530402e-10, 2.11513107e-19, 3.81275067e-10,
       6.86682499e-20, 1.48282134e-17, 1.05306175e-20, 1.00907256e-18],
      dtype=float32), 'pred': 0, 'box': Box(x=81.18, y=115.4, w=450.79, h=154.72), 'texts': ['lufthansa airplane']}
lufthansa airplane
predicate correct
This is the original CLIP result:
tensor([111.7500, 108.1875,  95.0000, 109.1250,  87.3750,  95.0625,  86.1250,
         90.4375], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.0842390e-01 2.5770003e-02 4.8289866e-08 6.5806009e-02 2.3570052e-11
 5.1404292e-08 6.7529328e-12 5.0394988e-10]
predicts:  0
The Final Result:  {'probs': array([9.0842390e-01, 2.5770003e-02, 4.8289866e-08, 6.5806009e-02,
       2.3570052e-11, 5.1404292e-08, 6.7529328e-12, 5.0394988e-10],
      dtype=float32), 'pred': 0, 'box': Box(x=81.18, y=115.4, w=450.79, h=154.72), 'texts': ['an airplane sitting on the tarmac.']}
an airplane sitting on the tarmac.
predicate correct
  1%|█▎                                                                                                                                                                                                                 | 32/5023 [00:28<1:27:58,  1.06s/it]This is the original CLIP result:
tensor([ 81.8750, 110.3750,  80.7500, 105.7500], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [4.1530801e-13 9.9029154e-01 1.3483077e-13 9.7084772e-03]
predicts:  1
The Final Result:  {'probs': array([4.1530801e-13, 9.9029154e-01, 1.3483077e-13, 9.7084772e-03],
      dtype=float32), 'pred': 1, 'box': Box(x=33.12, y=78.85, w=303.88, h=181.46), 'texts': ['white colored bus.']}
white colored bus.
predicate correct
This is the original CLIP result:
tensor([ 78.8750, 113.7500,  75.3750, 101.8125], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [7.1445863e-16 9.9999344e-01 2.1574781e-17 6.5404370e-06]
predicts:  1
The Final Result:  {'probs': array([7.1445863e-16, 9.9999344e-01, 2.1574781e-17, 6.5404370e-06],
      dtype=float32), 'pred': 1, 'box': Box(x=33.12, y=78.85, w=303.88, h=181.46), 'texts': ['this is a bus with atlantic on the side']}
this is a bus with atlantic on the side
predicate correct
  1%|█▍                                                                                                                                                                                                                 | 33/5023 [00:29<1:15:03,  1.11it/s]This is the original CLIP result:
tensor([109.8125, 123.3125, 118.5000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.3599047e-06 9.9193668e-01 8.0619808e-03]
predicts:  1
The Final Result:  {'probs': array([1.3599047e-06, 9.9193668e-01, 8.0619808e-03], dtype=float32), 'pred': 1, 'box': Box(x=132.82, y=214.35, w=251.45, h=307.43), 'texts': ['a black baggage with a note']}
a black baggage with a note
predicate correct
This is the original CLIP result:
tensor([113.0625, 131.0000, 126.3125], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.606428e-08 9.908743e-01 9.125637e-03]
predicts:  1
The Final Result:  {'probs': array([1.606428e-08, 9.908743e-01, 9.125637e-03], dtype=float32), 'pred': 1, 'box': Box(x=132.82, y=214.35, w=251.45, h=307.43), 'texts': ['the black suitcase with the tag']}
the black suitcase with the tag
predicate correct
  1%|█▍                                                                                                                                                                                                                 | 34/5023 [00:29<1:01:27,  1.35it/s]This is the original CLIP result:
tensor([119.2500, 121.5000, 112.7500, 106.1250], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([96.2500, 94.0000, 99.8125, 91.0000], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [9.5335774e-02 9.0452069e-01 1.4333153e-04 1.9016949e-07]
parser result:  [2.7501345e-02 2.8986202e-03 9.6945578e-01 1.4431380e-04]
clip * parser result:  [2.6218619e-03 2.6218619e-03 1.3895359e-04 2.7444082e-11]
CLIP result after softmax:  [2.6218619e-03 2.6218619e-03 1.3895359e-04 2.7444082e-11]
predicts:  0
The Final Result:  {'probs': array([2.6218619e-03, 2.6218619e-03, 1.3895359e-04, 2.7444082e-11],
      dtype=float32), 'pred': 0, 'box': Box(x=37.58, y=215.94, w=342.55, h=99.87), 'texts': (['the man'], [([0.027501344680786133, 0.002898620208725333, 0.9694557785987854, 0.00014431380259338766], [0.027501344680786133, 0.002898620208725333, 0.9694557785987854, 0.00014431380259338766])], ('the man', 'the man', 'top'))}
the white bedspread the man is laying on top of.
This is the original CLIP result:
tensor([124.4375, 126.0000, 119.8750, 114.6250], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.7297375e-01 8.2521164e-01 1.8051432e-03 9.4725210e-06]
predicts:  1
The Final Result:  {'probs': array([1.7297375e-01, 8.2521164e-01, 1.8051432e-03, 9.4725210e-06],
      dtype=float32), 'pred': 1, 'box': Box(x=0.0, y=311.16, w=637.48, h=168.27), 'texts': ['hotel bed man is laying on']}
hotel bed man is laying on
predicate correct
  1%|█▍                                                                                                                                                                                                                   | 35/5023 [00:30<58:08,  1.43it/s]This is the original CLIP result:
tensor([128.5000, 128.7500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.4378235 0.5621765]
predicts:  1
The Final Result:  {'probs': array([0.4378235, 0.5621765], dtype=float32), 'pred': 1, 'box': Box(x=237.16, y=139.45, w=195.6, h=129.95), 'texts': ['near zebra']}
near zebra
predicate correct
This is the original CLIP result:
tensor([129.0000, 128.5000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.62245935 0.37754068]
predicts:  0
The Final Result:  {'probs': array([0.62245935, 0.37754068], dtype=float32), 'pred': 0, 'box': Box(x=203.42, y=158.89, w=182.78, h=126.97), 'texts': ['zebra was eating grass']}
zebra was eating grass
predicate correct
  1%|█▌                                                                                                                                                                                                                   | 36/5023 [00:30<46:34,  1.78it/s]This is the original CLIP result:
tensor([110.7500,  68.7500, 130.5000, 130.7500,  73.8750,  76.8750,  88.6250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.1587321e-09 6.6621562e-28 4.3782350e-01 5.6217653e-01 1.1204025e-25
 2.2503884e-24 2.8524473e-19]
predicts:  3
The Final Result:  {'probs': array([1.1587321e-09, 6.6621562e-28, 4.3782350e-01, 5.6217653e-01,
       1.1204025e-25, 2.2503884e-24, 2.8524473e-19], dtype=float32), 'pred': 3, 'box': Box(x=64.72, y=21.57, w=339.77, h=280.45), 'texts': ['a black horse with a blue cover tied to a horse trailer']}
a black horse with a blue cover tied to a horse trailer
This is the original CLIP result:
tensor([118.8750,  74.1250, 126.8125, 121.3125,  77.5000,  85.6250,  85.3750],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([117.0625,  75.7500, 126.5000, 121.1875,  78.5000,  84.9375,  85.0000],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([117.0625,  75.7500, 126.5000, 121.1875,  78.5000,  84.9375,  85.0000],
       device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [3.5551822e-04 1.3067237e-23 9.9557579e-01 4.0686908e-03 3.8188067e-22
 1.2899425e-18 1.0046082e-18]
parser result:  [7.9282217e-05 9.0653592e-23 9.9501580e-01 4.9050171e-03 1.4180608e-21
 8.8606491e-19 9.4321120e-19]
clip * parser result:  [2.81862729e-08 1.40129846e-45 9.90613639e-01 1.99569986e-05
 5.40901207e-43 1.14297275e-36 9.47557663e-37]
CLIP result after softmax:  [2.81862729e-08 1.40129846e-45 9.90613639e-01 1.99569986e-05
 5.40901207e-43 1.14297275e-36 9.47557663e-37]
predicts:  2
The Final Result:  {'probs': array([2.81862729e-08, 1.40129846e-45, 9.90613639e-01, 1.99569986e-05,
       5.40901207e-43, 1.14297275e-36, 9.47557663e-37], dtype=float32), 'pred': 2, 'box': Box(x=361.35, y=157.15, w=267.5, h=162.88), 'texts': (['the horse with the blue cover'], [([7.92822174844332e-05, 9.065359175415543e-23, 0.9950157999992371, 0.004905017092823982, 1.418060806089909e-21, 8.86064912023687e-19, 9.432112016297957e-19], [7.92822174844332e-05, 9.065359175415543e-23, 0.9950157999992371, 0.004905017092823982, 1.418060806089909e-21, 8.86064912023687e-19, 9.432112016297957e-19])], ('the horse', 'the horse', 'the blue cover', 'the blue cover', 'the blue cover', 'its back', 'its back'))}
the horse with the blue cover on its back.
predicate correct
  1%|█▌                                                                                                                                                                                                                 | 37/5023 [00:31<1:05:20,  1.27it/s]This is the original CLIP result:
tensor([116.7500, 120.2500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.02931223 0.97068775]
predicts:  1
The Final Result:  {'probs': array([0.02931223, 0.97068775], dtype=float32), 'pred': 1, 'box': Box(x=32.36, y=167.26, w=321.44, h=244.86), 'texts': ['elephant facing towards a red cement wall.']}
elephant facing towards a red cement wall.
This is the original CLIP result:
tensor([121.3750, 122.2500], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([116.6875, 118.0625], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([120.8125, 121.7500], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([120.8125, 121.7500], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([116.6875, 118.0625], device='cuda:0', dtype=torch.float16)
/home/lhxiao/pcl_experiment_202203/reclip/methods/parse.py:189: RuntimeWarning: invalid value encountered in double_scalars
  if m1 < self.baseline_threshold * m2:

 This is the parser result:
CLIP result:  [0.29421496 0.70578504]
parser result:  [1. 0.]
clip * parser result:  [0.29421496 0.        ]
CLIP result after softmax:  [0.29421496 0.        ]
predicts:  0
The Final Result:  {'probs': array([0.29421496, 0.        ]), 'pred': 0, 'box': Box(x=294.08, y=178.11, w=214.98, h=256.48), 'texts': (['an elephant facing towards a red wall', 'another elephant'], [([0.2018132209777832, 0.7981867790222168], [0.2018132209777832, 0.7981867790222168]), ([1.0, 0.0], [0.28140559792518616, 0.7185943722724915])], ('an elephant', 'an elephant', 'a red wall', 'a red wall', 'a red wall', 'the right', 'the right', 'another elephant', 'another elephant', 'the wall', 'the wall'))}
an elephant facing towards a red wall to the right of another elephant facing away from the wall.
predicate correct
  1%|█▌                                                                                                                                                                                                                 | 38/5023 [00:32<1:03:03,  1.32it/s]This is the original CLIP result:
tensor([104.7500, 108.1250, 106.3125, 100.1250, 102.8750,  98.3750, 100.2500,
        101.1250,  96.3125,  91.6250,  89.3750,  90.5000, 105.8125,  96.0000,
         88.2500,  94.3750,  92.5000,  97.1250,  87.8750,  87.7500],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([105.1250, 106.5625, 105.8750, 100.6250, 104.6250,  99.7500, 102.0000,
        103.0000,  98.7500,  93.7500,  92.1250,  88.0625, 107.8750,  97.1250,
         87.6875,  92.2500,  89.7500,  95.5625,  84.8125,  89.6875],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([105.1250, 106.5625, 105.8750, 100.6250, 104.6250,  99.7500, 102.0000,
        103.0000,  98.7500,  93.7500,  92.1250,  88.0625, 107.8750,  97.1250,
         87.6875,  92.2500,  89.7500,  95.5625,  84.8125,  89.6875],
       device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [2.62521356e-02 7.67199874e-01 1.25241935e-01 2.57366890e-04
 4.02589561e-03 4.47236598e-05 2.91634875e-04 6.99595723e-04
 5.68597534e-06 5.23660226e-08 5.51933788e-09 1.70007581e-08
 7.59630799e-02 4.15994828e-06 1.79186654e-09 8.19142429e-07
 1.25619550e-07 1.28135425e-05 1.23153066e-09 1.08682208e-09]
parser result:  [4.20918688e-02 1.77213401e-01 8.91084895e-02 4.67598409e-04
 2.55300105e-02 1.94924054e-04 1.84938789e-03 5.02715679e-03
 7.17085495e-05 4.83168378e-07 9.51414876e-08 1.63699976e-09
 6.58427656e-01 1.41202490e-05 1.12509246e-09 1.07809434e-07
 8.84953710e-09 2.95976520e-06 6.34733724e-11 8.31337221e-09]
clip * parser result:  [1.1050014e-03 1.3595811e-01 1.1160119e-02 1.2034435e-07 1.0278116e-04
 8.7177172e-09 5.3934599e-07 3.5169774e-06 4.0773304e-10 2.5301606e-14
 5.2511802e-16 2.7830237e-17 5.0016191e-02 5.8739506e-11 2.0160155e-18
 8.8311282e-14 1.1116748e-15 3.7925076e-11 7.8169402e-20 9.0351565e-18]
CLIP result after softmax:  [1.1050014e-03 1.3595811e-01 1.1160119e-02 1.2034435e-07 1.0278116e-04
 8.7177172e-09 5.3934599e-07 3.5169774e-06 4.0773304e-10 2.5301606e-14
 5.2511802e-16 2.7830237e-17 5.0016191e-02 5.8739506e-11 2.0160155e-18
 8.8311282e-14 1.1116748e-15 3.7925076e-11 7.8169402e-20 9.0351565e-18]
predicts:  1
The Final Result:  {'probs': array([1.1050014e-03, 1.3595811e-01, 1.1160119e-02, 1.2034435e-07,
       1.0278116e-04, 8.7177172e-09, 5.3934599e-07, 3.5169774e-06,
       4.0773304e-10, 2.5301606e-14, 5.2511802e-16, 2.7830237e-17,
       5.0016191e-02, 5.8739506e-11, 2.0160155e-18, 8.8311282e-14,
       1.1116748e-15, 3.7925076e-11, 7.8169402e-20, 9.0351565e-18],
      dtype=float32), 'pred': 1, 'box': Box(x=276.66, y=4.22, w=204.93, h=250.02), 'texts': (['a chair closest to the donuts'], [([0.042091868817806244, 0.1772134006023407, 0.08910848945379257, 0.000467598409159109, 0.02553001046180725, 0.00019492405408527702, 0.0018493878887966275, 0.005027156788855791, 7.170854951255023e-05, 4.831683781958418e-07, 9.514148757716612e-08, 1.636999757970159e-09, 0.6584276556968689, 1.4120249034021981e-05, 1.1250924636385662e-09, 1.0780943426880185e-07, 8.8495371031172e-09, 2.9597651973745087e-06, 6.347337239143158e-11, 8.313372212853665e-09], [0.042091868817806244, 0.1772134006023407, 0.08910848945379257, 0.000467598409159109, 0.02553001046180725, 0.00019492405408527702, 0.0018493878887966275, 0.005027156788855791, 7.170854951255023e-05, 4.831683781958418e-07, 9.514148757716612e-08, 1.636999757970159e-09, 0.6584276556968689, 1.4120249034021981e-05, 1.1250924636385662e-09, 1.0780943426880185e-07, 8.8495371031172e-09, 2.9597651973745087e-06, 6.347337239143158e-11, 8.313372212853665e-09])], ('a chair', 'a chair', 'the donuts', 'the donuts'))}
a chair closest to the donuts.
This is the original CLIP result:
tensor([103.6250, 105.6250, 103.6250, 100.7500, 105.6250, 100.6875, 103.3750,
        103.2500,  98.2500,  93.8750,  92.6875,  87.5625, 108.0000,  97.3125,
         86.8750,  92.0625,  90.0000,  96.1875,  85.1875,  89.3750],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.02248890e-02 7.55522773e-02 1.02248890e-02 5.76848746e-04
 7.55522773e-02 5.41899295e-04 7.96315167e-03 7.02745607e-03
 4.73506298e-05 5.96056509e-07 1.81786959e-07 1.08094467e-09
 8.12263548e-01 1.85427725e-05 5.43533163e-10 9.73035483e-08
 1.23707569e-08 6.01995725e-06 1.00543525e-10 6.62158905e-09]
predicts:  12
The Final Result:  {'probs': array([1.02248890e-02, 7.55522773e-02, 1.02248890e-02, 5.76848746e-04,
       7.55522773e-02, 5.41899295e-04, 7.96315167e-03, 7.02745607e-03,
       4.73506298e-05, 5.96056509e-07, 1.81786959e-07, 1.08094467e-09,
       8.12263548e-01, 1.85427725e-05, 5.43533163e-10, 9.73035483e-08,
       1.23707569e-08, 6.01995725e-06, 1.00543525e-10, 6.62158905e-09],
      dtype=float32), 'pred': 12, 'box': Box(x=140.92, y=258.82, w=26.5, h=22.02), 'texts': ['a chair nearest to some donuts']}
a chair nearest to some donuts
  1%|█▋                                                                                                                                                                                                                 | 39/5023 [00:35<2:05:43,  1.51s/it]This is the original CLIP result:
tensor([138.5000, 108.0000,  92.0625, 110.2500, 123.0000], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [9.9999976e-01 5.6756839e-14 6.7990757e-21 5.3849389e-13 1.8553911e-07]
predicts:  0
The Final Result:  {'probs': array([9.9999976e-01, 5.6756839e-14, 6.7990757e-21, 5.3849389e-13,
       1.8553911e-07], dtype=float32), 'pred': 0, 'box': Box(x=356.15, y=75.63, w=224.03, h=219.25), 'texts': ['white apple computer monitor displaying two web pages']}
white apple computer monitor displaying two web pages
predicate correct
This is the original CLIP result:
tensor([131.2500,  99.6250,  79.1250, 102.6250, 109.1250], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.0000000e+00 1.8426251e-14 2.3035633e-23 3.7010117e-13 2.4616970e-10]
predicts:  0
The Final Result:  {'probs': array([1.0000000e+00, 1.8426251e-14, 2.3035633e-23, 3.7010117e-13,
       2.4616970e-10], dtype=float32), 'pred': 0, 'box': Box(x=356.15, y=75.63, w=224.03, h=219.25), 'texts': ['an imac computer beside a computer monitor.']}
an imac computer beside a computer monitor.
predicate correct
  1%|█▋                                                                                                                                                                                                                 | 40/5023 [00:36<1:39:57,  1.20s/it]This is the original CLIP result:
tensor([104.8750, 103.7500,  87.0625,  83.6875,  83.8125,  82.4375,  90.0625,
         90.8750, 103.8125], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([103.3125, 101.0000,  85.6250,  83.6875,  83.2500,  81.8125,  89.5000,
         90.2500, 102.8750], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([103.3125, 101.0000,  85.6250,  83.6875,  83.2500,  81.8125,  89.5000,
         90.2500, 102.8750], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 91.8750,  89.3750,  96.0000,  91.6250,  94.8750,  94.6250,  94.6875,
         99.1250, 103.7500], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [5.9871477e-01 1.9437423e-01 1.0998906e-08 3.7636189e-10 4.2647388e-10
 1.0782948e-10 2.2091895e-07 4.9784853e-07 2.0691030e-01]
parser result:  [6.27193257e-07 1.11612305e-12 0.00000000e+00 4.88458593e-07
 2.72859960e-10 2.12457980e-10 1.15919095e-04 1.85673227e-10
 9.99882965e-01]
clip * parser result:  [3.75509866e-07 2.16945563e-13 0.00000000e+00 1.83837197e-16
 1.16367647e-19 2.29092339e-20 2.56087245e-11 9.24371437e-17
 2.06886081e-01]
CLIP result after softmax:  [3.75509866e-07 2.16945563e-13 0.00000000e+00 1.83837197e-16
 1.16367647e-19 2.29092339e-20 2.56087245e-11 9.24371437e-17
 2.06886081e-01]
predicts:  8
The Final Result:  {'probs': array([3.75509866e-07, 2.16945563e-13, 0.00000000e+00, 1.83837197e-16,
       1.16367647e-19, 2.29092339e-20, 2.56087245e-11, 9.24371437e-17,
       2.06886081e-01]), 'pred': 8, 'box': Box(x=337.36, y=0.12, w=229.46, h=184.81), 'texts': (['couch', 'the person'], [([6.889196356496541e-06, 5.654997039528098e-07, 0.0004262194852344692, 5.365311608329648e-06, 0.00013837321603205055, 0.0001077651686500758, 0.00011471541074570268, 0.009700711816549301, 0.9894994497299194], [6.889196356496541e-06, 5.654997039528098e-07, 0.0004262194852344692, 5.365311608329648e-06, 0.00013837321603205055, 0.0001077651686500758, 0.00011471541074570268, 0.009700711816549301, 0.9894994497299194]), ([6.271932571258365e-07, 1.1161230526867325e-12, 0.0, 4.884585932913717e-07, 2.7285996033887243e-10, 2.1245798035976663e-10, 0.00011591909457694872, 1.8567322736805218e-10, 0.9998829645814654], [0.5731759071350098, 0.056752100586891174, 1.1931752474936275e-08, 1.7189318857191438e-09, 1.1098258978492481e-09, 2.636067752970206e-10, 5.749040496993985e-07, 1.2170719401183305e-06, 0.37007012963294983])], ('couch', 'the person', 'the person', 'headphones'))}
couch behind the person wearing headphones.
predicate correct
This is the original CLIP result:
tensor([89.8750, 79.9375, 80.5625, 78.9375, 80.3750, 81.0000, 81.8750, 87.8750,
        96.3750], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.5008758e-03 7.2534284e-08 1.3551190e-07 2.6683873e-08 1.1234330e-07
 2.0988492e-07 5.0348768e-07 2.0312144e-04 9.9829501e-01]
predicts:  8
The Final Result:  {'probs': array([1.5008758e-03, 7.2534284e-08, 1.3551190e-07, 2.6683873e-08,
       1.1234330e-07, 2.0988492e-07, 5.0348768e-07, 2.0312144e-04,
       9.9829501e-01], dtype=float32), 'pred': 8, 'box': Box(x=337.36, y=0.12, w=229.46, h=184.81), 'texts': ['an ugly couch with someone sitting on it']}
an ugly couch with someone sitting on it
predicate correct
  1%|█▋                                                                                                                                                                                                                 | 41/5023 [00:38<2:01:35,  1.46s/it]This is the original CLIP result:
tensor([ 82.0000,  97.3750, 113.8125, 110.2500, 109.4375,  95.7500, 107.1250,
        121.0000, 121.8750, 108.6250,  99.3750,  90.0000,  86.2500, 107.6875,
        112.6875, 111.7500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.3965258e-18 1.6155211e-11 2.2234539e-04 6.3074526e-06 2.7989151e-06
 3.1811496e-12 2.7713017e-07 2.9411674e-01 7.0554936e-01 1.2420112e-06
 1.1937175e-10 1.0124902e-14 2.3811486e-16 4.8637855e-07 7.2184979e-05
 2.8268043e-05]
predicts:  8
The Final Result:  {'probs': array([3.3965258e-18, 1.6155211e-11, 2.2234539e-04, 6.3074526e-06,
       2.7989151e-06, 3.1811496e-12, 2.7713017e-07, 2.9411674e-01,
       7.0554936e-01, 1.2420112e-06, 1.1937175e-10, 1.0124902e-14,
       2.3811486e-16, 4.8637855e-07, 7.2184979e-05, 2.8268043e-05],
      dtype=float32), 'pred': 8, 'box': Box(x=320.93, y=3.77, w=317.11, h=415.5), 'texts': ['a lady pouring wine in a glass']}
a lady pouring wine in a glass
This is the original CLIP result:
tensor([ 88.3125, 105.6875, 118.6875, 116.2500, 116.9375,  99.1875, 111.2500,
        127.8750, 122.8750, 101.7500,  96.6875,  90.8750,  87.5000, 104.3750,
        111.0625, 110.6250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [6.5351028e-18 2.2967780e-10 1.0161254e-04 8.8788038e-06 1.7657614e-05
 3.4530663e-13 5.9824920e-08 9.9317980e-01 6.6919927e-03 4.4780048e-12
 2.8344496e-14 8.4748512e-17 2.8999343e-18 6.1816940e-11 4.9596601e-08
 3.2021973e-08]
predicts:  7
The Final Result:  {'probs': array([6.5351028e-18, 2.2967780e-10, 1.0161254e-04, 8.8788038e-06,
       1.7657614e-05, 3.4530663e-13, 5.9824920e-08, 9.9317980e-01,
       6.6919927e-03, 4.4780048e-12, 2.8344496e-14, 8.4748512e-17,
       2.8999343e-18, 6.1816940e-11, 4.9596601e-08, 3.2021973e-08],
      dtype=float32), 'pred': 7, 'box': Box(x=0.96, y=67.97, w=190.5, h=272.83), 'texts': ['woman pouring wine from a bottle']}
woman pouring wine from a bottle
predicate correct
  1%|█▊                                                                                                                                                                                                                 | 42/5023 [00:39<1:59:00,  1.43s/it]This is the original CLIP result:
tensor([ 84.1250,  93.1875,  99.8750, 105.8750, 104.6250,  95.2500,  96.6250,
         94.0000,  98.8125,  94.1250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.7765951e-10 2.3950042e-06 1.9215452e-03 7.7520674e-01 2.2210042e-01
 1.8838167e-05 7.4506395e-05 5.3972253e-06 6.6406827e-04 6.1158571e-06]
predicts:  3
The Final Result:  {'probs': array([2.7765951e-10, 2.3950042e-06, 1.9215452e-03, 7.7520674e-01,
       2.2210042e-01, 1.8838167e-05, 7.4506395e-05, 5.3972253e-06,
       6.6406827e-04, 6.1158571e-06], dtype=float32), 'pred': 3, 'box': Box(x=94.92, y=124.04, w=66.88, h=273.98), 'texts': ['the man with glasses in the grey sirt']}
the man with glasses in the grey sirt
predicate correct
This is the original CLIP result:
tensor([ 84.3750,  94.3750, 109.1250, 107.2500, 103.5000,  93.1250,  90.8750,
         90.0000,  95.5625,  87.7500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.54131707e-11 3.39497660e-07 8.64331603e-01 1.32549539e-01
 3.11726658e-03 9.72677086e-08 1.02519415e-08 4.27364455e-09
 1.11317001e-06 4.50438853e-10]
predicts:  2
The Final Result:  {'probs': array([1.54131707e-11, 3.39497660e-07, 8.64331603e-01, 1.32549539e-01,
       3.11726658e-03, 9.72677086e-08, 1.02519415e-08, 4.27364455e-09,
       1.11317001e-06, 4.50438853e-10], dtype=float32), 'pred': 2, 'box': Box(x=140.86, y=115.67, w=214.54, h=358.64), 'texts': ['the far most man waring a gray t-shirt']}
the far most man waring a gray t-shirt
  1%|█▊                                                                                                                                                                                                                 | 43/5023 [00:40<1:46:04,  1.28s/it]This is the original CLIP result:
tensor([110.3750, 112.7500, 108.7500, 107.0000, 112.7500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([108.0000, 108.0000, 102.7500, 101.5000, 104.9375], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [0.04398861 0.47292215 0.00866187 0.00150521 0.47292215]
parser result:  [0.48696834 0.48696834 0.00255538 0.00073213 0.02277581]
clip * parser result:  [2.1421062e-02 2.3029812e-01 2.2134333e-05 1.1020034e-06 1.0771186e-02]
CLIP result after softmax:  [2.1421062e-02 2.3029812e-01 2.2134333e-05 1.1020034e-06 1.0771186e-02]
predicts:  1
The Final Result:  {'probs': array([2.1421062e-02, 2.3029812e-01, 2.2134333e-05, 1.1020034e-06,
       1.0771186e-02], dtype=float32), 'pred': 1, 'box': Box(x=48.2, y=182.67, w=136.88, h=135.92), 'texts': (['a yellow vehicle'], [([0.48696833848953247, 0.48696833848953247, 0.0025553752202540636, 0.000732127227820456, 0.022775812074542046], [0.48696833848953247, 0.48696833848953247, 0.0025553752202540636, 0.000732127227820456, 0.022775812074542046])], ('a yellow vehicle', 'a yellow vehicle', 'a yellow vehicle'))}
a yellow vehicle with the back window open.
predicate correct
This is the original CLIP result:
tensor([ 98.6250, 105.6250,  91.8750,  90.1875,  93.2500], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [9.1104611e-04 9.9908340e-01 1.0667254e-06 1.9732435e-07 4.2189804e-06]
predicts:  1
The Final Result:  {'probs': array([9.1104611e-04, 9.9908340e-01, 1.0667254e-06, 1.9732435e-07,
       4.2189804e-06], dtype=float32), 'pred': 1, 'box': Box(x=48.2, y=182.67, w=136.88, h=135.92), 'texts': ['yellow vehical with hatch open']}
yellow vehical with hatch open
predicate correct
  1%|█▊                                                                                                                                                                                                                 | 44/5023 [00:41<1:32:27,  1.11s/it]This is the original CLIP result:
tensor([106.5000,  97.8125,  92.6250, 113.0000], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.5011819e-03 2.5322117e-07 1.4144818e-09 9.9849856e-01]
predicts:  3
The Final Result:  {'probs': array([1.5011819e-03, 2.5322117e-07, 1.4144818e-09, 9.9849856e-01],
      dtype=float32), 'pred': 3, 'box': Box(x=329.79, y=179.21, w=98.21, h=171.85), 'texts': ['male tennis player']}
male tennis player
predicate correct
This is the original CLIP result:
tensor([101.1250,  85.3125,  94.6250, 101.1250], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [4.9962440e-01 6.7820686e-08 7.5115490e-04 4.9962440e-01]
predicts:  0
The Final Result:  {'probs': array([4.9962440e-01, 6.7820686e-08, 7.5115490e-04, 4.9962440e-01],
      dtype=float32), 'pred': 0, 'box': Box(x=188.4, y=158.3, w=138.07, h=274.69), 'texts': ['the woman in a white shirt and black pants']}
the woman in a white shirt and black pants
  1%|█▉                                                                                                                                                                                                                 | 45/5023 [00:41<1:14:49,  1.11it/s]This is the original CLIP result:
tensor([ 79.8750,  85.7500, 131.0000,  82.0625, 104.3750,  87.1250,  88.4375],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [6.2617343e-23 2.2293316e-20 1.0000000e+00 5.5810225e-22 2.7346981e-12
 8.8171779e-20 3.2759788e-19]
predicts:  2
The Final Result:  {'probs': array([6.2617343e-23, 2.2293316e-20, 1.0000000e+00, 5.5810225e-22,
       2.7346981e-12, 8.8171779e-20, 3.2759788e-19], dtype=float32), 'pred': 2, 'box': Box(x=132.31, y=52.97, w=247.38, h=581.04), 'texts': ['this is a woman holding a thing of bananas.']}
this is a woman holding a thing of bananas.
predicate correct
This is the original CLIP result:
tensor([ 74.6250,  88.8750, 135.7500,  86.0000,  93.2500,  84.3750,  88.5000],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 75.1250,  88.6875, 137.0000,  85.5000,  93.6250,  85.4375,  88.3750],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 75.1250,  88.6875, 137.0000,  85.5000,  93.6250,  85.4375,  88.3750],
       device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [2.8428226e-27 4.3898144e-21 1.0000000e+00 2.4765638e-22 3.4872614e-19
 4.8766431e-23 3.0170724e-21]
parser result:  [1.3428544e-27 1.0426723e-21 1.0000000e+00 4.3036228e-23 1.4537069e-19
 4.0428793e-23 7.6283536e-22]
clip * parser result:  [0.0000000e+00 4.5766408e-42 1.0000000e+00 1.1210388e-44 5.0694556e-38
 1.4012985e-45 2.3009321e-42]
CLIP result after softmax:  [0.0000000e+00 4.5766408e-42 1.0000000e+00 1.1210388e-44 5.0694556e-38
 1.4012985e-45 2.3009321e-42]
predicts:  2
The Final Result:  {'probs': array([0.0000000e+00, 4.5766408e-42, 1.0000000e+00, 1.1210388e-44,
       5.0694556e-38, 1.4012985e-45, 2.3009321e-42], dtype=float32), 'pred': 2, 'box': Box(x=132.31, y=52.97, w=247.38, h=581.04), 'texts': (['the long - haired woman displaying bananas wearing paisley pants and black top'], [([1.3428543648345085e-27, 1.0426722692846369e-21, 1.0, 4.3036227798241777e-23, 1.453706854040239e-19, 4.0428793226440283e-23, 7.628353615940375e-22], [1.3428543648345085e-27, 1.0426722692846369e-21, 1.0, 4.3036227798241777e-23, 1.453706854040239e-19, 4.0428793226440283e-23, 7.628353615940375e-22])], ('the long-haired woman', 'the long-haired woman', 'the long-haired woman', 'the long-haired woman', 'the long-haired woman', 'bananas', 'paisley pants', 'paisley pants', 'black top', 'black top'))}
the long-haired woman displaying bananas wearing paisley pants and black top.
predicate correct
  1%|█▉                                                                                                                                                                                                                 | 46/5023 [00:42<1:26:33,  1.04s/it]This is the original CLIP result:
tensor([126.1875, 132.3750, 128.0000,  87.4375,  86.8125,  89.0000,  88.0000,
        108.2500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.0253011e-03 9.8556823e-01 1.2406474e-02 3.0031597e-20 1.6074754e-20
 1.4327274e-19 5.2707089e-20 3.2834645e-11]
predicts:  1
The Final Result:  {'probs': array([2.0253011e-03, 9.8556823e-01, 1.2406474e-02, 3.0031597e-20,
       1.6074754e-20, 1.4327274e-19, 5.2707089e-20, 3.2834645e-11],
      dtype=float32), 'pred': 1, 'box': Box(x=350.18, y=261.59, w=289.82, h=218.41), 'texts': ['the industrial kitchen stove.']}
the industrial kitchen stove.
predicate correct
This is the original CLIP result:
tensor([116.6875, 120.4375, 115.5000,  90.8750,  92.5625,  92.0000,  91.2500,
        107.8750], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.2817394e-02 9.7022027e-01 6.9589117e-03 1.4061761e-13 7.6017160e-13
 4.3313272e-13 2.0459743e-13 3.3966116e-06]
predicts:  1
The Final Result:  {'probs': array([2.2817394e-02, 9.7022027e-01, 6.9589117e-03, 1.4061761e-13,
       7.6017160e-13, 4.3313272e-13, 2.0459743e-13, 3.3966116e-06],
      dtype=float32), 'pred': 1, 'box': Box(x=350.18, y=261.59, w=289.82, h=218.41), 'texts': ['this is a stove with four burners']}
this is a stove with four burners
predicate correct
  1%|█▉                                                                                                                                                                                                                 | 47/5023 [00:43<1:18:47,  1.05it/s]This is the original CLIP result:
tensor([ 74.8125, 110.1250, 102.1250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [4.6113749e-16 9.9966466e-01 3.3535014e-04]
predicts:  1
The Final Result:  {'probs': array([4.6113749e-16, 9.9966466e-01, 3.3535014e-04], dtype=float32), 'pred': 1, 'box': Box(x=134.53, y=157.26, w=402.51, h=315.33), 'texts': ['a man with beard wearing blue shirt with his friend']}
a man with beard wearing blue shirt with his friend
predicate correct
This is the original CLIP result:
tensor([89.2500, 91.7500, 92.5000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.0256589  0.31258935 0.6617517 ]
predicts:  2
The Final Result:  {'probs': array([0.0256589 , 0.31258935, 0.6617517 ], dtype=float32), 'pred': 2, 'box': Box(x=371.65, y=127.58, w=268.35, h=346.73), 'texts': ['a man with a beard']}
a man with a beard
  1%|██                                                                                                                                                                                                                 | 48/5023 [00:43<1:03:27,  1.31it/s]This is the original CLIP result:
tensor([ 95.5000,  95.0000,  89.7500,  97.3125, 120.1250, 120.7500,  88.6875,
        112.0000,  95.1250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [7.0442896e-12 4.2725771e-12 2.2420428e-14 4.3151503e-11 3.4860915e-01
 6.5128767e-01 7.7482932e-15 1.0320391e-04 4.8414645e-12]
predicts:  5
The Final Result:  {'probs': array([7.0442896e-12, 4.2725771e-12, 2.2420428e-14, 4.3151503e-11,
       3.4860915e-01, 6.5128767e-01, 7.7482932e-15, 1.0320391e-04,
       4.8414645e-12], dtype=float32), 'pred': 5, 'box': Box(x=375.3, y=117.24, w=104.67, h=339.48), 'texts': ['brown and colorful luggage']}
brown and colorful luggage
  1%|██                                                                                                                                                                                                                   | 49/5023 [00:44<55:09,  1.50it/s]This is the original CLIP result:
tensor([ 68.8750,  69.9375, 139.5000,  84.4375,  65.3750,  71.5000, 101.0625,
         67.8125,  68.8750,  72.7500,  62.8125], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [2.1279048e-31 6.1572968e-31 1.0000000e+00 1.2208438e-24 6.4257157e-33
 2.9374820e-30 2.0267763e-17 7.3538421e-32 2.1279048e-31 1.0252820e-29
 4.9549801e-34]
predicts:  2
The Final Result:  {'probs': array([2.1279048e-31, 6.1572968e-31, 1.0000000e+00, 1.2208438e-24,
       6.4257157e-33, 2.9374820e-30, 2.0267763e-17, 7.3538421e-32,
       2.1279048e-31, 1.0252820e-29, 4.9549801e-34], dtype=float32), 'pred': 2, 'box': Box(x=3.1, y=114.58, w=394.32, h=360.26), 'texts': ['a younf woman wearing a green shirt eating a piece of pizza with her legs up.']}
a younf woman wearing a green shirt eating a piece of pizza with her legs up.
predicate correct
This is the original CLIP result:
tensor([ 75.8125,  73.8750, 131.0000,  90.4375,  70.0000,  72.2500,  95.2500,
         72.7500,  76.0000,  73.3750,  66.4375], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.0773908e-24 1.5521287e-25 1.0000000e+00 2.4206390e-18 3.2213403e-27
 3.0563223e-26 2.9783261e-16 5.0390238e-26 1.2995815e-24 9.4141360e-26
 9.1382391e-29]
predicts:  2
The Final Result:  {'probs': array([1.0773908e-24, 1.5521287e-25, 1.0000000e+00, 2.4206390e-18,
       3.2213403e-27, 3.0563223e-26, 2.9783261e-16, 5.0390238e-26,
       1.2995815e-24, 9.4141360e-26, 9.1382391e-29], dtype=float32), 'pred': 2, 'box': Box(x=3.1, y=114.58, w=394.32, h=360.26), 'texts': ['a women wearing green t-shirt and a black pants holding a piece of pizza.']}
a women wearing green t-shirt and a black pants holding a piece of pizza.
predicate correct
  1%|██                                                                                                                                                                                                                 | 50/5023 [00:45<1:03:35,  1.30it/s]This is the original CLIP result:
tensor([ 96.6250, 116.6875, 107.0000,  98.8750,  92.5000, 127.1250, 105.2500,
         94.7500, 112.2500,  91.6250,  93.0000, 101.8750,  94.2500,  97.7500,
         91.2500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [5.6755168e-14 2.9311528e-05 1.8189077e-09 5.3847801e-13 9.1736188e-16
 9.9997032e-01 3.1607875e-10 8.7036870e-15 3.4662247e-07 3.8241330e-16
 1.5124740e-15 1.0815621e-11 5.2790528e-15 1.7481821e-13 2.6282855e-16]
predicts:  5
The Final Result:  {'probs': array([5.6755168e-14, 2.9311528e-05, 1.8189077e-09, 5.3847801e-13,
       9.1736188e-16, 9.9997032e-01, 3.1607875e-10, 8.7036870e-15,
       3.4662247e-07, 3.8241330e-16, 1.5124740e-15, 1.0815621e-11,
       5.2790528e-15, 1.7481821e-13, 2.6282855e-16], dtype=float32), 'pred': 5, 'box': Box(x=37.37, y=138.56, w=148.46, h=169.88), 'texts': ['the fork between the bread plate and dinner plate.']}
the fork between the bread plate and dinner plate.
predicate correct
This is the original CLIP result:
tensor([101.1250, 100.5000, 101.9375, 103.0000,  93.5000, 115.5625, 106.8750,
        100.0000, 109.4375,  98.8750,  97.2500,  97.1250, 100.0625,  92.8125,
         92.9375], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [5.3561013e-07 2.8669140e-07 1.2070160e-06 3.4926165e-06 2.6142874e-10
 9.9764341e-01 1.6828367e-04 1.7388713e-07 2.1823363e-03 5.6452890e-08
 1.1116232e-08 9.8100408e-09 1.8510191e-07 1.3145461e-10 1.4895761e-10]
predicts:  5
The Final Result:  {'probs': array([5.3561013e-07, 2.8669140e-07, 1.2070160e-06, 3.4926165e-06,
       2.6142874e-10, 9.9764341e-01, 1.6828367e-04, 1.7388713e-07,
       2.1823363e-03, 5.6452890e-08, 1.1116232e-08, 9.8100408e-09,
       1.8510191e-07, 1.3145461e-10, 1.4895761e-10], dtype=float32), 'pred': 5, 'box': Box(x=37.37, y=138.56, w=148.46, h=169.88), 'texts': ['a somewhat vertical fork near a horizontal fork.']}
a somewhat vertical fork near a horizontal fork.
predicate correct
  1%|██▏                                                                                                                                                                                                                | 51/5023 [00:46<1:16:20,  1.09it/s]This is the original CLIP result:
tensor([117.4375,  93.3125,  97.1250,  82.5000, 100.8750, 103.9375, 122.6250,
        121.5000, 108.1250,  88.1250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [4.1992115e-03 1.3989859e-13 6.3322941e-12 2.8184105e-18 2.6925598e-10
 5.7569469e-09 7.5174463e-01 2.4405575e-01 3.7914063e-07 7.8146704e-16]
predicts:  6
The Final Result:  {'probs': array([4.1992115e-03, 1.3989859e-13, 6.3322941e-12, 2.8184105e-18,
       2.6925598e-10, 5.7569469e-09, 7.5174463e-01, 2.4405575e-01,
       3.7914063e-07, 7.8146704e-16], dtype=float32), 'pred': 6, 'box': Box(x=155.91, y=183.81, w=164.49, h=102.81), 'texts': ['brown bread vegetable sandwich with tooth pick next to white bowl']}
brown bread vegetable sandwich with tooth pick next to white bowl
predicate correct
This is the original CLIP result:
tensor([114.8750,  89.9375,  90.0000,  86.5625,  92.8750, 101.7500, 118.2500,
        114.5625, 111.1875,  90.3750], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.2277916e-02 4.7718513e-13 5.0796086e-13 1.6328376e-14 9.0038220e-12
 6.4385851e-08 9.4329900e-01 2.3615029e-02 8.0806180e-04 7.3907867e-13]
predicts:  6
The Final Result:  {'probs': array([3.2277916e-02, 4.7718513e-13, 5.0796086e-13, 1.6328376e-14,
       9.0038220e-12, 6.4385851e-08, 9.4329900e-01, 2.3615029e-02,
       8.0806180e-04, 7.3907867e-13], dtype=float32), 'pred': 6, 'box': Box(x=155.91, y=183.81, w=164.49, h=102.81), 'texts': ['the sandwich in the plate of the man in black']}
the sandwich in the plate of the man in black
predicate correct
  1%|██▏                                                                                                                                                                                                                | 52/5023 [00:47<1:16:10,  1.09it/s]This is the original CLIP result:
tensor([134.8750, 121.8750, 115.2500,  94.1250,  63.1562,  58.1562, 101.8125,
         89.7500,  64.5000,  56.7500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9999774e-01 2.2603242e-06 2.9989538e-09 2.0067757e-18 7.1275724e-32
 4.8025203e-34 4.3766087e-15 2.5261581e-20 2.7322779e-31 1.1769083e-34]
predicts:  0
The Final Result:  {'probs': array([9.9999774e-01, 2.2603242e-06, 2.9989538e-09, 2.0067757e-18,
       7.1275724e-32, 4.8025203e-34, 4.3766087e-15, 2.5261581e-20,
       2.7322779e-31, 1.1769083e-34], dtype=float32), 'pred': 0, 'box': Box(x=51.34, y=21.24, w=280.88, h=344.3), 'texts': ['a us army officer, named wilkins, cutting a cake with two other officers.']}
a us army officer, named wilkins, cutting a cake with two other officers.
This is the original CLIP result:
tensor([124.8750, 117.6250, 118.1875,  99.8750,  75.5000,  69.9375, 106.0625,
        101.8125,  70.6875,  68.0000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9804723e-01 7.0878753e-04 1.2439610e-03 1.3860823e-11 3.5963421e-22
 1.3806957e-24 6.7450645e-09 9.6213183e-11 2.9229330e-24 1.9890810e-25]
predicts:  0
The Final Result:  {'probs': array([9.9804723e-01, 7.0878753e-04, 1.2439610e-03, 1.3860823e-11,
       3.5963421e-22, 1.3806957e-24, 6.7450645e-09, 9.6213183e-11,
       2.9229330e-24, 1.9890810e-25], dtype=float32), 'pred': 0, 'box': Box(x=51.34, y=21.24, w=280.88, h=344.3), 'texts': ['a military man is cutting a cake with military men on both sides of him.']}
a military man is cutting a cake with military men on both sides of him.
  1%|██▏                                                                                                                                                                                                                | 53/5023 [00:48<1:15:15,  1.10it/s]This is the original CLIP result:
tensor([100.0000,  86.0000,  84.7500,  84.8750,  87.2500,  99.6250,  80.9375,
         83.2500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [5.9266514e-01 4.9281806e-07 1.4119473e-07 1.5999458e-07 1.7201040e-06
 4.0733236e-01 3.1193979e-09 3.1504804e-08]
predicts:  0
The Final Result:  {'probs': array([5.9266514e-01, 4.9281806e-07, 1.4119473e-07, 1.5999458e-07,
       1.7201040e-06, 4.0733236e-01, 3.1193979e-09, 3.1504804e-08],
      dtype=float32), 'pred': 0, 'box': Box(x=69.66, y=84.27, w=143.82, h=391.01), 'texts': ["the yellow lights that face away and the bulbs can't be seen."]}
the yellow lights that face away and the bulbs can't be seen.
This is the original CLIP result:
tensor([115.2500,  86.6875,  83.5625,  86.2500,  85.6250, 116.3750,  79.2500,
         87.3750], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.4508502e-01 9.6556308e-14 4.2423878e-15 6.2341435e-14 3.3368965e-14
 7.5491500e-01 5.6848027e-17 1.9202513e-13]
predicts:  5
The Final Result:  {'probs': array([2.4508502e-01, 9.6556308e-14, 4.2423878e-15, 6.2341435e-14,
       3.3368965e-14, 7.5491500e-01, 5.6848027e-17, 1.9202513e-13],
      dtype=float32), 'pred': 5, 'box': Box(x=1.13, y=202.7, w=119.37, h=291.67), 'texts': ['the side of a traffic light, with the actual lights not visible.']}
the side of a traffic light, with the actual lights not visible.
predicate correct
  1%|██▎                                                                                                                                                                                                                | 54/5023 [00:49<1:09:58,  1.18it/s]This is the original CLIP result:
tensor([ 96.8750, 114.0000, 112.2500, 114.2500, 113.0625,  91.1250],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([102.5000, 113.2500, 113.0000, 112.5000, 111.1875,  92.0625],
       device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.2821912e-08 3.5095045e-01 6.0986046e-02 4.5062932e-01 1.3743417e-01
 4.0809335e-11]
parser result:  [2.67693475e-05 6.67273492e-02 6.53803939e-01 2.79441943e-01
 4.19459008e-11 0.00000000e+00]
clip * parser result:  [3.43234229e-13 2.34179932e-02 3.98729169e-02 1.25924734e-01
 5.76480005e-12 0.00000000e+00]
CLIP result after softmax:  [3.43234229e-13 2.34179932e-02 3.98729169e-02 1.25924734e-01
 5.76480005e-12 0.00000000e+00]
predicts:  3
The Final Result:  {'probs': array([3.43234229e-13, 2.34179932e-02, 3.98729169e-02, 1.25924734e-01,
       5.76480005e-12, 0.00000000e+00]), 'pred': 3, 'box': Box(x=323.85, y=134.2, w=181.9, h=195.2), 'texts': (['the right computer', 'sup:right'], [([9.017023330670781e-06, 0.42046406865119934, 0.3274577558040619, 0.19861315190792084, 0.053456004709005356, 2.643105734279061e-10], [9.017023330670781e-06, 0.42046406865119934, 0.3274577558040619, 0.19861315190792084, 0.053456004709005356, 2.643105734279061e-10]), ([2.676934750753658e-05, 0.06672734922316842, 0.6538039386688276, 0.27944194271855055, 4.194590083380666e-11, 0.0], None)], ('the right computer', 'the right computer', 'the right computer', 'the right hand picture', 'the right hand picture', 'the right hand picture', 'the right hand picture'))}
the right computer in the right hand picture
predicate correct
This is the original CLIP result:
tensor([ 94.7500, 116.0000, 110.9375, 116.3125, 117.1875,  93.1250],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([101.9375, 116.0625, 113.0625, 113.3750, 109.7500,  92.1250],
       device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.04480896e-10 1.76927209e-01 1.11989898e-03 2.41830841e-01
 5.80122054e-01 2.05735099e-11]
parser result:  [6.5540138e-07 8.9313453e-01 4.4466548e-02 6.0778566e-02 1.6196939e-03
 3.5891592e-11]
clip * parser result:  [6.8476923e-17 1.5801980e-01 4.9798040e-05 1.4698132e-02 9.3962019e-04
 7.3841601e-22]
CLIP result after softmax:  [6.8476923e-17 1.5801980e-01 4.9798040e-05 1.4698132e-02 9.3962019e-04
 7.3841601e-22]
predicts:  1
The Final Result:  {'probs': array([6.8476923e-17, 1.5801980e-01, 4.9798040e-05, 1.4698132e-02,
       9.3962019e-04, 7.3841601e-22], dtype=float32), 'pred': 1, 'box': Box(x=79.82, y=244.76, w=258.7, h=142.33), 'texts': (['the computer'], [([6.554013793902413e-07, 0.8931345343589783, 0.044466547667980194, 0.06077856570482254, 0.0016196939395740628, 3.589159178196688e-11], [6.554013793902413e-07, 0.8931345343589783, 0.044466547667980194, 0.06077856570482254, 0.0016196939395740628, 3.589159178196688e-11])], ('the computer', 'the computer', 'the right', 'the right', 'the right hand picture', 'the right hand picture', 'the right hand picture', 'the right hand picture'))}
the computer on the right in the right hand picture
  1%|██▎                                                                                                                                                                                                                | 55/5023 [00:50<1:19:18,  1.04it/s]This is the original CLIP result:
tensor([ 78.3750,  80.1250, 104.0000,  89.6250,  95.8750,  98.3750,  85.8750,
        107.2500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.7743573e-13 1.5965325e-12 3.7321448e-02 2.1329239e-08 1.1048818e-05
 1.3460217e-04 5.0161558e-10 9.6253288e-01]
predicts:  7
The Final Result:  {'probs': array([2.7743573e-13, 1.5965325e-12, 3.7321448e-02, 2.1329239e-08,
       1.1048818e-05, 1.3460217e-04, 5.0161558e-10, 9.6253288e-01],
      dtype=float32), 'pred': 7, 'box': Box(x=418.91, y=235.64, w=117.19, h=187.01), 'texts': ['the handle of some luggage.']}
the handle of some luggage.
This is the original CLIP result:
tensor([ 91.1875,  91.3750, 104.7500,  89.6250, 100.0000, 101.1875,  85.3750,
        105.3750], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [4.4329707e-07 5.3471831e-07 3.4420228e-01 9.2920104e-08 2.9779335e-03
 9.7642671e-03 1.3254341e-09 6.4305454e-01]
predicts:  7
The Final Result:  {'probs': array([4.4329707e-07, 5.3471831e-07, 3.4420228e-01, 9.2920104e-08,
       2.9779335e-03, 9.7642671e-03, 1.3254341e-09, 6.4305454e-01],
      dtype=float32), 'pred': 7, 'box': Box(x=418.91, y=235.64, w=117.19, h=187.01), 'texts': ["the handle to the man's luggage"]}
the handle to the man's luggage
  1%|██▎                                                                                                                                                                                                                | 56/5023 [00:51<1:17:15,  1.07it/s]This is the original CLIP result:
tensor([100.1250, 106.1250,  82.1875,  77.9375,  95.7500,  96.3125,  80.1250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.4724111e-03 9.9744189e-01 4.0083298e-11 5.7175754e-13 3.1123065e-05
 5.4622680e-05 5.0960195e-12]
predicts:  1
The Final Result:  {'probs': array([2.4724111e-03, 9.9744189e-01, 4.0083298e-11, 5.7175754e-13,
       3.1123065e-05, 5.4622680e-05, 5.0960195e-12], dtype=float32), 'pred': 1, 'box': Box(x=454.36, y=228.44, w=185.12, h=83.89), 'texts': ['a surfboard near a girl resting on some rocks']}
a surfboard near a girl resting on some rocks
predicate correct
This is the original CLIP result:
tensor([114.9375, 112.0000,  79.6250,  78.2500,  95.7500,  98.3125,  81.0625],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.4966936e-01 5.0330631e-02 4.3807506e-16 1.1076272e-16 4.4111013e-09
 5.7204037e-08 1.8443647e-15]
predicts:  0
The Final Result:  {'probs': array([9.4966936e-01, 5.0330631e-02, 4.3807506e-16, 1.1076272e-16,
       4.4111013e-09, 5.7204037e-08, 1.8443647e-15], dtype=float32), 'pred': 0, 'box': Box(x=1.92, y=330.88, w=195.75, h=50.86), 'texts': ['the surfboard leaning up against the hill']}
the surfboard leaning up against the hill
  1%|██▍                                                                                                                                                                                                                | 57/5023 [00:52<1:12:43,  1.14it/s]This is the original CLIP result:
tensor([79.4375, 79.0625, 88.6250], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([88.2500, 88.2500, 94.2500], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.0229266e-04 7.0304653e-05 9.9982738e-01]
parser result:  [0.         0.50061892 0.49938108]
clip * parser result:  [0.00000000e+00 3.51958398e-05 4.99294878e-01]
CLIP result after softmax:  [0.00000000e+00 3.51958398e-05 4.99294878e-01]
predicts:  2
The Final Result:  {'probs': array([0.00000000e+00, 3.51958398e-05, 4.99294878e-01]), 'pred': 2, 'box': Box(x=11.65, y=213.56, w=401.88, h=87.36), 'texts': (['the woman', 'sup:right'], [([0.0024665244854986668, 0.0024665244854986668, 0.9950670003890991], [0.0024665244854986668, 0.0024665244854986668, 0.9950670003890991]), ([0.0, 0.5006189209216519, 0.49938107907834806], None)], ('the woman', 'the woman', 'the right', 'the right'))}
the woman on the right.
This is the original CLIP result:
tensor([116.7500, 115.7500, 121.1250], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([117.2500, 115.8750, 119.3125], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([117.2500, 115.8750, 119.3125], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [0.01237506 0.00455253 0.9830724 ]
parser result:  [0.         0.22178053 0.77821947]
clip * parser result:  [0.         0.00100966 0.76504608]
CLIP result after softmax:  [0.         0.00100966 0.76504608]
predicts:  2
The Final Result:  {'probs': array([0.        , 0.00100966, 0.76504608]), 'pred': 2, 'box': Box(x=11.65, y=213.56, w=401.88, h=87.36), 'texts': (['the girl with the racket in the photo', 'sup:right'], [([0.10966777056455612, 0.027728358283638954, 0.8626039028167725], [0.10966777056455612, 0.027728358283638954, 0.8626039028167725]), ([0.0, 0.22178053264532518, 0.7782194673546748], None)], ('the girl', 'the girl', 'the racket', 'the racket', 'the photo', 'the photo', 'the right', 'the right'))}
the girl with the racket in the photo on the right
  1%|██▍                                                                                                                                                                                                                | 58/5023 [00:52<1:11:29,  1.16it/s]This is the original CLIP result:
tensor([109.8125, 104.8750], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([111.1250, 104.7500], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([111.1250, 104.7500], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [0.9928786  0.00712143]
parser result:  [0.9982993  0.00170072]
clip * parser result:  [9.9119002e-01 1.2111573e-05]
CLIP result after softmax:  [9.9119002e-01 1.2111573e-05]
predicts:  0
The Final Result:  {'probs': array([9.9119002e-01, 1.2111573e-05], dtype=float32), 'pred': 0, 'box': Box(x=35.58, y=207.42, w=159.27, h=61.85), 'texts': (['traffic light with red arrow pointing left'], [([0.9982993006706238, 0.0017007223796099424], [0.9982993006706238, 0.0017007223796099424])], ('traffic light', 'traffic light', 'red arrow pointing', 'red arrow pointing', 'red arrow pointing'))}
traffic light with red arrow pointing left.
predicate correct
This is the original CLIP result:
tensor([109.5625, 102.2500], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([104.7500, 106.5000], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([102.6250,  94.9375], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([102.6250,  94.9375], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [9.9933332e-01 6.6670234e-04]
parser result:  [9.9954176e-01 4.5831292e-04]
clip * parser result:  [9.988754e-01 3.055583e-07]
CLIP result after softmax:  [9.988754e-01 3.055583e-07]
predicts:  0
The Final Result:  {'probs': array([9.988754e-01, 3.055583e-07], dtype=float32), 'pred': 0, 'box': Box(x=35.58, y=207.42, w=159.27, h=61.85), 'texts': (['a picture with a red arrow pointing left lit up'], [([0.9995417594909668, 0.0004583129193633795], [0.9995417594909668, 0.0004583129193633795])], ('a picture', 'a picture', 'a traffic light', 'a traffic light', 'a traffic light', 'a red arrow pointing', 'a red arrow pointing', 'a red arrow pointing', 'a red arrow pointing'))}
a picture of a traffic light with a red arrow pointing left lit up.
predicate correct
  1%|██▍                                                                                                                                                                                                                | 59/5023 [00:53<1:09:45,  1.19it/s]This is the original CLIP result:
tensor([ 55.8125,  63.0625, 101.3750,  99.3125], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([63.4688, 69.3750, 92.5625, 93.8750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([60.1250, 78.2500, 96.0000, 98.3125], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.4470429e-20 2.0375884e-17 8.8720459e-01 1.1279540e-01]
parser result:  [2.62836351e-16 1.95556787e-08 9.99999980e-01 0.00000000e+00]
clip * parser result:  [3.80335487e-36 3.98464236e-25 8.87204570e-01 0.00000000e+00]
CLIP result after softmax:  [3.80335487e-36 3.98464236e-25 8.87204570e-01 0.00000000e+00]
predicts:  2
The Final Result:  {'probs': array([3.80335487e-36, 3.98464236e-25, 8.87204570e-01, 0.00000000e+00]), 'pred': 2, 'box': Box(x=435.81, y=0.0, w=185.72, h=198.74), 'texts': (['a plant', 'the blue sign'], [([2.367971428480655e-17, 1.7618296821453328e-09, 0.09009299427270889, 0.9099069833755493], [2.367971428480655e-17, 1.7618296821453328e-09, 0.09009299427270889, 0.9099069833755493]), ([2.6283635051036457e-16, 1.955567868371883e-08, 0.9999999804443211, 0.0], [4.9115855967844096e-14, 1.80415352796226e-11, 0.2120688110589981, 0.7879312038421631])], ('a plant', 'a plant', 'the right', 'the right', 'the blue sign', 'the blue sign', 'the blue sign'))}
a plant to the right of the blue sign.
predicate correct
This is the original CLIP result:
tensor([ 98.8125, 120.0625, 110.6250, 107.7500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 98.5000, 125.1250,  90.5000,  93.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 68.5000,  80.2500, 104.1250, 105.6250], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [5.9048072e-10 9.9991584e-01 7.9672645e-05 4.4948233e-06]
parser result:  [6.15665263e-17 0.00000000e+00 1.82425522e-01 8.17574478e-01]
clip * parser result:  [3.63538468e-26 0.00000000e+00 1.45343239e-05 3.67485283e-06]
CLIP result after softmax:  [3.63538468e-26 0.00000000e+00 1.45343239e-05 3.67485283e-06]
predicts:  2
The Final Result:  {'probs': array([3.63538468e-26, 0.00000000e+00, 1.45343239e-05, 3.67485283e-06]), 'pred': 2, 'box': Box(x=435.81, y=0.0, w=185.72, h=198.74), 'texts': (['a potted plant', 'a tennis racket'], [([6.156652359672982e-17, 7.803776722048461e-12, 0.18242551386356354, 0.8175744414329529], [6.156652359672982e-17, 7.803776722048461e-12, 0.18242551386356354, 0.8175744414329529]), ([6.156652634879947e-17, 0.0, 0.18242552201862228, 0.8175744779813776], [2.734698101650168e-12, 1.0, 9.173890920400186e-16, 1.62611098224923e-14])], ('a potted plant', 'a potted plant', 'a potted plant', 'a tennis racket', 'a tennis racket', 'a tennis racket'))}
a potted plant above a tennis racket
predicate correct
  1%|██▌                                                                                                                                                                                                                | 60/5023 [00:54<1:19:41,  1.04it/s]This is the original CLIP result:
tensor([107.6875,  93.4375,  85.1875,  77.2500,  73.8750,  78.0000,  78.1875,
         83.2500,  80.3750,  83.7500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9999940e-01 6.4759479e-07 1.6918969e-10 6.0417322e-14 2.0673671e-15
 1.2790347e-13 1.5428102e-13 2.4374086e-11 1.3750918e-12 4.0186073e-11]
predicts:  0
The Final Result:  {'probs': array([9.9999940e-01, 6.4759479e-07, 1.6918969e-10, 6.0417322e-14,
       2.0673671e-15, 1.2790347e-13, 1.5428102e-13, 2.4374086e-11,
       1.3750918e-12, 4.0186073e-11], dtype=float32), 'pred': 0, 'box': Box(x=433.48, y=83.78, w=124.46, h=154.5), 'texts': ['black metal chair']}
black metal chair
predicate correct
This is the original CLIP result:
tensor([121.8125, 109.1875,  83.3750,  89.7500,  86.5625, 106.5000,  93.6250,
         90.3750,  79.4375,  82.6250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9999654e-01 3.2887485e-06 2.0267694e-17 1.1896841e-14 4.9104130e-16
 2.2380216e-07 5.7322192e-13 2.2226224e-14 3.9515710e-19 9.5737810e-18]
predicts:  0
The Final Result:  {'probs': array([9.9999654e-01, 3.2887485e-06, 2.0267694e-17, 1.1896841e-14,
       4.9104130e-16, 2.2380216e-07, 5.7322192e-13, 2.2226224e-14,
       3.9515710e-19, 9.5737810e-18], dtype=float32), 'pred': 0, 'box': Box(x=433.48, y=83.78, w=124.46, h=154.5), 'texts': ["the chair with the man in the white shirt and blue short's sitting in it."]}
the chair with the man in the white shirt and blue short's sitting in it.
predicate correct
  1%|██▌                                                                                                                                                                                                                | 61/5023 [00:55<1:19:18,  1.04it/s]This is the original CLIP result:
tensor([105.0625, 111.1875,  76.4375,  95.8125,  70.6250,  84.4375,  89.0000,
         86.3750,  82.3125,  80.0000,  78.5000,  82.3125,  74.3750,  79.7500,
         84.5625, 102.5625,  83.5000,  94.8125,  80.9375,  80.4375,  81.1250,
         86.1250,  81.7500,  78.4375,  92.7500, 100.7500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 98.8750, 102.8750,  77.9375,  90.0000,  71.1250,  81.0625,  89.1875,
         84.6250,  82.0625,  80.3125,  80.8750,  84.3750,  72.8750,  82.8750,
         83.5000, 100.0625,  82.6875,  95.3750,  81.0000,  82.6250,  83.7500,
         88.6250,  83.5000,  80.5000,  88.5625,  93.4375], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [2.18226085e-03 9.97609019e-01 8.07657297e-16 2.09740705e-07
 2.41485123e-18 2.40759235e-12 2.30702096e-10 1.67120050e-11
 2.87545893e-13 2.84709017e-14 6.35271703e-15 2.87545893e-13
 1.02682105e-16 2.21731575e-14 2.72815950e-12 1.79130875e-04
 9.42826654e-13 7.71592923e-08 7.27029995e-14 4.40965928e-14
 8.76965533e-14 1.30153223e-11 1.63838723e-13 5.96782526e-15
 9.80970238e-09 2.92423119e-05]
parser result:  [2.42361829e-01 8.59083662e-08 1.84533751e-10 3.19706801e-05
 2.15175015e-13 6.73855227e-18 1.50395870e-05 1.59662565e-07
 1.23118531e-08 1.98392477e-09 3.47996289e-09 1.22234497e-07
 1.87393791e-21 2.72741978e-08 5.18348747e-08 7.49620142e-01
 2.30015724e-08 6.89992854e-03 3.94550535e-09 0.00000000e+00
 1.19777285e-16 8.07898032e-06 5.09549176e-08 2.39173966e-09
 8.18912678e-06 1.05427737e-03]
clip * parser result:  [5.28896732e-04 8.57029609e-08 1.49040030e-25 6.70555297e-12
 5.19615649e-31 1.62236869e-29 3.46966426e-15 2.66828159e-18
 3.54022280e-21 5.64841272e-23 2.21072195e-23 3.51480276e-20
 1.92419889e-37 6.04755084e-22 1.41413806e-19 1.34280112e-04
 2.16864955e-20 5.32393603e-10 2.86850074e-22 0.00000000e+00
 1.05040551e-29 1.05150533e-16 8.34838865e-21 1.42734843e-23
 8.03328965e-14 3.08295078e-08]
CLIP result after softmax:  [5.28896732e-04 8.57029609e-08 1.49040030e-25 6.70555297e-12
 5.19615649e-31 1.62236869e-29 3.46966426e-15 2.66828159e-18
 3.54022280e-21 5.64841272e-23 2.21072195e-23 3.51480276e-20
 1.92419889e-37 6.04755084e-22 1.41413806e-19 1.34280112e-04
 2.16864955e-20 5.32393603e-10 2.86850074e-22 0.00000000e+00
 1.05040551e-29 1.05150533e-16 8.34838865e-21 1.42734843e-23
 8.03328965e-14 3.08295078e-08]
predicts:  0
The Final Result:  {'probs': array([5.28896732e-04, 8.57029609e-08, 1.49040030e-25, 6.70555297e-12,
       5.19615649e-31, 1.62236869e-29, 3.46966426e-15, 2.66828159e-18,
       3.54022280e-21, 5.64841272e-23, 2.21072195e-23, 3.51480276e-20,
       1.92419889e-37, 6.04755084e-22, 1.41413806e-19, 1.34280112e-04,
       2.16864955e-20, 5.32393603e-10, 2.86850074e-22, 0.00000000e+00,
       1.05040551e-29, 1.05150533e-16, 8.34838865e-21, 1.42734843e-23,
       8.03328965e-14, 3.08295078e-08]), 'pred': 0, 'box': Box(x=324.44, y=11.8, w=175.28, h=138.2), 'texts': (['the pure green umbrella', 'sup:right'], [([0.016974514350295067, 0.9267771244049072, 1.3701137446808787e-11, 2.3737436549708946e-06, 1.5070423750075668e-14, 3.118364733101231e-10, 1.0533423164815758e-06, 1.0992614818405855e-08, 8.476593316153469e-10, 1.4730111574934313e-10, 2.585215097550275e-10, 8.5610567523986e-09, 8.672430856131522e-14, 1.910229752155601e-09, 3.5687794941452466e-09, 0.055657289922237396, 1.583636222157736e-09, 0.0005125859170220792, 2.929432252329889e-10, 1.4876885279235808e-09, 4.582403345665398e-09, 6.001764063512383e-07, 3.5687794941452466e-09, 1.7767906590471227e-10, 5.638135576191416e-07, 7.384500349871814e-05], [0.016974514350295067, 0.9267771244049072, 1.3701137446808787e-11, 2.3737436549708946e-06, 1.5070423750075668e-14, 3.118364733101231e-10, 1.0533423164815758e-06, 1.0992614818405855e-08, 8.476593316153469e-10, 1.4730111574934313e-10, 2.585215097550275e-10, 8.5610567523986e-09, 8.672430856131522e-14, 1.910229752155601e-09, 3.5687794941452466e-09, 0.055657289922237396, 1.583636222157736e-09, 0.0005125859170220792, 2.929432252329889e-10, 1.4876885279235808e-09, 4.582403345665398e-09, 6.001764063512383e-07, 3.5687794941452466e-09, 1.7767906590471227e-10, 5.638135576191416e-07, 7.384500349871814e-05]), ([0.24236182893193634, 8.590836617445436e-08, 1.8453375063134864e-10, 3.197068007827738e-05, 2.1517501495461648e-13, 6.738552265222788e-18, 1.5039587041829057e-05, 1.596625648222104e-07, 1.2311853121271721e-08, 1.983924773755105e-09, 3.4799628913749916e-09, 1.2223449700007338e-07, 1.8739379051526807e-21, 2.727419778898482e-08, 5.183487469768816e-08, 0.7496201416083146, 2.300157238573105e-08, 0.006899928543310104, 3.945505352873324e-09, 0.0, 1.197772851760624e-16, 8.078980318519684e-06, 5.095491760333439e-08, 2.3917396571249878e-09, 8.189126784238279e-06, 0.0010542773734906388], None)], ('the pure green umbrella', 'the pure green umbrella', 'the pure green umbrella', 'the pure green umbrella', 'the right', 'the right'))}
the pure green umbrella towards the right.
This is the original CLIP result:
tensor([ 97.5000, 104.8125,  70.1250,  91.0000,  64.8125,  82.7500,  88.0000,
         82.5000,  80.7500,  79.2500,  79.5625,  83.0000,  72.9375,  80.6250,
         82.9375,  99.7500,  80.9375,  95.6875,  80.5000,  82.2500,  82.7500,
         87.3750,  82.3750,  80.0000,  90.2500,  90.0000], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 97.5000, 104.8125,  70.1250,  91.0000,  64.8125,  82.7500,  88.0000,
         82.5000,  80.7500,  79.2500,  79.5625,  83.0000,  72.9375,  80.6250,
         82.9375,  99.7500,  80.9375,  95.6875,  80.5000,  82.2500,  82.7500,
         87.3750,  82.3750,  80.0000,  90.2500,  90.0000], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 97.5000, 104.8125,  70.1250,  91.0000,  64.8125,  82.7500,  88.0000,
         82.5000,  80.7500,  79.2500,  79.5625,  83.0000,  72.9375,  80.6250,
         82.9375,  99.7500,  80.9375,  95.6875,  80.5000,  82.2500,  82.7500,
         87.3750,  82.3750,  80.0000,  90.2500,  90.0000], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [6.6243869e-04 9.9294245e-01 8.5572493e-16 9.9593626e-07 4.2183709e-18
 2.6019686e-10 4.9584745e-08 2.0264151e-10 3.5213818e-11 7.8572643e-12
 1.0739608e-11 3.3409939e-10 1.4249102e-14 3.1076086e-11 3.1385730e-10
 6.2850430e-03 4.2475971e-11 1.0814014e-04 2.7424547e-11 1.5781737e-10
 2.6019686e-10 2.6540802e-08 1.7883051e-10 1.6633830e-11 4.7044696e-07
 3.6638446e-07]
parser result:  [6.6243869e-04 9.9294245e-01 8.5572493e-16 9.9593626e-07 4.2183709e-18
 2.6019686e-10 4.9584745e-08 2.0264151e-10 3.5213818e-11 7.8572643e-12
 1.0739608e-11 3.3409939e-10 1.4249102e-14 3.1076086e-11 3.1385730e-10
 6.2850430e-03 4.2475971e-11 1.0814014e-04 2.7424547e-11 1.5781737e-10
 2.6019686e-10 2.6540802e-08 1.7883051e-10 1.6633830e-11 4.7044696e-07
 3.6638446e-07]
clip * parser result:  [4.3882503e-07 9.8593473e-01 7.3226518e-31 9.9188908e-13 1.7794653e-35
 6.7702407e-20 2.4586470e-15 4.1063585e-20 1.2400130e-21 6.1736602e-23
 1.1533918e-22 1.1162240e-19 2.0303690e-28 9.6572317e-22 9.8506406e-20
 3.9501767e-05 1.8042081e-21 1.1694290e-08 7.5210579e-22 2.4906323e-20
 6.7702407e-20 7.0441415e-16 3.1980350e-20 2.7668429e-22 2.2132034e-13
 1.3423756e-13]
CLIP result after softmax:  [4.3882503e-07 9.8593473e-01 7.3226518e-31 9.9188908e-13 1.7794653e-35
 6.7702407e-20 2.4586470e-15 4.1063585e-20 1.2400130e-21 6.1736602e-23
 1.1533918e-22 1.1162240e-19 2.0303690e-28 9.6572317e-22 9.8506406e-20
 3.9501767e-05 1.8042081e-21 1.1694290e-08 7.5210579e-22 2.4906323e-20
 6.7702407e-20 7.0441415e-16 3.1980350e-20 2.7668429e-22 2.2132034e-13
 1.3423756e-13]
predicts:  1
The Final Result:  {'probs': array([4.3882503e-07, 9.8593473e-01, 7.3226518e-31, 9.9188908e-13,
       1.7794653e-35, 6.7702407e-20, 2.4586470e-15, 4.1063585e-20,
       1.2400130e-21, 6.1736602e-23, 1.1533918e-22, 1.1162240e-19,
       2.0303690e-28, 9.6572317e-22, 9.8506406e-20, 3.9501767e-05,
       1.8042081e-21, 1.1694290e-08, 7.5210579e-22, 2.4906323e-20,
       6.7702407e-20, 7.0441415e-16, 3.1980350e-20, 2.7668429e-22,
       2.2132034e-13, 1.3423756e-13], dtype=float32), 'pred': 1, 'box': Box(x=11.74, y=31.12, w=128.36, h=111.58), 'texts': (['a green umbrella with no one under it'], [([0.0006624386878684163, 0.9929424524307251, 8.55724934661228e-16, 9.959362614608835e-07, 4.218370901885144e-18, 2.601968640547625e-10, 4.9584745198671953e-08, 2.026415146794136e-10, 3.521381797266798e-11, 7.857264318344992e-12, 1.0739607987642064e-11, 3.3409938704487274e-10, 1.4249101640902324e-14, 3.107608614882906e-11, 3.138573012595458e-10, 0.006285042967647314, 4.2475970657429585e-11, 0.00010814014240168035, 2.742454700832564e-11, 1.5781737028319753e-10, 2.601968640547625e-10, 2.6540801556507176e-08, 1.7883050595912664e-10, 1.663382973027261e-11, 4.704469631633401e-07, 3.6638445521930407e-07], [0.0006624386878684163, 0.9929424524307251, 8.55724934661228e-16, 9.959362614608835e-07, 4.218370901885144e-18, 2.601968640547625e-10, 4.9584745198671953e-08, 2.026415146794136e-10, 3.521381797266798e-11, 7.857264318344992e-12, 1.0739607987642064e-11, 3.3409938704487274e-10, 1.4249101640902324e-14, 3.107608614882906e-11, 3.138573012595458e-10, 0.006285042967647314, 4.2475970657429585e-11, 0.00010814014240168035, 2.742454700832564e-11, 1.5781737028319753e-10, 2.601968640547625e-10, 2.6540801556507176e-08, 1.7883050595912664e-10, 1.663382973027261e-11, 4.704469631633401e-07, 3.6638445521930407e-07])], ('a green umbrella', 'a green umbrella', 'a green umbrella', 'no one', 'no one', 'it'))}
a green umbrella with no one under it
predicate correct
  1%|██▌                                                                                                                                                                                                                | 62/5023 [01:01<3:07:29,  2.27s/it]This is the original CLIP result:
tensor([ 77.2500, 118.2500,  80.3750, 116.3750,  78.2500, 124.0000, 104.1875],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [4.9561185e-21 3.1711401e-03 1.1280073e-19 4.8631008e-04 1.3472127e-20
 9.9634260e-01 2.4771325e-09]
predicts:  5
The Final Result:  {'probs': array([4.9561185e-21, 3.1711401e-03, 1.1280073e-19, 4.8631008e-04,
       1.3472127e-20, 9.9634260e-01, 2.4771325e-09], dtype=float32), 'pred': 5, 'box': Box(x=0.0, y=0.0, w=640.0, h=480.0), 'texts': ['a bus bench with a blonde lady sitting in it.']}
a bus bench with a blonde lady sitting in it.
This is the original CLIP result:
tensor([ 79.0000, 102.8750,  86.2500, 109.6875,  70.2500, 110.5000,  97.1250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.4457240e-14 3.3796064e-04 2.0357310e-11 3.0725381e-01 2.2909133e-18
 6.9240719e-01 1.0756546e-06]
predicts:  5
The Final Result:  {'probs': array([1.4457240e-14, 3.3796064e-04, 2.0357310e-11, 3.0725381e-01,
       2.2909133e-18, 6.9240719e-01, 1.0756546e-06], dtype=float32), 'pred': 5, 'box': Box(x=0.0, y=0.0, w=640.0, h=480.0), 'texts': ['the empty seat next to the woman in purple.']}
the empty seat next to the woman in purple.
  1%|██▋                                                                                                                                                                                                                | 63/5023 [01:01<2:30:55,  1.83s/it]This is the original CLIP result:
tensor([86.3750, 88.8750, 88.1250, 92.5000, 94.8125, 93.5000], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.5783505e-04 1.9228247e-03 9.0827805e-04 7.2153464e-02 7.2872412e-01
 1.9613345e-01]
predicts:  4
The Final Result:  {'probs': array([1.5783505e-04, 1.9228247e-03, 9.0827805e-04, 7.2153464e-02,
       7.2872412e-01, 1.9613345e-01], dtype=float32), 'pred': 4, 'box': Box(x=344.68, y=176.82, w=63.79, h=236.13), 'texts': ['man in the middle.']}
man in the middle.
This is the original CLIP result:
tensor([88.0625, 91.1875, 91.9375, 92.0000, 97.7500, 94.4375], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [5.9434926e-05 1.3527325e-03 2.8637347e-03 3.0484297e-03 9.5778823e-01
 3.4887429e-02]
predicts:  4
The Final Result:  {'probs': array([5.9434926e-05, 1.3527325e-03, 2.8637347e-03, 3.0484297e-03,
       9.5778823e-01, 3.4887429e-02], dtype=float32), 'pred': 4, 'box': Box(x=344.68, y=176.82, w=63.79, h=236.13), 'texts': ['the shortest player crouched in the middle with cupped hands.']}
the shortest player crouched in the middle with cupped hands.
  1%|██▋                                                                                                                                                                                                                | 64/5023 [01:02<2:02:42,  1.48s/it]This is the original CLIP result:
tensor([117.3125, 118.6875, 112.6250, 122.7500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([118.0625, 117.8750, 110.7500, 104.8750], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [4.2583803e-03 1.6842220e-02 3.9218321e-05 9.7886020e-01]
parser result:  [9.99331964e-01 0.00000000e+00 6.66165374e-04 1.87111699e-06]
clip * parser result:  [4.25553552e-03 0.00000000e+00 2.61258875e-08 1.83156195e-06]
CLIP result after softmax:  [4.25553552e-03 0.00000000e+00 2.61258875e-08 1.83156195e-06]
predicts:  0
The Final Result:  {'probs': array([4.25553552e-03, 0.00000000e+00, 2.61258875e-08, 1.83156195e-06]), 'pred': 0, 'box': Box(x=253.12, y=75.79, w=209.98, h=491.86), 'texts': (['vase', 'sup:right'], [([0.546538233757019, 0.4530961215496063, 0.00036462140269577503, 1.0241463996862876e-06], [0.546538233757019, 0.4530961215496063, 0.00036462140269577503, 1.0241463996862876e-06]), ([0.999331963508865, 0.0, 0.0006661653741403625, 1.8711169946112196e-06], None)], ('vase',))}
vase on right
predicate correct
  1%|██▋                                                                                                                                                                                                                | 65/5023 [01:03<1:38:37,  1.19s/it]This is the original CLIP result:
tensor([109.3750, 109.4375, 113.5625, 103.8750,  92.5625, 104.7500],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.4719667e-02 1.5669003e-02 9.6940696e-01 6.0155919e-05 7.3505868e-10
 1.4430654e-04]
predicts:  2
The Final Result:  {'probs': array([1.4719667e-02, 1.5669003e-02, 9.6940696e-01, 6.0155919e-05,
       7.3505868e-10, 1.4430654e-04], dtype=float32), 'pred': 2, 'box': Box(x=127.28, y=251.33, w=162.88, h=202.78), 'texts': ['teady bear on right']}
teady bear on right
This is the original CLIP result:
tensor([ 92.9375, 122.2500, 120.1250,  97.7500,  95.0625,  98.6250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.6624359e-13 8.9330941e-01 1.0669060e-01 2.0454418e-11 1.3919406e-12
 4.9067597e-11]
predicts:  1
The Final Result:  {'probs': array([1.6624359e-13, 8.9330941e-01, 1.0669060e-01, 2.0454418e-11,
       1.3919406e-12, 4.9067597e-11], dtype=float32), 'pred': 1, 'box': Box(x=408.81, y=252.4, w=200.63, h=179.06), 'texts': ['a light brown teddy bear with a white stomach.']}
a light brown teddy bear with a white stomach.
predicate correct
  1%|██▊                                                                                                                                                                                                                | 66/5023 [01:03<1:24:40,  1.02s/it]This is the original CLIP result:
tensor([ 83.0625, 112.6250,  98.0625, 102.2500,  91.3750,  98.8750, 102.4375,
         98.7500, 108.1875, 104.2500,  97.8750,  95.6875], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.4319703e-13 9.8801756e-01 4.6811360e-07 3.0829000e-05 5.8345440e-10
 1.0549103e-06 3.7186870e-05 9.3095508e-07 1.1683767e-02 2.2779719e-04
 3.8807980e-07 4.3541348e-08]
predicts:  1
The Final Result:  {'probs': array([1.4319703e-13, 9.8801756e-01, 4.6811360e-07, 3.0829000e-05,
       5.8345440e-10, 1.0549103e-06, 3.7186870e-05, 9.3095508e-07,
       1.1683767e-02, 2.2779719e-04, 3.8807980e-07, 4.3541348e-08],
      dtype=float32), 'pred': 1, 'box': Box(x=274.23, y=0.0, w=153.67, h=97.56), 'texts': ['the person in the black pants']}
the person in the black pants
predicate correct
This is the original CLIP result:
tensor([108.0000, 107.8750,  93.0625,  97.7500,  93.6875,  86.1250,  96.0625,
         87.1875, 103.6875,  95.2500,  87.2500,  91.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([107.6250, 109.8125,  95.5000,  98.4375,  96.1875,  89.0625,  98.5000,
         89.8750, 105.8750,  97.3125,  90.6250,  93.7500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([107.6250, 109.8125,  95.5000,  98.4375,  96.1875,  89.0625,  98.5000,
         89.8750, 105.8750,  97.3125,  90.6250,  93.7500], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [5.2744210e-01 4.6546602e-01 1.7175168e-07 1.8649034e-05 3.2087436e-07
 1.6671818e-10 3.4497243e-06 4.8241505e-10 7.0677279e-03 1.5308060e-06
 5.1352822e-10 3.1770867e-08]
parser result:  [9.9138111e-02 8.8360840e-01 5.3755150e-07 1.0142851e-05 1.0690488e-06
 8.6029889e-10 1.0797010e-05 1.9387134e-09 1.7227620e-02 3.2929022e-06
 4.1042560e-09 9.3412439e-08]
clip * parser result:  [5.2289613e-02 4.1128969e-01 9.2325372e-14 1.8915439e-10 3.4303037e-13
 1.4342747e-19 3.7246709e-11 9.3526458e-19 1.2176013e-04 5.0407946e-12
 2.1076512e-18 2.9677942e-15]
CLIP result after softmax:  [5.2289613e-02 4.1128969e-01 9.2325372e-14 1.8915439e-10 3.4303037e-13
 1.4342747e-19 3.7246709e-11 9.3526458e-19 1.2176013e-04 5.0407946e-12
 2.1076512e-18 2.9677942e-15]
predicts:  1
The Final Result:  {'probs': array([5.2289613e-02, 4.1128969e-01, 9.2325372e-14, 1.8915439e-10,
       3.4303037e-13, 1.4342747e-19, 3.7246709e-11, 9.3526458e-19,
       1.2176013e-04, 5.0407946e-12, 2.1076512e-18, 2.9677942e-15],
      dtype=float32), 'pred': 1, 'box': Box(x=274.23, y=0.0, w=153.67, h=97.56), 'texts': (['someone in dark pants standing behind a table full of food'], [([0.09913811087608337, 0.8836084008216858, 5.375515002015163e-07, 1.014285135170212e-05, 1.0690488352338434e-06, 8.602988876837969e-10, 1.0797009963425808e-05, 1.938713412030779e-09, 0.017227619886398315, 3.292902192697511e-06, 4.104256046133514e-09, 9.341243867311277e-08], [0.09913811087608337, 0.8836084008216858, 5.375515002015163e-07, 1.014285135170212e-05, 1.0690488352338434e-06, 8.602988876837969e-10, 1.0797009963425808e-05, 1.938713412030779e-09, 0.017227619886398315, 3.292902192697511e-06, 4.104256046133514e-09, 9.341243867311277e-08])], ('someone', 'dark pants', 'dark pants', 'a table', 'a table', 'food'))}
someone in dark pants standing behind a table full of food.
predicate correct
  1%|██▊                                                                                                                                                                                                                | 67/5023 [01:05<1:45:03,  1.27s/it]This is the original CLIP result:
tensor([103.6250, 128.0000, 104.0000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.5946094e-11 1.0000000e+00 3.7751347e-11]
predicts:  1
The Final Result:  {'probs': array([2.5946094e-11, 1.0000000e+00, 3.7751347e-11], dtype=float32), 'pred': 1, 'box': Box(x=0.0, y=30.68, w=234.97, h=300.82), 'texts': ['a young boy with blonde hair brushing his teeth.']}
a young boy with blonde hair brushing his teeth.
predicate correct
This is the original CLIP result:
tensor([88.5000, 93.7500, 72.3125], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [5.2201259e-03 9.9477994e-01 4.8701132e-10]
predicts:  1
The Final Result:  {'probs': array([5.2201259e-03, 9.9477994e-01, 4.8701132e-10], dtype=float32), 'pred': 1, 'box': Box(x=0.0, y=30.68, w=234.97, h=300.82), 'texts': ['little blond boy']}
little blond boy
predicate correct
  1%|██▊                                                                                                                                                                                                                | 68/5023 [01:05<1:21:37,  1.01it/s]This is the original CLIP result:
tensor([ 88.7500,  97.8750,  93.2500, 103.2500,  84.2500,  98.6250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [4.9714868e-07 4.5648185e-03 4.4751901e-05 9.8572624e-01 5.5228231e-09
 9.6637206e-03]
predicts:  3
The Final Result:  {'probs': array([4.9714868e-07, 4.5648185e-03, 4.4751901e-05, 9.8572624e-01,
       5.5228231e-09, 9.6637206e-03], dtype=float32), 'pred': 3, 'box': Box(x=3.83, y=1.91, w=211.56, h=291.02), 'texts': ["man's hand with ring on it"]}
man's hand with ring on it
predicate correct
This is the original CLIP result:
tensor([ 92.5000, 105.5000,  95.0000, 103.1250,  90.3750,  96.6250],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 92.5000, 105.5000,  95.0000, 103.1250,  90.3750,  96.6250],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 92.5000, 105.5000,  95.0000, 103.1250,  90.3750,  96.6250],
       device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [2.0676562e-06 9.1475880e-01 2.5189209e-05 8.5085817e-02 2.4694631e-07
 1.2792136e-04]
parser result:  [2.0676562e-06 9.1475880e-01 2.5189209e-05 8.5085817e-02 2.4694631e-07
 1.2792136e-04]
clip * parser result:  [4.2752022e-12 8.3678365e-01 6.3449623e-10 7.2395960e-03 6.0982483e-14
 1.6363874e-08]
CLIP result after softmax:  [4.2752022e-12 8.3678365e-01 6.3449623e-10 7.2395960e-03 6.0982483e-14
 1.6363874e-08]
predicts:  1
The Final Result:  {'probs': array([4.2752022e-12, 8.3678365e-01, 6.3449623e-10, 7.2395960e-03,
       6.0982483e-14, 1.6363874e-08], dtype=float32), 'pred': 1, 'box': Box(x=45.09, y=59.01, w=175.59, h=108.42), 'texts': (['a persion sitting on left chair'], [([2.0676561689469963e-06, 0.9147588014602661, 2.5189208827214316e-05, 0.08508581668138504, 2.469463140641892e-07, 0.00012792136112693697], [2.0676561689469963e-06, 0.9147588014602661, 2.5189208827214316e-05, 0.08508581668138504, 2.469463140641892e-07, 0.00012792136112693697])], ('a persion', 'a persion', 'left chair', 'left chair'))}
a persion sitting on left chair
  1%|██▉                                                                                                                                                                                                                | 69/5023 [01:07<1:26:44,  1.05s/it]This is the original CLIP result:
tensor([ 83.7500,  74.4375,  75.5625, 109.6875,  81.1250, 113.7500],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.1993396e-14 8.3059488e-18 2.5584126e-17 1.6914913e-02 6.6639788e-15
 9.8308510e-01]
predicts:  5
The Final Result:  {'probs': array([9.1993396e-14, 8.3059488e-18, 2.5584126e-17, 1.6914913e-02,
       6.6639788e-15, 9.8308510e-01], dtype=float32), 'pred': 5, 'box': Box(x=2.4, y=157.65, w=169.95, h=158.54), 'texts': ['white truck with dent in the door']}
white truck with dent in the door
predicate correct
This is the original CLIP result:
tensor([ 70.8125,  76.0000,  71.1875, 117.8750,  75.0625, 110.6875],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 80.6250,  80.9375,  76.9375, 119.6250,  83.1250, 114.3125],
       device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 91.2500,  84.7500,  83.3750, 113.1875,  87.5000, 117.0000],
       device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [3.6365348e-21 6.5101404e-19 5.2911262e-21 9.9924457e-01 2.5494076e-19
 7.5540552e-04]
parser result:  [6.05326699e-08 1.27406456e-26 2.30102219e-11 9.99999939e-01
 0.00000000e+00 1.43671365e-12]
clip * parser result:  [2.20129159e-28 8.29433920e-45 1.21749988e-31 9.99244510e-01
 0.00000000e+00 1.08530142e-15]
CLIP result after softmax:  [2.20129159e-28 8.29433920e-45 1.21749988e-31 9.99244510e-01
 0.00000000e+00 1.08530142e-15]
predicts:  3
The Final Result:  {'probs': array([2.20129159e-28, 8.29433920e-45, 1.21749988e-31, 9.99244510e-01,
       0.00000000e+00, 1.08530142e-15]), 'pred': 3, 'box': Box(x=161.75, y=167.8, w=235.35, h=140.44), 'texts': (['a white truck', 'a yellow truck'], [([6.418399232238636e-12, 9.649672079730005e-15, 2.439819535776178e-15, 0.02161533385515213, 1.5094628563576407e-13, 0.9783847332000732], [6.418399232238636e-12, 9.649672079730005e-15, 2.439819535776178e-15, 0.02161533385515213, 1.5094628563576407e-13, 0.9783847332000732]), ([6.053266989970738e-08, 1.2740645570185312e-26, 2.3010221899594296e-11, 0.999999939442883, 0.0, 1.4367136538745438e-12], [1.1491576054210273e-17, 1.570712089353263e-17, 2.8768597242043005e-19, 0.9950946569442749, 1.3999605704008406e-16, 0.004905405919998884])], ('a white truck', 'a white truck', 'a white truck', 'front', 'a yellow truck', 'a yellow truck', 'a yellow truck'))}
a white truck in front of a yellow truck.
  1%|██▉                                                                                                                                                                                                                | 70/5023 [01:08<1:31:32,  1.11s/it]This is the original CLIP result:
tensor([ 88.9375, 103.2500, 106.0625,  93.2500,  87.3750,  76.7500],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.4464946e-08 5.6652278e-02 9.4334513e-01 2.5720094e-06 7.2242456e-09
 1.7555515e-13]
predicts:  2
The Final Result:  {'probs': array([3.4464946e-08, 5.6652278e-02, 9.4334513e-01, 2.5720094e-06,
       7.2242456e-09, 1.7555515e-13], dtype=float32), 'pred': 2, 'box': Box(x=142.45, y=27.56, w=157.94, h=317.93), 'texts': ['guy in grey shirt giving a thumbs up.']}
guy in grey shirt giving a thumbs up.
predicate correct
This is the original CLIP result:
tensor([ 87.1250, 115.0000, 105.5625,  84.5000,  94.3750,  92.8750],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [7.8344173e-13 9.9992037e-01 7.9673009e-05 5.6752332e-14 1.1031682e-09
 2.4615010e-10]
predicts:  1
The Final Result:  {'probs': array([7.8344173e-13, 9.9992037e-01, 7.9673009e-05, 5.6752332e-14,
       1.1031682e-09, 2.4615010e-10], dtype=float32), 'pred': 1, 'box': Box(x=0.0, y=94.92, w=495.1, h=379.69), 'texts': ['a man thumbs up holding his blue color bullet']}
a man thumbs up holding his blue color bullet
  1%|██▉                                                                                                                                                                                                                | 71/5023 [01:09<1:21:12,  1.02it/s]This is the original CLIP result:
tensor([ 93.5000, 118.6875, 102.8125, 101.7500, 106.7500,  85.3750,  89.0000,
         77.8750,  75.1250, 103.7500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.1513429e-11 9.9999297e-01 1.2751816e-07 4.4069097e-08 6.5404338e-06
 3.4084900e-15 1.2790265e-13 1.8851827e-18 1.2051568e-19 3.2562903e-07]
predicts:  1
The Final Result:  {'probs': array([1.1513429e-11, 9.9999297e-01, 1.2751816e-07, 4.4069097e-08,
       6.5404338e-06, 3.4084900e-15, 1.2790265e-13, 1.8851827e-18,
       1.2051568e-19, 3.2562903e-07], dtype=float32), 'pred': 1, 'box': Box(x=106.67, y=215.0, w=217.65, h=291.67), 'texts': ['a man with black color stripped coat and sandal color pant with sports bat in his hands sitting in a chair.']}
a man with black color stripped coat and sandal color pant with sports bat in his hands sitting in a chair.
This is the original CLIP result:
tensor([100.2500, 111.4375, 106.2500, 106.5000, 117.1250, 112.7500,  99.2500,
         97.6250, 104.5000, 105.2500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [4.6171525e-08 3.3345998e-03 1.8626923e-05 2.3917441e-05 9.8422319e-01
 1.2389542e-02 1.6985556e-08 3.3446541e-09 3.2368737e-06 6.8524619e-06]
predicts:  4
The Final Result:  {'probs': array([4.6171525e-08, 3.3345998e-03, 1.8626923e-05, 2.3917441e-05,
       9.8422319e-01, 1.2389542e-02, 1.6985556e-08, 3.3446541e-09,
       3.2368737e-06, 6.8524619e-06], dtype=float32), 'pred': 4, 'box': Box(x=283.45, y=209.83, w=139.46, h=279.61), 'texts': ['this is a man sitting and holding a racquet.']}
this is a man sitting and holding a racquet.
predicate correct
  1%|███                                                                                                                                                                                                                | 72/5023 [01:10<1:22:13,  1.00it/s]This is the original CLIP result:
tensor([118.0000,  96.4375,  62.7812,  95.0625,  81.0625,  72.1875,  75.6875,
         88.3125,  91.9375], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.0000000e+00 4.3204126e-10 1.0442430e-24 1.0923715e-10 9.0833815e-17
 1.2702349e-20 4.2064401e-19 1.2790355e-13 4.7995453e-12]
predicts:  0
The Final Result:  {'probs': array([1.0000000e+00, 4.3204126e-10, 1.0442430e-24, 1.0923715e-10,
       9.0833815e-17, 1.2702349e-20, 4.2064401e-19, 1.2790355e-13,
       4.7995453e-12], dtype=float32), 'pred': 0, 'box': Box(x=151.01, y=172.4, w=148.86, h=134.84), 'texts': ['the green plant is beside the girl']}
the green plant is beside the girl
predicate correct
This is the original CLIP result:
tensor([120.8750, 104.3125,  56.3750,  73.8125,  77.5000,  69.0000,  66.3750,
         89.3125,  95.7500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9999988e-01 6.4120599e-08 9.7276037e-29 3.6392837e-21 1.4537067e-19
 2.9578333e-23 2.1426474e-24 1.9614642e-14 1.2256065e-11]
predicts:  0
The Final Result:  {'probs': array([9.9999988e-01, 6.4120599e-08, 9.7276037e-29, 3.6392837e-21,
       1.4537067e-19, 2.9578333e-23, 2.1426474e-24, 1.9614642e-14,
       1.2256065e-11], dtype=float32), 'pred': 0, 'box': Box(x=151.01, y=172.4, w=148.86, h=134.84), 'texts': ['a green bush in a black pot.']}
a green bush in a black pot.
predicate correct
  1%|███                                                                                                                                                                                                                | 73/5023 [01:11<1:22:48,  1.00s/it]This is the original CLIP result:
tensor([ 90.1875,  96.1250,  89.0000, 109.1250,  93.7500], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [5.9641305e-09 2.2603238e-06 1.8189571e-09 9.9999750e-01 2.1024286e-07]
predicts:  3
The Final Result:  {'probs': array([5.9641305e-09, 2.2603238e-06, 1.8189571e-09, 9.9999750e-01,
       2.1024286e-07], dtype=float32), 'pred': 3, 'box': Box(x=12.06, y=184.87, w=622.91, h=235.1), 'texts': ['art project']}
art project
predicate correct
  1%|███                                                                                                                                                                                                                | 74/5023 [01:11<1:04:45,  1.27it/s]This is the original CLIP result:
tensor([114.1250, 112.5000, 118.0000,  99.5000], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [2.0251274e-02 3.9877123e-03 9.7576106e-01 9.0135437e-09]
predicts:  2
The Final Result:  {'probs': array([2.0251274e-02, 3.9877123e-03, 9.7576106e-01, 9.0135437e-09],
      dtype=float32), 'pred': 2, 'box': Box(x=3.5, y=2.5, w=210.0, h=169.0), 'texts': ['the toothbrush that is blue and white.']}
the toothbrush that is blue and white.
predicate correct
This is the original CLIP result:
tensor([116.0000, 114.6250, 125.6875, 101.9375], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [6.2049519e-05 1.5688576e-05 9.9992216e-01 4.8469909e-11]
predicts:  2
The Final Result:  {'probs': array([6.2049519e-05, 1.5688576e-05, 9.9992216e-01, 4.8469909e-11],
      dtype=float32), 'pred': 2, 'box': Box(x=3.5, y=2.5, w=210.0, h=169.0), 'texts': ['a blue color brush is side of other yellow color brush.']}
a blue color brush is side of other yellow color brush.
predicate correct
  1%|███▏                                                                                                                                                                                                                 | 75/5023 [01:11<54:32,  1.51it/s]This is the original CLIP result:
tensor([124.6250, 112.5000, 116.5000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9969876e-01 5.4206148e-06 2.9595554e-04]
predicts:  0
The Final Result:  {'probs': array([9.9969876e-01, 5.4206148e-06, 2.9595554e-04], dtype=float32), 'pred': 0, 'box': Box(x=444.4, y=24.63, w=118.66, h=360.27), 'texts': ['the mid sized vase']}
the mid sized vase
This is the original CLIP result:
tensor([128.5000, 112.2500, 116.0000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [9.9999619e-01 8.7642150e-08 3.7266389e-06]
predicts:  0
The Final Result:  {'probs': array([9.9999619e-01, 8.7642150e-08, 3.7266389e-06], dtype=float32), 'pred': 0, 'box': Box(x=444.4, y=24.63, w=118.66, h=360.27), 'texts': ['the vase of medium height, neither tall nor short.']}
the vase of medium height, neither tall nor short.
  2%|███▏                                                                                                                                                                                                                 | 76/5023 [01:12<47:18,  1.74it/s]This is the original CLIP result:
tensor([ 84.5000, 120.0625, 116.8125], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.4584482e-16 9.6267307e-01 3.7326884e-02]
predicts:  1
The Final Result:  {'probs': array([3.4584482e-16, 9.6267307e-01, 3.7326884e-02], dtype=float32), 'pred': 1, 'box': Box(x=11.51, y=145.26, w=310.65, h=476.04), 'texts': ["someone's hand brushing the teeth of the child"]}
someone's hand brushing the teeth of the child
predicate correct
This is the original CLIP result:
tensor([82.5625, 91.2500, 83.5000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.6858014e-04 9.9940097e-01 4.3048451e-04]
predicts:  1
The Final Result:  {'probs': array([1.6858014e-04, 9.9940097e-01, 4.3048451e-04], dtype=float32), 'pred': 1, 'box': Box(x=11.51, y=145.26, w=310.65, h=476.04), 'texts': ['arm and hand of adult helping child']}
arm and hand of adult helping child
predicate correct
  2%|███▎                                                                                                                                                                                                                 | 77/5023 [01:12<43:40,  1.89it/s]This is the original CLIP result:
tensor([ 82.0000,  76.1250,  95.8750, 105.6250,  86.3750, 122.6250, 111.9375,
        100.1875,  93.5625], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.2739284e-18 6.3869967e-21 2.4133078e-12 4.1398433e-08 1.8064051e-16
 9.9997723e-01 2.2827997e-05 1.8009749e-10 2.3894981e-13]
predicts:  5
The Final Result:  {'probs': array([2.2739284e-18, 6.3869967e-21, 2.4133078e-12, 4.1398433e-08,
       1.8064051e-16, 9.9997723e-01, 2.2827997e-05, 1.8009749e-10,
       2.3894981e-13], dtype=float32), 'pred': 5, 'box': Box(x=371.82, y=161.35, w=146.71, h=113.66), 'texts': ['the umbrella that the woman in gray is holding that is facing the ground.']}
the umbrella that the woman in gray is holding that is facing the ground.
This is the original CLIP result:
tensor([ 91.5000,  88.8750, 107.0000, 121.6250,  80.3750, 129.5000, 116.7500,
         97.9375, 100.3750], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 93.2500,  90.7500, 109.1250, 123.5000,  80.8125, 130.6250, 116.8750,
         99.6875, 101.8750], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 93.2500,  90.7500, 109.1250, 123.5000,  80.8125, 130.6250, 116.8750,
         99.6875, 101.8750], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [3.1379308e-17 2.2731095e-18 1.6912501e-10 3.7998339e-04 4.6250589e-22
 9.9961710e-01 2.9012092e-06 1.9607134e-14 2.2439174e-13]
parser result:  [5.8599500e-17 4.8101396e-18 4.5953524e-10 8.0408505e-04 2.3246431e-22
 9.9919480e-01 1.0668443e-06 3.6615469e-14 3.2635014e-13]
clip * parser result:  [1.8388117e-33 1.0933974e-35 7.7718898e-20 3.0553898e-07 1.0789998e-43
 9.9881220e-01 3.0951385e-12 7.1792443e-28 7.3230278e-26]
CLIP result after softmax:  [1.8388117e-33 1.0933974e-35 7.7718898e-20 3.0553898e-07 1.0789998e-43
 9.9881220e-01 3.0951385e-12 7.1792443e-28 7.3230278e-26]
predicts:  5
The Final Result:  {'probs': array([1.8388117e-33, 1.0933974e-35, 7.7718898e-20, 3.0553898e-07,
       1.0789998e-43, 9.9881220e-01, 3.0951385e-12, 7.1792443e-28,
       7.3230278e-26], dtype=float32), 'pred': 5, 'box': Box(x=371.82, y=161.35, w=146.71, h=113.66), 'texts': (['umbrella with a red handle being held with a girl in high - top sneakers'], [([5.859949953139601e-17, 4.810139634418336e-18, 4.5953524319131134e-10, 0.0008040850516408682, 2.3246430834091414e-22, 0.9991948008537292, 1.0668443337635836e-06, 3.6615469093141326e-14, 3.263501394037277e-13], [5.859949953139601e-17, 4.810139634418336e-18, 4.5953524319131134e-10, 0.0008040850516408682, 2.3246430834091414e-22, 0.9991948008537292, 1.0668443337635836e-06, 3.6615469093141326e-14, 3.263501394037277e-13])], ('umbrella', 'a red handle', 'a red handle', 'a red handle', 'a girl', 'a girl', 'high-top sneakers', 'high-top sneakers', 'high-top sneakers', 'high-top sneakers'))}
umbrella with a red handle being held with a girl in high-top sneakers.
  2%|███▎                                                                                                                                                                                                               | 78/5023 [01:14<1:15:30,  1.09it/s]This is the original CLIP result:
tensor([121.7500, 122.1250, 121.5000, 121.7500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([118.8125, 119.6250, 119.6250, 116.1250], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [0.23619486 0.34366152 0.18394874 0.23619486]
parser result:  [0.17936832 0.40421277 0.40421277 0.01220617]
clip * parser result:  [0.04236588 0.13891238 0.07435443 0.00288303]
CLIP result after softmax:  [0.04236588 0.13891238 0.07435443 0.00288303]
predicts:  1
The Final Result:  {'probs': array([0.04236588, 0.13891238, 0.07435443, 0.00288303], dtype=float32), 'pred': 1, 'box': Box(x=386.88, y=195.6, w=168.27, h=107.86), 'texts': (['the middle banana'], [([0.17936831712722778, 0.4042127728462219, 0.4042127728462219, 0.012206166982650757], [0.17936831712722778, 0.4042127728462219, 0.4042127728462219, 0.012206166982650757])], ('the middle banana', 'the middle banana', 'the middle banana', 'the right hand picture', 'the right hand picture', 'the right hand picture', 'the right hand picture'))}
the middle banana in the right hand picture
This is the original CLIP result:
tensor([123.1250, 122.1250, 121.1250, 123.8750], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [0.27622673 0.10161813 0.03738322 0.584772  ]
predicts:  3
The Final Result:  {'probs': array([0.27622673, 0.10161813, 0.03738322, 0.584772  ], dtype=float32), 'pred': 3, 'box': Box(x=0.0, y=176.46, w=640.0, h=192.72), 'texts': ['banana in the middle, tied to elbow']}
banana in the middle, tied to elbow
  2%|███▎                                                                                                                                                                                                               | 79/5023 [01:15<1:12:19,  1.14it/s]This is the original CLIP result:
tensor([ 93.7500, 100.1875,  96.0000, 123.1875,  91.7500, 117.3750, 119.7500,
        113.9375,  95.4375,  95.5000, 100.8750, 101.0000,  98.0000,  95.1875,
         98.5000,  95.6250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.58642291e-13 9.91264848e-11 1.50515613e-12 9.65968072e-01
 2.14698966e-14 2.88819219e-03 3.10509950e-02 9.28407899e-05
 8.57612104e-13 9.12923274e-13 1.97136543e-10 2.23384963e-10
 1.11216834e-11 6.67908979e-13 1.83365562e-11 1.03447773e-12]
predicts:  3
The Final Result:  {'probs': array([1.58642291e-13, 9.91264848e-11, 1.50515613e-12, 9.65968072e-01,
       2.14698966e-14, 2.88819219e-03, 3.10509950e-02, 9.28407899e-05,
       8.57612104e-13, 9.12923274e-13, 1.97136543e-10, 2.23384963e-10,
       1.11216834e-11, 6.67908979e-13, 1.83365562e-11, 1.03447773e-12],
      dtype=float32), 'pred': 3, 'box': Box(x=230.79, y=121.75, w=192.87, h=341.31), 'texts': ['this is a woman holding a wineglass and is wearing a white tshirt.']}
this is a woman holding a wineglass and is wearing a white tshirt.
predicate correct
This is the original CLIP result:
tensor([ 75.0000,  78.5000,  78.5625, 133.5000,  94.0000, 115.6250, 115.7500,
        111.5000,  79.6875,  77.6250,  90.3125, 108.6875,  89.5625,  76.3125,
         81.8750,  84.7500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.9243960e-26 1.2995815e-24 1.3833972e-24 1.0000000e+00 7.0043520e-18
 1.7257829e-08 1.9555680e-08 2.7894681e-10 4.2611635e-24 5.4174613e-25
 1.7535052e-19 1.6752058e-11 8.2829718e-20 1.4580899e-25 3.7979336e-23
 6.7319981e-22]
predicts:  3
The Final Result:  {'probs': array([3.9243960e-26, 1.2995815e-24, 1.3833972e-24, 1.0000000e+00,
       7.0043520e-18, 1.7257829e-08, 1.9555680e-08, 2.7894681e-10,
       4.2611635e-24, 5.4174613e-25, 1.7535052e-19, 1.6752058e-11,
       8.2829718e-20, 1.4580899e-25, 3.7979336e-23, 6.7319981e-22],
      dtype=float32), 'pred': 3, 'box': Box(x=230.79, y=121.75, w=192.87, h=341.31), 'texts': ['a woman in a white blouse holding a glass of wine.']}
a woman in a white blouse holding a glass of wine.
predicate correct
  2%|███▎                                                                                                                                                                                                               | 80/5023 [01:16<1:26:52,  1.05s/it]This is the original CLIP result:
tensor([ 85.1250, 105.8750, 109.1250,  90.5000,  84.8125,  86.7500,  85.5000,
         80.1250, 128.1250, 122.3750,  87.9375,  86.2500,  89.0000],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.10842044e-19 2.16554746e-10 5.58502000e-09 4.55292021e-17
 1.54255342e-19 1.07074425e-18 3.06773372e-19 1.42064251e-21
 9.96827304e-01 3.17268283e-03 3.51083493e-18 6.49439196e-19
 1.01589385e-17]
predicts:  8
The Final Result:  {'probs': array([2.10842044e-19, 2.16554746e-10, 5.58502000e-09, 4.55292021e-17,
       1.54255342e-19, 1.07074425e-18, 3.06773372e-19, 1.42064251e-21,
       9.96827304e-01, 3.17268283e-03, 3.51083493e-18, 6.49439196e-19,
       1.01589385e-17], dtype=float32), 'pred': 8, 'box': Box(x=0.0, y=1.83, w=640.0, h=470.29), 'texts': ['soup in a white bowl with vegetables, nuts and broth.']}
soup in a white bowl with vegetables, nuts and broth.
predicate correct
This is the original CLIP result:
tensor([ 68.1250, 115.6250,  95.3750,  93.3750,  88.0000,  85.1250,  80.1875,
         84.1250, 118.3750, 116.0000,  95.0625,  89.3750,  96.1250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.2983463e-22 5.5255871e-02 8.8698278e-11 1.2004005e-11 5.5589576e-14
 3.1361492e-15 2.2494055e-17 1.1537248e-15 8.6434728e-01 8.0396816e-02
 6.4893042e-11 2.1986105e-13 1.8777425e-10]
predicts:  8
The Final Result:  {'probs': array([1.2983463e-22, 5.5255871e-02, 8.8698278e-11, 1.2004005e-11,
       5.5589576e-14, 3.1361492e-15, 2.2494055e-17, 1.1537248e-15,
       8.6434728e-01, 8.0396816e-02, 6.4893042e-11, 2.1986105e-13,
       1.8777425e-10], dtype=float32), 'pred': 8, 'box': Box(x=0.0, y=1.83, w=640.0, h=470.29), 'texts': ['a large white bowl of curry, with carrot and kale garnishes.']}
a large white bowl of curry, with carrot and kale garnishes.
predicate correct
  2%|███▍                                                                                                                                                                                                               | 81/5023 [01:17<1:30:56,  1.10s/it]This is the original CLIP result:
tensor([122.6250, 124.1250, 122.8750], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.14780405 0.6624118  0.18978414]
predicts:  1
The Final Result:  {'probs': array([0.14780405, 0.6624118 , 0.18978414], dtype=float32), 'pred': 1, 'box': Box(x=278.79, y=113.54, w=139.77, h=132.89), 'texts': ['giraffe holding head highest.']}
giraffe holding head highest.
predicate correct
This is the original CLIP result:
tensor([113.6875, 118.1250, 116.1250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.01030846 0.8717174  0.11797412]
predicts:  1
The Final Result:  {'probs': array([0.01030846, 0.8717174 , 0.11797412], dtype=float32), 'pred': 1, 'box': Box(x=278.79, y=113.54, w=139.77, h=132.89), 'texts': ['giraffe talking with anothergiraffe']}
giraffe talking with anothergiraffe
predicate correct
  2%|███▍                                                                                                                                                                                                               | 82/5023 [01:18<1:12:34,  1.13it/s]This is the original CLIP result:
tensor([ 87.1875, 124.5000, 119.6875,  83.2500,  99.3750, 117.7500, 108.0000,
         86.5000,  74.7500,  82.0000,  84.6875], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [6.18539589e-17 9.90787208e-01 8.05263873e-03 1.20596026e-18
 1.21431545e-11 1.16009254e-03 6.76272052e-08 3.11021234e-17
 2.45374768e-22 3.45513394e-19 5.07728216e-18]
predicts:  1
The Final Result:  {'probs': array([6.18539589e-17, 9.90787208e-01, 8.05263873e-03, 1.20596026e-18,
       1.21431545e-11, 1.16009254e-03, 6.76272052e-08, 3.11021234e-17,
       2.45374768e-22, 3.45513394e-19, 5.07728216e-18], dtype=float32), 'pred': 1, 'box': Box(x=0.0, y=187.04, w=378.2, h=292.93), 'texts': ['a thick sandwich which appears to be made with bananas and bacon on whole wheat bread sits on a wooden cutting board']}
a thick sandwich which appears to be made with bananas and bacon on whole wheat bread sits on a wooden cutting board
predicate correct
This is the original CLIP result:
tensor([ 93.8750, 116.1250, 114.2500,  97.3750, 102.0000, 114.1250, 109.7500,
         95.4375,  87.1250,  92.8750,  95.8750], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [1.68354691e-10 7.74956703e-01 1.18843451e-01 5.57514168e-09
 5.68679923e-07 1.04878984e-01 1.32023159e-03 8.03175249e-10
 1.97123080e-13 6.19342286e-11 1.24398214e-09]
predicts:  1
The Final Result:  {'probs': array([1.68354691e-10, 7.74956703e-01, 1.18843451e-01, 5.57514168e-09,
       5.68679923e-07, 1.04878984e-01, 1.32023159e-03, 8.03175249e-10,
       1.97123080e-13, 6.19342286e-11, 1.24398214e-09], dtype=float32), 'pred': 1, 'box': Box(x=0.0, y=187.04, w=378.2, h=292.93), 'texts': ['a sandwich which is roughly triangular in shape']}
a sandwich which is roughly triangular in shape
predicate correct
  2%|███▍                                                                                                                                                                                                               | 83/5023 [01:19<1:23:33,  1.01s/it]This is the original CLIP result:
tensor([134.3750, 131.7500, 144.5000, 146.2500, 115.6875], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [5.9315175e-06 4.2967764e-07 1.4804624e-01 8.5194737e-01 4.5424239e-14]
predicts:  3
The Final Result:  {'probs': array([5.9315175e-06, 4.2967764e-07, 1.4804624e-01, 8.5194737e-01,
       4.5424239e-14], dtype=float32), 'pred': 3, 'box': Box(x=0.0, y=0.0, w=544.23, h=397.0), 'texts': ['orange cat getting slapped in the face.']}
orange cat getting slapped in the face.
This is the original CLIP result:
tensor([114.7500, 107.1875, 112.8750, 113.8750, 111.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([111.5000, 109.1250, 110.1250, 110.3750, 119.7500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([109.6250, 107.3750, 107.8125, 108.0000, 118.1250], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [6.2307054e-01 3.2373169e-04 9.5550954e-02 2.5973445e-01 2.1320300e-02]
parser result:  [5.37397698e-01 0.00000000e+00 9.57109615e-06 2.57106047e-06
 4.62590160e-01]
clip * parser result:  [3.34836673e-01 0.00000000e+00 9.14527371e-07 6.67792983e-07
 9.86256106e-03]
CLIP result after softmax:  [3.34836673e-01 0.00000000e+00 9.14527371e-07 6.67792983e-07
 9.86256106e-03]
predicts:  0
The Final Result:  {'probs': array([3.34836673e-01, 0.00000000e+00, 9.14527371e-07, 6.67792983e-07,
       9.86256106e-03]), 'pred': 0, 'box': Box(x=305.45, y=11.98, w=334.55, h=349.08), 'texts': (['the orange cat', 'the other orange cat'], [([0.00020340768969617784, 2.143901292583905e-05, 3.3205396903213114e-05, 4.00533463107422e-05, 0.9997017979621887], [0.00020340768969617784, 2.143901292583905e-05, 3.3205396903213114e-05, 4.00533463107422e-05, 0.9997017979621887]), ([0.5373976981061721, 0.0, 9.571096150577833e-06, 2.571060473705183e-06, 0.4625901597372036], [0.0002611445961520076, 2.4290229703183286e-05, 6.602769281016663e-05, 8.478123345412314e-05, 0.9995637536048889])], ('the orange cat', 'the orange cat', 'the orange cat', 'top', 'the other orange cat', 'the other orange cat', 'the other orange cat', 'the other orange cat'))}
the orange cat on top of the other orange cat.
predicate correct
  2%|███▌                                                                                                                                                                                                               | 84/5023 [01:20<1:25:32,  1.04s/it]This is the original CLIP result:
tensor([ 91.8750,  89.1250,  85.3750,  92.2500,  89.2500,  99.0000,  92.2500,
         85.6250, 107.3750,  83.3125,  93.8125,  92.8750,  83.7500, 103.7500,
         88.6875,  82.0000, 111.3750,  84.8750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 94.5000,  93.0000,  89.7500,  94.0000,  91.0625,  94.6250,  90.3750,
         90.6875, 104.0625,  86.4375,  92.8750,  91.7500,  84.9375,  98.8125,
         89.7500,  87.1875, 110.1250,  89.1875], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [3.3355332e-09 2.1323349e-10 5.0147712e-12 4.8531716e-09 2.4162522e-10
 4.1448939e-06 4.8531716e-09 6.4390932e-12 1.7977519e-02 6.3755658e-13
 2.3153188e-08 9.0669197e-09 9.8746694e-13 4.7908459e-04 1.3767389e-10
 1.7159601e-13 9.8153919e-01 3.0416125e-12]
parser result:  [2.34378099e-11 4.65941088e-12 1.79807847e-13 8.20538680e-12
 0.00000000e+00 4.17088284e-13 2.15674621e-13 4.53566471e-13
 4.96160557e-07 5.13290460e-11 1.38026205e-05 4.48105434e-06
 1.64801491e-15 5.23100366e-03 1.40917085e-09 4.67640037e-08
 9.94750168e-01 1.00926104e-13]
clip * parser result:  [7.81775928e-20 9.93542426e-22 9.01695206e-25 3.98221505e-20
 0.00000000e+00 1.72878667e-18 1.04670595e-21 2.92055677e-24
 8.91973582e-09 3.27251708e-23 3.19574664e-13 4.06293597e-14
 1.62736025e-27 2.50609322e-06 1.94006028e-19 8.02451661e-21
 9.76386274e-01 3.06978104e-25]
CLIP result after softmax:  [7.81775928e-20 9.93542426e-22 9.01695206e-25 3.98221505e-20
 0.00000000e+00 1.72878667e-18 1.04670595e-21 2.92055677e-24
 8.91973582e-09 3.27251708e-23 3.19574664e-13 4.06293597e-14
 1.62736025e-27 2.50609322e-06 1.94006028e-19 8.02451661e-21
 9.76386274e-01 3.06978104e-25]
predicts:  16
The Final Result:  {'probs': array([7.81775928e-20, 9.93542426e-22, 9.01695206e-25, 3.98221505e-20,
       0.00000000e+00, 1.72878667e-18, 1.04670595e-21, 2.92055677e-24,
       8.91973582e-09, 3.27251708e-23, 3.19574664e-13, 4.06293597e-14,
       1.62736025e-27, 2.50609322e-06, 1.94006028e-19, 8.02451661e-21,
       9.76386274e-01, 3.06978104e-25]), 'pred': 16, 'box': Box(x=351.82, y=242.36, w=213.32, h=182.06), 'texts': (['the table', 'sup:right'], [([1.6335526709099213e-07, 3.6449488760581517e-08, 1.413299921537714e-09, 9.907996911806549e-08, 5.2510467085653545e-09, 1.8510579025132756e-07, 2.640392127162272e-09, 3.608987997338886e-09, 0.0023231334052979946, 5.147944917571756e-11, 3.21665609703814e-08, 1.0442952280698137e-08, 1.1486618080314148e-11, 1.2190685083623976e-05, 1.413299921537714e-09, 1.0898200397679858e-10, 0.9976643323898315, 8.052741251596274e-10], [1.6335526709099213e-07, 3.6449488760581517e-08, 1.413299921537714e-09, 9.907996911806549e-08, 5.2510467085653545e-09, 1.8510579025132756e-07, 2.640392127162272e-09, 3.608987997338886e-09, 0.0023231334052979946, 5.147944917571756e-11, 3.21665609703814e-08, 1.0442952280698137e-08, 1.1486618080314148e-11, 1.2190685083623976e-05, 1.413299921537714e-09, 1.0898200397679858e-10, 0.9976643323898315, 8.052741251596274e-10]), ([2.3437809936636205e-11, 4.659410877478043e-12, 1.7980784741764175e-13, 8.205386800325088e-12, 0.0, 4.1708828437311745e-13, 2.1567462065144626e-13, 4.5356647098859347e-13, 4.961605567934838e-07, 5.1329046001795587e-11, 1.3802620458911272e-05, 4.4810543440828345e-06, 1.6480149121188607e-15, 0.00523100366209063, 1.409170854535346e-09, 4.676400365345731e-08, 0.9947501682403749, 1.0092610419438799e-13], None)], ('the table', 'the table', 'the right', 'the right'))}
the table on the right.
predicate correct
This is the original CLIP result:
tensor([ 95.3125,  86.6250,  84.7500,  90.6875,  89.9375, 100.2500,  88.0625,
         85.6250, 118.4375,  86.7500,  99.1875,  94.1250,  81.5000, 109.4375,
         93.5000,  87.3125, 129.8750,  85.6250], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [9.7654503e-16 1.6472480e-19 2.5261366e-20 9.5737115e-18 4.5223010e-18
 1.3615114e-13 6.9351732e-19 6.0598864e-20 1.0783313e-05 1.8665765e-19
 4.7052579e-14 2.9782941e-16 9.7948958e-22 1.3307664e-09 1.5941662e-16
 3.2759436e-19 9.9998927e-01 6.0598864e-20]
predicts:  16
The Final Result:  {'probs': array([9.7654503e-16, 1.6472480e-19, 2.5261366e-20, 9.5737115e-18,
       4.5223010e-18, 1.3615114e-13, 6.9351732e-19, 6.0598864e-20,
       1.0783313e-05, 1.8665765e-19, 4.7052579e-14, 2.9782941e-16,
       9.7948958e-22, 1.3307664e-09, 1.5941662e-16, 3.2759436e-19,
       9.9998927e-01, 6.0598864e-20], dtype=float32), 'pred': 16, 'box': Box(x=351.82, y=242.36, w=213.32, h=182.06), 'texts': ['the end of a table, with a pink tablecloth at which eight people are sitting.']}
the end of a table, with a pink tablecloth at which eight people are sitting.
predicate correct
  2%|███▌                                                                                                                                                                                                               | 85/5023 [01:23<2:01:32,  1.48s/it]This is the original CLIP result:
tensor([ 92.3750,  95.5000, 108.8750, 107.3750,  90.2500,  87.6250, 107.6250,
         92.3125, 116.5000, 107.2500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.3287713e-11 7.5762491e-10 4.8768896e-04 1.0881812e-04 3.9756501e-12
 2.8799516e-13 1.3972523e-04 3.1270916e-11 9.9916768e-01 9.6031654e-05]
predicts:  8
The Final Result:  {'probs': array([3.3287713e-11, 7.5762491e-10, 4.8768896e-04, 1.0881812e-04,
       3.9756501e-12, 2.8799516e-13, 1.3972523e-04, 3.1270916e-11,
       9.9916768e-01, 9.6031654e-05], dtype=float32), 'pred': 8, 'box': Box(x=185.79, y=225.65, w=126.64, h=126.63), 'texts': ['the small 1 person chair in the corner']}
the small 1 person chair in the corner
predicate correct
This is the original CLIP result:
tensor([ 86.3750,  89.6250, 113.8750, 101.1250,  88.8750,  86.3750, 111.1250,
         94.7500, 123.5000, 113.6875], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [7.5294459e-17 1.9418696e-15 6.6048247e-05 1.9169319e-10 9.1727442e-16
 7.5294459e-17 4.2223232e-06 3.2657229e-13 9.9987495e-01 5.4755921e-05]
predicts:  8
The Final Result:  {'probs': array([7.5294459e-17, 1.9418696e-15, 6.6048247e-05, 1.9169319e-10,
       9.1727442e-16, 7.5294459e-17, 4.2223232e-06, 3.2657229e-13,
       9.9987495e-01, 5.4755921e-05], dtype=float32), 'pred': 8, 'box': Box(x=185.79, y=225.65, w=126.64, h=126.63), 'texts': ['the only red chair made for one person that can entirely be seen.']}
the only red chair made for one person that can entirely be seen.
predicate correct
  2%|███▌                                                                                                                                                                                                               | 86/5023 [01:24<1:51:10,  1.35s/it]This is the original CLIP result:
tensor([ 76.1250,  99.6250,  88.9375,  77.3750,  77.4375,  78.1250,  77.5000,
        111.9375], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.7978660e-16 4.4951812e-06 1.0261833e-10 9.7655106e-16 1.0395333e-15
 2.0673590e-15 1.1065774e-15 9.9999547e-01]
predicts:  7
The Final Result:  {'probs': array([2.7978660e-16, 4.4951812e-06, 1.0261833e-10, 9.7655106e-16,
       1.0395333e-15, 2.0673590e-15, 1.1065774e-15, 9.9999547e-01],
      dtype=float32), 'pred': 7, 'box': Box(x=102.16, y=106.46, w=154.96, h=131.0), 'texts': ['the woman holding the cow wearing all white.']}
the woman holding the cow wearing all white.
This is the original CLIP result:
tensor([ 80.6250, 111.5625, 101.7500,  80.2500,  79.1875,  80.2500,  79.3750,
        130.0000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.60337879e-22 9.83321335e-09 5.38494000e-13 2.47656381e-22
 8.55877542e-23 2.47656381e-22 1.03238536e-22 1.00000000e+00]
predicts:  7
The Final Result:  {'probs': array([3.60337879e-22, 9.83321335e-09, 5.38494000e-13, 2.47656381e-22,
       8.55877542e-23, 2.47656381e-22, 1.03238536e-22, 1.00000000e+00],
      dtype=float32), 'pred': 7, 'box': Box(x=102.16, y=106.46, w=154.96, h=131.0), 'texts': ['a woman dressed in white leading a black and white cow by a rope down the street.']}
a woman dressed in white leading a black and white cow by a rope down the street.
  2%|███▋                                                                                                                                                                                                               | 87/5023 [01:24<1:33:17,  1.13s/it]This is the original CLIP result:
tensor([120.6875,  94.3750, 105.3750,  85.0000, 139.5000,  94.6250,  79.1250,
         75.0625], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [6.7582620e-09 2.5261637e-20 1.5125189e-15 2.1426476e-24 1.0000000e+00
 3.2436582e-20 6.0182561e-27 1.0354981e-28]
predicts:  4
The Final Result:  {'probs': array([6.7582620e-09, 2.5261637e-20, 1.5125189e-15, 2.1426476e-24,
       1.0000000e+00, 3.2436582e-20, 6.0182561e-27, 1.0354981e-28],
      dtype=float32), 'pred': 4, 'box': Box(x=248.97, y=53.9, w=244.17, h=310.85), 'texts': ['a person in a blue and white plaid shirt shearing a sheep']}
a person in a blue and white plaid shirt shearing a sheep
predicate correct
This is the original CLIP result:
tensor([132.7500,  90.8750, 108.0000,  88.8125, 147.7500,  94.1250,  79.7500,
         77.5625], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.0590220e-07 1.9929720e-25 5.4549927e-18 2.5337795e-26 9.9999964e-01
 5.1399423e-24 2.9374808e-30 3.2957624e-31]
predicts:  4
The Final Result:  {'probs': array([3.0590220e-07, 1.9929720e-25, 5.4549927e-18, 2.5337795e-26,
       9.9999964e-01, 5.1399423e-24, 2.9374808e-30, 3.2957624e-31],
      dtype=float32), 'pred': 4, 'box': Box(x=248.97, y=53.9, w=244.17, h=310.85), 'texts': ['a person in blue jeans, bending over a sheep and shearing its wool off.']}
a person in blue jeans, bending over a sheep and shearing its wool off.
predicate correct
  2%|███▋                                                                                                                                                                                                               | 88/5023 [01:25<1:25:04,  1.03s/it]This is the original CLIP result:
tensor([ 86.0000,  94.0625, 102.8750, 106.7500,  98.8125], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 86.9375,  93.6250, 101.8750, 105.8125, 100.6875], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 86.9375,  93.6250, 101.8750, 105.8125, 100.6875], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [9.5348762e-10 3.0256192e-06 2.0325180e-02 9.7932202e-01 3.4971401e-04]
parser result:  [6.1912440e-09 4.9673213e-06 1.9013047e-02 9.7518331e-01 5.7986518e-03]
clip * parser result:  [5.9032745e-18 1.5029223e-11 3.8644360e-04 9.5501846e-01 2.0278699e-06]
CLIP result after softmax:  [5.9032745e-18 1.5029223e-11 3.8644360e-04 9.5501846e-01 2.0278699e-06]
predicts:  3
The Final Result:  {'probs': array([5.9032745e-18, 1.5029223e-11, 3.8644360e-04, 9.5501846e-01,
       2.0278699e-06], dtype=float32), 'pred': 3, 'box': Box(x=0.0, y=241.93, w=136.74, h=124.11), 'texts': (['a boat on a lift with a duck crossing sign on its left'], [([6.191243961950477e-09, 4.967321274307324e-06, 0.019013047218322754, 0.9751833081245422, 0.005798651836812496], [6.191243961950477e-09, 4.967321274307324e-06, 0.019013047218322754, 0.9751833081245422, 0.005798651836812496])], ('a boat', 'a boat', 'a lift', 'a lift', 'a duck crossing sign', 'a duck crossing sign', 'a duck crossing sign', 'a duck crossing sign', 'its left', 'its left'))}
a boat on a lift with a duck crossing sign on its left.
This is the original CLIP result:
tensor([ 79.6250,  99.3750, 110.6250, 115.1250,  78.7500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 90.3750,  96.0625,  96.8750, 102.1250,  89.6250], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 90.6250, 107.2500, 115.1250, 116.1250,  85.1250], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [3.7822292e-16 1.4291041e-07 1.0986941e-02 9.8901296e-01 1.5766679e-16]
parser result:  [2.28884892e-11 3.79097704e-04 9.99620902e-01 0.00000000e+00
 9.35396651e-14]
clip * parser result:  [8.65695125e-27 5.41770078e-11 1.09827758e-02 0.00000000e+00
 1.47480989e-29]
CLIP result after softmax:  [8.65695125e-27 5.41770078e-11 1.09827758e-02 0.00000000e+00
 1.47480989e-29]
predicts:  2
The Final Result:  {'probs': array([8.65695125e-27, 5.41770078e-11, 1.09827758e-02, 0.00000000e+00,
       1.47480989e-29]), 'pred': 2, 'box': Box(x=426.95, y=266.03, w=204.9, h=100.07), 'texts': (['a boat', 'the pole'], [([6.1574161568100916e-12, 0.00010222197306575254, 0.2689139246940613, 0.7309837937355042, 2.51639495644964e-14], [6.1574161568100916e-12, 0.00010222197306575254, 0.2689139246940613, 0.7309837937355042, 2.51639495644964e-14]), ([2.2888489152366244e-11, 0.0003790977035282121, 0.9996209022734897, 0.0, 9.353966510353461e-14], [7.829913556633983e-06, 0.002311036689206958, 0.005208001937717199, 0.9924694895744324, 3.69858958038094e-06])], ('a boat', 'a boat', 'the right', 'the right', 'the pole', 'the pole'))}
a boat to the right of the pole.
predicate correct
  2%|███▋                                                                                                                                                                                                               | 89/5023 [01:27<1:34:35,  1.15s/it]This is the original CLIP result:
tensor([ 65.5000,  73.5000,  71.4375,  80.6250, 101.6250,  84.0625,  83.8125,
         83.6875,  83.4375,  81.1250,  80.8750,  88.8750,  77.5625,  68.3750,
        101.0000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.3333024e-16 3.9745185e-13 5.0530330e-14 4.9389282e-10 6.5135360e-01
 1.5364554e-08 1.1965926e-08 1.0559893e-08 8.2240543e-09 8.1429152e-10
 6.3417094e-10 1.8904369e-06 2.3099675e-11 2.3633350e-15 3.4864444e-01]
predicts:  4
The Final Result:  {'probs': array([1.3333024e-16, 3.9745185e-13, 5.0530330e-14, 4.9389282e-10,
       6.5135360e-01, 1.5364554e-08, 1.1965926e-08, 1.0559893e-08,
       8.2240543e-09, 8.1429152e-10, 6.3417094e-10, 1.8904369e-06,
       2.3099675e-11, 2.3633350e-15, 3.4864444e-01], dtype=float32), 'pred': 4, 'box': Box(x=213.02, y=260.04, w=62.37, h=55.65), 'texts': ['a sofa with a teddy bear']}
a sofa with a teddy bear
This is the original CLIP result:
tensor([ 75.1875,  83.6250,  80.5625,  86.3750, 112.2500,  90.1875,  90.0000,
         89.6250,  88.4375,  90.5625,  88.0625,  94.7500,  85.6250,  79.2500,
        106.8125], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [7.9813354e-17 3.6849809e-13 1.7234884e-14 5.7642801e-12 9.9566853e-01
 2.6091124e-10 2.1630300e-10 1.4866273e-10 4.5339572e-11 3.7962358e-10
 3.1161403e-11 2.5001228e-08 2.7228528e-12 4.6387061e-15 4.3315021e-03]
predicts:  4
The Final Result:  {'probs': array([7.9813354e-17, 3.6849809e-13, 1.7234884e-14, 5.7642801e-12,
       9.9566853e-01, 2.6091124e-10, 2.1630300e-10, 1.4866273e-10,
       4.5339572e-11, 3.7962358e-10, 3.1161403e-11, 2.5001228e-08,
       2.7228528e-12, 4.6387061e-15, 4.3315021e-03], dtype=float32), 'pred': 4, 'box': Box(x=213.02, y=260.04, w=62.37, h=55.65), 'texts': ['the teddy bear that is sitting down.']}
the teddy bear that is sitting down.
  2%|███▊                                                                                                                                                                                                               | 90/5023 [01:28<1:39:04,  1.21s/it]This is the original CLIP result:
tensor([ 89.0000, 102.9375,  79.6250,  68.9375], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [8.8515696e-07 9.9999917e-01 7.5077451e-11 1.7139070e-15]
predicts:  1
The Final Result:  {'probs': array([8.8515696e-07, 9.9999917e-01, 7.5077451e-11, 1.7139070e-15],
      dtype=float32), 'pred': 1, 'box': Box(x=62.84, y=126.5, w=316.39, h=345.64), 'texts': ['a woman wearing a turtleneck and jeans.']}
a woman wearing a turtleneck and jeans.
predicate correct
This is the original CLIP result:
tensor([ 89.3750, 125.2500,  92.1875,  69.8750], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [2.6283636e-16 1.0000000e+00 4.3766184e-15 8.9318835e-25]
predicts:  1
The Final Result:  {'probs': array([2.6283636e-16, 1.0000000e+00, 4.3766184e-15, 8.9318835e-25],
      dtype=float32), 'pred': 1, 'box': Box(x=62.84, y=126.5, w=316.39, h=345.64), 'texts': ['a woman in a light green turtleneck sweater sitting on the beach at night.']}
a woman in a light green turtleneck sweater sitting on the beach at night.
predicate correct
  2%|███▊                                                                                                                                                                                                               | 91/5023 [01:28<1:20:41,  1.02it/s]This is the original CLIP result:
tensor([ 77.8750,  88.4375, 120.6250, 108.8750,  90.6250,  88.5000,  91.5000,
         77.9375,  75.8125,  71.2500,  80.8750,  87.5000,  93.5000,  93.9375,
         84.3750,  82.0000,  91.5000,  83.3750], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [2.71586039e-19 1.04988785e-14 9.99992132e-01 7.88926263e-06
 9.35754905e-14 1.11759983e-14 2.24475928e-13 2.89101847e-19
 3.45282927e-20 3.60335051e-22 5.45495174e-18 4.11142042e-15
 1.65866539e-12 2.56899124e-12 1.80643209e-16 1.68024338e-17
 2.24475928e-13 6.64549162e-17]
predicts:  2
The Final Result:  {'probs': array([2.71586039e-19, 1.04988785e-14, 9.99992132e-01, 7.88926263e-06,
       9.35754905e-14, 1.11759983e-14, 2.24475928e-13, 2.89101847e-19,
       3.45282927e-20, 3.60335051e-22, 5.45495174e-18, 4.11142042e-15,
       1.65866539e-12, 2.56899124e-12, 1.80643209e-16, 1.68024338e-17,
       2.24475928e-13, 6.64549162e-17], dtype=float32), 'pred': 2, 'box': Box(x=369.44, y=160.35, w=153.89, h=117.22), 'texts': ['a man with dark hair using a laptop']}
a man with dark hair using a laptop
predicate correct
This is the original CLIP result:
tensor([ 78.1875,  88.8750, 104.6875,  92.0625,  84.8750,  84.2500,  90.2500,
         83.6875,  76.7500,  75.0000,  90.4375,  85.1250,  95.0625,  90.3750,
         85.1875,  88.6250,  91.5000,  85.4375], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [3.09859191e-12 1.35733387e-07 9.99926686e-01 3.28851888e-06
 2.48604337e-09 1.33068312e-09 5.36835955e-07 7.58200447e-10
 7.35980125e-13 1.27894169e-13 6.47547722e-07 3.19214299e-09
 6.60516598e-05 6.08314792e-07 3.39801876e-09 1.05709255e-07
 1.87374144e-06 4.36314229e-09]
predicts:  2
The Final Result:  {'probs': array([3.09859191e-12, 1.35733387e-07, 9.99926686e-01, 3.28851888e-06,
       2.48604337e-09, 1.33068312e-09, 5.36835955e-07, 7.58200447e-10,
       7.35980125e-13, 1.27894169e-13, 6.47547722e-07, 3.19214299e-09,
       6.60516598e-05, 6.08314792e-07, 3.39801876e-09, 1.05709255e-07,
       1.87374144e-06, 4.36314229e-09], dtype=float32), 'pred': 2, 'box': Box(x=369.44, y=160.35, w=153.89, h=117.22), 'texts': ['a man wearing grey long sleeved shirt.']}
a man wearing grey long sleeved shirt.
predicate correct
  2%|███▊                                                                                                                                                                                                               | 92/5023 [01:30<1:36:33,  1.17s/it]This is the original CLIP result:
tensor([ 97.5000,  97.6875,  87.4375, 108.5000], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([106.6250, 101.5625,  98.4375, 106.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([106.6250, 101.5625,  98.4375, 106.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([ 70.2500,  89.0000,  77.5000, 116.7500], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.6701086e-05 2.0145355e-05 7.1228934e-10 9.9996316e-01]
parser result:  [1.76465677e-24 8.82243742e-13 0.00000000e+00 1.00000000e+00]
clip * parser result:  [2.94716840e-29 1.77731133e-17 0.00000000e+00 9.99963164e-01]
CLIP result after softmax:  [2.94716840e-29 1.77731133e-17 0.00000000e+00 9.99963164e-01]
predicts:  3
The Final Result:  {'probs': array([2.94716840e-29, 1.77731133e-17, 0.00000000e+00, 9.99963164e-01]), 'pred': 3, 'box': Box(x=0.0, y=12.96, w=73.9, h=372.81), 'texts': (['a black vehicle', 'a man'], [([6.38714214669426e-21, 8.878265418850451e-13, 8.993765228263497e-18, 1.0], [6.38714214669426e-21, 8.878265418850451e-13, 8.993765228263497e-18, 1.0]), ([1.7646567682192392e-24, 8.822437424238907e-13, 0.0, 0.9999999999991178], [0.5600958466529846, 0.003545247483998537, 0.00015576730947941542, 0.43620309233665466])], ('a black vehicle', 'a black vehicle', 'a black vehicle', 'the left', 'the left', 'a man', 'a man', 'a horse', 'a horse'))}
a black vehicle to the left of a man and a horse.
predicate correct
This is the original CLIP result:
tensor([ 72.3750, 100.7500,  75.2500, 116.9375], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [4.4335546e-20 9.3294922e-08 7.8586640e-19 9.9999988e-01]
predicts:  3
The Final Result:  {'probs': array([4.4335546e-20, 9.3294922e-08, 7.8586640e-19, 9.9999988e-01],
      dtype=float32), 'pred': 3, 'box': Box(x=0.0, y=12.96, w=73.9, h=372.81), 'texts': ['black bus with a large mirror.']}
black bus with a large mirror.
predicate correct
  2%|███▉                                                                                                                                                                                                               | 93/5023 [01:31<1:39:27,  1.21s/it]This is the original CLIP result:
tensor([ 76.1250,  87.2500,  98.6250, 113.0625, 121.1875, 105.3750],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.6882911e-20 1.8239055e-15 1.5889202e-10 2.9595708e-04 9.9970382e-01
 1.3570313e-07]
predicts:  4
The Final Result:  {'probs': array([2.6882911e-20, 1.8239055e-15, 1.5889202e-10, 2.9595708e-04,
       9.9970382e-01, 1.3570313e-07], dtype=float32), 'pred': 4, 'box': Box(x=323.6, y=217.76, w=138.75, h=102.92), 'texts': ['a fried egg in a cupcake paper.']}
a fried egg in a cupcake paper.
predicate correct
This is the original CLIP result:
tensor([ 90.1875,  98.4375,  92.5000, 119.4375, 112.5000,  92.1250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.9790876e-13 7.5752066e-10 1.9988078e-12 9.9903023e-01 9.6975191e-04
 1.3737591e-12]
predicts:  3
The Final Result:  {'probs': array([1.9790876e-13, 7.5752066e-10, 1.9988078e-12, 9.9903023e-01,
       9.6975191e-04, 1.3737591e-12], dtype=float32), 'pred': 3, 'box': Box(x=0.96, y=80.6, w=638.1, h=340.64), 'texts': ['an egg cup on a breakfast plate']}
an egg cup on a breakfast plate
  2%|███▉                                                                                                                                                                                                               | 94/5023 [01:32<1:24:51,  1.03s/it]This is the original CLIP result:
tensor([ 78.3750, 117.5000, 106.8125,  80.3750, 112.4375,  67.8125, 112.7500],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.0040620e-17 9.8521751e-01 2.2491055e-05 7.4190696e-17 6.2361462e-03
 2.5973173e-22 8.5238004e-03]
predicts:  1
The Final Result:  {'probs': array([1.0040620e-17, 9.8521751e-01, 2.2491055e-05, 7.4190696e-17,
       6.2361462e-03, 2.5973173e-22, 8.5238004e-03], dtype=float32), 'pred': 1, 'box': Box(x=326.25, y=46.06, w=281.15, h=380.94), 'texts': ['bride in her wedding dress and vail cutting the cake with her groom.']}
bride in her wedding dress and vail cutting the cake with her groom.
This is the original CLIP result:
tensor([ 87.0000, 103.0000, 109.2500,  88.5625, 120.3750,  74.1250, 124.1250],
       device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [7.3573566e-17 6.5378292e-10 3.3866795e-07 3.5099987e-16 2.2977363e-02
 1.8844316e-22 9.7702229e-01]
predicts:  6
The Final Result:  {'probs': array([7.3573566e-17, 6.5378292e-10, 3.3866795e-07, 3.5099987e-16,
       2.2977363e-02, 1.8844316e-22, 9.7702229e-01], dtype=float32), 'pred': 6, 'box': Box(x=0.0, y=293.34, w=462.17, h=133.66), 'texts': ['a woman in a wedding dress cutting a cake']}
a woman in a wedding dress cutting a cake
  2%|███▉                                                                                                                                                                                                               | 95/5023 [01:33<1:17:32,  1.06it/s]This is the original CLIP result:
tensor([ 87.0625,  83.3125, 116.8125,  93.1250,  76.5000,  77.7500,  84.8750,
         92.1250,  85.5000,  70.3750,  83.1250,  97.8750,  93.9375,  91.8125,
         90.5000,  85.5000], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 87.0625,  83.3125, 116.8125,  93.1250,  76.5000,  77.7500,  84.8750,
         92.1250,  85.5000,  70.3750,  83.1250,  97.8750,  93.9375,  91.8125,
         90.5000,  85.5000], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 87.0625,  83.3125, 116.8125,  93.1250,  76.5000,  77.7500,  84.8750,
         92.1250,  85.5000,  70.3750,  83.1250,  97.8750,  93.9375,  91.8125,
         90.5000,  85.5000], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.20154266e-13 2.82575739e-15 1.00000000e+00 5.15999708e-11
 3.10816217e-18 1.08485515e-17 1.34809334e-14 1.89825690e-11
 2.51856997e-14 6.79907728e-21 2.34263500e-15 5.96414562e-09
 1.16282331e-10 1.38879429e-11 3.73788934e-12 2.51856997e-14]
parser result:  [1.20154266e-13 2.82575739e-15 1.00000000e+00 5.15999708e-11
 3.10816217e-18 1.08485515e-17 1.34809334e-14 1.89825690e-11
 2.51856997e-14 6.79907728e-21 2.34263500e-15 5.96414562e-09
 1.16282331e-10 1.38879429e-11 3.73788934e-12 2.51856997e-14]
clip * parser result:  [1.44370482e-26 7.98490480e-30 1.00000000e+00 2.66255707e-21
 9.66067233e-36 1.17691068e-34 1.81735564e-28 3.60337929e-22
 6.34319472e-28 4.62274350e-41 5.48793888e-30 3.55710328e-17
 1.35215806e-20 1.92874951e-22 1.39718168e-23 6.34319472e-28]
CLIP result after softmax:  [1.44370482e-26 7.98490480e-30 1.00000000e+00 2.66255707e-21
 9.66067233e-36 1.17691068e-34 1.81735564e-28 3.60337929e-22
 6.34319472e-28 4.62274350e-41 5.48793888e-30 3.55710328e-17
 1.35215806e-20 1.92874951e-22 1.39718168e-23 6.34319472e-28]
predicts:  2
The Final Result:  {'probs': array([1.44370482e-26, 7.98490480e-30, 1.00000000e+00, 2.66255707e-21,
       9.66067233e-36, 1.17691068e-34, 1.81735564e-28, 3.60337929e-22,
       6.34319472e-28, 4.62274350e-41, 5.48793888e-30, 3.55710328e-17,
       1.35215806e-20, 1.92874951e-22, 1.39718168e-23, 6.34319472e-28],
      dtype=float32), 'pred': 2, 'box': Box(x=398.02, y=17.26, w=240.54, h=424.99), 'texts': (['back view of man in black shirts head'], [([1.2015426631081794e-13, 2.825757392698391e-15, 1.0, 5.1599970823934527e-11, 3.1081621709409722e-18, 1.0848551488610538e-17, 1.348093339026803e-14, 1.8982568988912263e-11, 2.5185699676515995e-14, 6.7990772839521e-21, 2.342634998814719e-15, 5.964145621817352e-09, 1.1628233098637253e-10, 1.3887942879042825e-11, 3.737889338328859e-12, 2.5185699676515995e-14], [1.2015426631081794e-13, 2.825757392698391e-15, 1.0, 5.1599970823934527e-11, 3.1081621709409722e-18, 1.0848551488610538e-17, 1.348093339026803e-14, 1.8982568988912263e-11, 2.5185699676515995e-14, 6.7990772839521e-21, 2.342634998814719e-15, 5.964145621817352e-09, 1.1628233098637253e-10, 1.3887942879042825e-11, 3.737889338328859e-12, 2.5185699676515995e-14])], ('back view', 'back view', 'man', 'black shirts', 'black shirts'))}
back view of man in black shirts head
predicate correct
This is the original CLIP result:
tensor([ 89.6250,  84.3750, 114.8750,  92.3750,  75.2500,  81.3125,  82.2500,
         98.7500,  80.6250,  76.9375,  78.0000,  82.3750,  81.0000,  84.1250,
         82.7500,  81.2500], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 89.8125,  85.8125, 106.7500,  98.5625,  82.7500,  82.1875,  90.2500,
        102.2500,  88.3750,  81.4375,  83.2500,  88.0625,  87.0000,  86.6250,
         93.0625,  88.9375], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([ 89.8125,  85.8125, 106.7500,  98.5625,  82.7500,  82.1875,  90.2500,
        102.2500,  88.3750,  81.4375,  83.2500,  88.0625,  87.0000,  86.6250,
         93.0625,  88.9375], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.0815941e-11 5.6756845e-14 9.9999988e-01 1.6918977e-10 6.1813181e-18
 2.6545530e-15 6.7786382e-15 9.9311919e-08 1.3347930e-15 3.3415890e-17
 9.6692087e-17 7.6812039e-15 1.9421123e-15 4.4202272e-14 1.1176085e-14
 2.4937217e-15]
parser result:  [4.3573181e-08 7.9807072e-10 9.8873991e-01 2.7497677e-04 3.7326264e-11
 2.1267861e-11 6.7487470e-08 1.0983909e-02 1.0349537e-08 1.0046227e-11
 6.1540599e-11 7.5718845e-09 2.6167730e-09 1.7984800e-09 1.1237671e-06
 1.8164004e-08]
clip * parser result:  [4.7128496e-19 4.5295977e-23 9.8873979e-01 4.6523258e-14 2.3072552e-28
 5.6456661e-26 4.5747314e-22 1.0908330e-09 1.3814490e-23 3.3570360e-28
 5.9504887e-27 5.8161187e-23 5.0820672e-24 7.9496902e-23 1.2559317e-20
 4.5295970e-23]
CLIP result after softmax:  [4.7128496e-19 4.5295977e-23 9.8873979e-01 4.6523258e-14 2.3072552e-28
 5.6456661e-26 4.5747314e-22 1.0908330e-09 1.3814490e-23 3.3570360e-28
 5.9504887e-27 5.8161187e-23 5.0820672e-24 7.9496902e-23 1.2559317e-20
 4.5295970e-23]
predicts:  2
The Final Result:  {'probs': array([4.7128496e-19, 4.5295977e-23, 9.8873979e-01, 4.6523258e-14,
       2.3072552e-28, 5.6456661e-26, 4.5747314e-22, 1.0908330e-09,
       1.3814490e-23, 3.3570360e-28, 5.9504887e-27, 5.8161187e-23,
       5.0820672e-24, 7.9496902e-23, 1.2559317e-20, 4.5295970e-23],
      dtype=float32), 'pred': 2, 'box': Box(x=398.02, y=17.26, w=240.54, h=424.99), 'texts': (['a man in a black shirt sits'], [([4.357318061920523e-08, 7.980707206201032e-10, 0.9887399077415466, 0.0002749767736531794, 3.732626360775093e-11, 2.1267860736418065e-11, 6.74874698347594e-08, 0.010983908548951149, 1.0349537227227756e-08, 1.0046226871229802e-11, 6.154059900564945e-11, 7.571884452772792e-09, 2.6167730204917916e-09, 1.798480031567351e-09, 1.1237671060371213e-06, 1.8164003634524306e-08], [4.357318061920523e-08, 7.980707206201032e-10, 0.9887399077415466, 0.0002749767736531794, 3.732626360775093e-11, 2.1267860736418065e-11, 6.74874698347594e-08, 0.010983908548951149, 1.0349537227227756e-08, 1.0046226871229802e-11, 6.154059900564945e-11, 7.571884452772792e-09, 2.6167730204917916e-09, 1.798480031567351e-09, 1.1237671060371213e-06, 1.8164003634524306e-08])], ('a man', 'a man', 'a black shirt', 'a black shirt', 'a black shirt', 'a man', 'a man', 'a green shirt', 'a green shirt', 'a green shirt'))}
a man in a black shirt sits behind a man in a green shirt.
predicate correct
  2%|████                                                                                                                                                                                                               | 96/5023 [01:37<2:41:30,  1.97s/it]This is the original CLIP result:
tensor([112.0000, 112.1875, 125.6250], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([106.8750, 107.5000, 124.5000], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([106.8750, 107.5000, 124.5000], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.2098640e-06 1.4593745e-06 9.9999738e-01]
parser result:  [2.2159490e-08 4.1399375e-08 1.0000000e+00]
clip * parser result:  [2.6809968e-14 6.0417193e-14 9.9999738e-01]
CLIP result after softmax:  [2.6809968e-14 6.0417193e-14 9.9999738e-01]
predicts:  2
The Final Result:  {'probs': array([2.6809968e-14, 6.0417193e-14, 9.9999738e-01], dtype=float32), 'pred': 2, 'box': Box(x=0.0, y=0.0, w=533.43, h=158.51), 'texts': (['half of a sandwich hidden behind a napkin'], [([2.2159490242756874e-08, 4.139937459513021e-08, 1.0], [2.2159490242756874e-08, 4.139937459513021e-08, 1.0])], ('half', 'a sandwich', 'a sandwich', 'a napkin', 'a napkin'))}
half of a sandwich hidden behind a napkin.
predicate correct
This is the original CLIP result:
tensor([107.7500, 108.6875, 123.2500], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([114.1875, 112.3750, 122.6250], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([87.6250, 90.7500, 98.6250], device='cuda:0', dtype=torch.float16)
This is the original CLIP result:
tensor([87.6250, 90.7500, 98.6250], device='cuda:0', dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.8553902e-07 4.7379044e-07 9.9999928e-01]
parser result:  [1.6695076e-05 3.7997816e-04 9.9960333e-01]
clip * parser result:  [3.0975879e-12 1.8003002e-10 9.9960262e-01]
CLIP result after softmax:  [3.0975879e-12 1.8003002e-10 9.9960262e-01]
predicts:  2
The Final Result:  {'probs': array([3.0975879e-12, 1.8003002e-10, 9.9960262e-01], dtype=float32), 'pred': 2, 'box': Box(x=0.0, y=0.0, w=533.43, h=158.51), 'texts': (['half on a white plate'], [([1.6695075828465633e-05, 0.0003799781552515924, 0.9996033310890198], [1.6695075828465633e-05, 0.0003799781552515924, 0.9996033310890198])], ('half', 'sandwich', 'napkin', 'a white plate', 'a white plate', 'a white plate'))}
half of sandwich under napkin on a white plate
predicate correct
  2%|████                                                                                                                                                                                                               | 97/5023 [01:38<2:28:01,  1.80s/it]This is the original CLIP result:
tensor([106.1250, 101.3750, 104.6875, 105.4375, 109.5000], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([110.7500, 104.8125, 112.2500, 112.8750, 113.6250], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([110.7500, 104.8125, 112.2500, 112.8750, 113.6250], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [3.2285884e-02 2.7932765e-04 7.6685706e-03 1.6234362e-02 9.4353187e-01]
parser result:  [0.00000000e+00 2.81473055e-04 2.83479366e-01 6.56364279e-01
 5.98748810e-02]
clip * parser result:  [0.00000000e+00 7.86232072e-08 2.17388154e-03 1.06556556e-02
 5.64938585e-02]
CLIP result after softmax:  [0.00000000e+00 7.86232072e-08 2.17388154e-03 1.06556556e-02
 5.64938585e-02]
predicts:  4
The Final Result:  {'probs': array([0.00000000e+00, 7.86232072e-08, 2.17388154e-03, 1.06556556e-02,
       5.64938585e-02]), 'pred': 4, 'box': Box(x=394.06, y=3.92, w=245.94, h=384.26), 'texts': (['the brown chair on which cats playing', 'sup:front'], [([0.0316629521548748, 8.354643796337768e-05, 0.14190351963043213, 0.26511067152023315, 0.5612393021583557], [0.0316629521548748, 8.354643796337768e-05, 0.14190351963043213, 0.26511067152023315, 0.5612393021583557]), ([0.0, 0.0002814730549903181, 0.28347936647438987, 0.6563642794901879, 0.05987488098043183], None)], ('the brown chair', 'the brown chair', 'the brown chair', 'the front', 'the front', 'on which cats', 'on which cats', 'on which cats'))}
the brown chair in the front on which cats is playing
This is the original CLIP result:
tensor([106.1250, 101.3750, 104.6875, 105.4375, 109.5000], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([110.7500, 104.8125, 112.2500, 112.8750, 113.6250], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([110.7500, 104.8125, 112.2500, 112.8750, 113.6250], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [3.2285884e-02 2.7932765e-04 7.6685706e-03 1.6234362e-02 9.4353187e-01]
parser result:  [0.00000000e+00 2.81473055e-04 2.83479366e-01 6.56364279e-01
 5.98748810e-02]
clip * parser result:  [0.00000000e+00 7.86232072e-08 2.17388154e-03 1.06556556e-02
 5.64938585e-02]
CLIP result after softmax:  [0.00000000e+00 7.86232072e-08 2.17388154e-03 1.06556556e-02
 5.64938585e-02]
predicts:  4
The Final Result:  {'probs': array([0.00000000e+00, 7.86232072e-08, 2.17388154e-03, 1.06556556e-02,
       5.64938585e-02]), 'pred': 4, 'box': Box(x=394.06, y=3.92, w=245.94, h=384.26), 'texts': (['the brown chair on which cats playing', 'sup:front'], [([0.0316629521548748, 8.354643796337768e-05, 0.14190351963043213, 0.26511067152023315, 0.5612393021583557], [0.0316629521548748, 8.354643796337768e-05, 0.14190351963043213, 0.26511067152023315, 0.5612393021583557]), ([0.0, 0.0002814730549903181, 0.28347936647438987, 0.6563642794901879, 0.05987488098043183], None)], ('the brown chair', 'the brown chair', 'the brown chair', 'the front', 'the front', 'on which cats', 'on which cats', 'on which cats'))}
the brown chair in the front on which cats is playing
  2%|████                                                                                                                                                                                                               | 98/5023 [01:40<2:19:30,  1.70s/it]This is the original CLIP result:
tensor([ 88.9375, 119.7500, 123.0625,  94.5625,  95.1250,  89.0000,  91.4375,
         93.6250, 124.5625], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.7410066e-16 6.6009867e-03 1.8122132e-01 7.6000519e-14 1.3338506e-13
 2.9177863e-16 3.3392296e-15 2.9762231e-14 8.1217760e-01]
predicts:  8
The Final Result:  {'probs': array([2.7410066e-16, 6.6009867e-03, 1.8122132e-01, 7.6000519e-14,
       1.3338506e-13, 2.9177863e-16, 3.3392296e-15, 2.9762231e-14,
       8.1217760e-01], dtype=float32), 'pred': 8, 'box': Box(x=390.14, y=323.45, w=249.86, h=156.55), 'texts': ['a brown couch in a living room']}
a brown couch in a living room
predicate correct
This is the original CLIP result:
tensor([ 84.6250, 113.5000, 107.6250,  96.7500,  96.3750,  95.0625,  96.0000,
         96.7500, 110.0625], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [2.7850037e-13 9.6622658e-01 2.7139317e-03 5.1362530e-08 3.5300914e-08
 9.5011119e-09 2.4261940e-08 5.1362530e-08 3.1059304e-02]
predicts:  1
The Final Result:  {'probs': array([2.7850037e-13, 9.6622658e-01, 2.7139317e-03, 5.1362530e-08,
       3.5300914e-08, 9.5011119e-09, 2.4261940e-08, 5.1362530e-08,
       3.1059304e-02], dtype=float32), 'pred': 1, 'box': Box(x=85.86, y=234.31, w=161.38, h=155.17), 'texts': ['chair']}
chair
  2%|████▏                                                                                                                                                                                                              | 99/5023 [01:41<2:00:09,  1.46s/it]This is the original CLIP result:
tensor([106.5000, 105.7500], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.6791787 0.3208213]
predicts:  0
The Final Result:  {'probs': array([0.6791787, 0.3208213], dtype=float32), 'pred': 0, 'box': Box(x=41.91, y=55.21, w=264.07, h=130.37), 'texts': ['an airplane heading down the runway.']}
an airplane heading down the runway.
This is the original CLIP result:
tensor([109.2500, 113.6250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.01243165 0.9875683 ]
predicts:  1
The Final Result:  {'probs': array([0.01243165, 0.9875683 ], dtype=float32), 'pred': 1, 'box': Box(x=293.33, y=41.55, w=310.6, h=99.96), 'texts': ['the plane facing away from the camera']}
the plane facing away from the camera
predicate correct
  2%|████▏                                                                                                                                                                                                             | 100/5023 [01:41<1:32:04,  1.12s/it]This is the original CLIP result:
tensor([111.4375, 108.9375, 119.1250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [4.5829566e-04 3.7619197e-05 9.9950409e-01]
predicts:  2
The Final Result:  {'probs': array([4.5829566e-04, 3.7619197e-05, 9.9950409e-01], dtype=float32), 'pred': 2, 'box': Box(x=10.11, y=105.43, w=360.68, h=366.29), 'texts': ['three zebras standing on a rock']}
three zebras standing on a rock
predicate correct
This is the original CLIP result:
tensor([112.7500, 108.8125, 117.6250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [7.5761210e-03 1.4771086e-04 9.9227613e-01]
predicts:  2
The Final Result:  {'probs': array([7.5761210e-03, 1.4771086e-04, 9.9227613e-01], dtype=float32), 'pred': 2, 'box': Box(x=10.11, y=105.43, w=360.68, h=366.29), 'texts': ['a zebra standing between two fighting zebras']}
a zebra standing between two fighting zebras
predicate correct
  2%|████▏                                                                                                                                                                                                             | 101/5023 [01:41<1:13:33,  1.12it/s]This is the original CLIP result:
tensor([118.5000,  99.2500, 124.1250, 118.0000, 107.8750, 120.8750,  93.0000,
         88.6250,  96.8750], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.4526826e-03 1.5065650e-11 9.5733315e-01 2.0941580e-03 8.3903053e-08
 3.7119836e-02 2.9083544e-14 3.6610781e-16 1.4013236e-12]
predicts:  2
The Final Result:  {'probs': array([3.4526826e-03, 1.5065650e-11, 9.5733315e-01, 2.0941580e-03,
       8.3903053e-08, 3.7119836e-02, 2.9083544e-14, 3.6610781e-16,
       1.4013236e-12], dtype=float32), 'pred': 2, 'box': Box(x=318.74, y=145.48, w=232.99, h=144.0), 'texts': ['the motorcycle rier in black']}
the motorcycle rier in black
This is the original CLIP result:
tensor([111.8125,  84.0000, 118.8750, 113.5625, 108.5625, 115.1875,  94.1250,
         88.7500,  96.5000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [8.3099434e-04 6.9307904e-16 9.7006947e-01 4.7820420e-03 3.2221149e-05
 2.4285214e-02 1.7298739e-11 8.0109049e-14 1.8597897e-10]
predicts:  2
The Final Result:  {'probs': array([8.3099434e-04, 6.9307904e-16, 9.7006947e-01, 4.7820420e-03,
       3.2221149e-05, 2.4285214e-02, 1.7298739e-11, 8.0109049e-14,
       1.8597897e-10], dtype=float32), 'pred': 2, 'box': Box(x=318.74, y=145.48, w=232.99, h=144.0), 'texts': ['a guy on a motorcycle']}
a guy on a motorcycle
  2%|████▎                                                                                                                                                                                                             | 102/5023 [01:42<1:10:40,  1.16it/s]This is the original CLIP result:
tensor([115.2500,  94.9375,  81.2500, 100.5000, 117.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([116.1250,  96.3750,  82.7500, 100.6250, 118.2500], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([116.1250,  96.3750,  82.7500, 100.6250, 118.2500], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [1.0669060e-01 1.6088644e-10 1.8285791e-16 4.1906613e-08 8.9330941e-01]
parser result:  [0.00000000e+00 2.96266135e-09 3.58442649e-15 2.07698581e-07
 9.99999789e-01]
clip * parser result:  [0.00000000e+00 4.76652046e-19 6.55440735e-31 8.70394413e-15
 8.93309226e-01]
CLIP result after softmax:  [0.00000000e+00 4.76652046e-19 6.55440735e-31 8.70394413e-15
 8.93309226e-01]
predicts:  4
The Final Result:  {'probs': array([0.00000000e+00, 4.76652046e-19, 6.55440735e-31, 8.70394413e-15,
       8.93309226e-01]), 'pred': 4, 'box': Box(x=192.16, y=117.33, w=156.88, h=133.31), 'texts': (['a smaller computer screen with a blue desktop background', 'sup:smaller'], [([0.10669060051441193, 2.823645206539993e-10, 3.416235548113711e-16, 1.979528185813706e-08, 0.8933094143867493], [0.10669060051441193, 2.823645206539993e-10, 3.416235548113711e-16, 1.979528185813706e-08, 0.8933094143867493]), ([0.0, 2.9626613480858836e-09, 3.584426494535881e-15, 2.0769858132361497e-07, 0.9999997893387538], None)], ('a smaller computer screen', 'a smaller computer screen', 'a smaller computer screen', 'a smaller computer screen', 'a blue desktop background', 'a blue desktop background', 'a blue desktop background', 'a blue desktop background'))}
a smaller computer screen with a blue desktop background.
predicate correct
This is the original CLIP result:
tensor([115.6250,  88.2500,  77.5000, 100.3750, 116.2500], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [3.4864509e-01 4.5037278e-13 9.6584280e-18 8.3060158e-08 6.5135485e-01]
predicts:  4
The Final Result:  {'probs': array([3.4864509e-01, 4.5037278e-13, 9.6584280e-18, 8.3060158e-08,
       6.5135485e-01], dtype=float32), 'pred': 4, 'box': Box(x=192.16, y=117.33, w=156.88, h=133.31), 'texts': ['a computer screen with a blue background and itunes open.']}
a computer screen with a blue background and itunes open.
predicate correct
  2%|████▎                                                                                                                                                                                                             | 103/5023 [01:43<1:12:19,  1.13it/s]This is the original CLIP result:
tensor([150.7500, 156.2500, 107.3125], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [4.0701381e-03 9.9592990e-01 5.5583074e-22]
predicts:  1
The Final Result:  {'probs': array([4.0701381e-03, 9.9592990e-01, 5.5583074e-22], dtype=float32), 'pred': 1, 'box': Box(x=52.26, y=167.91, w=284.67, h=252.42), 'texts': ['the row of bleacher seat the starbucks cup is sitting on.']}
the row of bleacher seat the starbucks cup is sitting on.
predicate correct
This is the original CLIP result:
tensor([129.5000, 137.5000,  93.0625], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [3.3535014e-04 9.9966466e-01 5.0221919e-20]
predicts:  1
The Final Result:  {'probs': array([3.3535014e-04, 9.9966466e-01, 5.0221919e-20], dtype=float32), 'pred': 1, 'box': Box(x=52.26, y=167.91, w=284.67, h=252.42), 'texts': ['a wooden bench with coffee on it.']}
a wooden bench with coffee on it.
predicate correct
  2%|████▎                                                                                                                                                                                                             | 104/5023 [01:44<1:00:19,  1.36it/s]This is the original CLIP result:
tensor([107.6250, 118.8750, 124.6875, 126.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([107.6250, 118.8750, 124.6875, 126.3750], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([107.6250, 118.8750, 124.6875, 126.3750], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [6.0682610e-09 4.6652745e-04 1.5603207e-01 8.4350139e-01]
parser result:  [0.00000000e+00 3.88906081e-08 9.99999961e-01 0.00000000e+00]
clip * parser result:  [0.00000000e+00 1.81435361e-11 1.56032064e-01 0.00000000e+00]
CLIP result after softmax:  [0.00000000e+00 1.81435361e-11 1.56032064e-01 0.00000000e+00]
predicts:  2
The Final Result:  {'probs': array([0.00000000e+00, 1.81435361e-11, 1.56032064e-01, 0.00000000e+00]), 'pred': 2, 'box': Box(x=356.23, y=55.85, w=194.71, h=187.17), 'texts': (['orange in top right corner of oranges', 'sup:top', 'sup:right'], [([6.068261004799069e-09, 0.0004665274464059621, 0.15603207051753998, 0.8435013890266418], [6.068261004799069e-09, 0.0004665274464059621, 0.15603207051753998, 0.8435013890266418]), ([0.0, 2.143412531102203e-11, 0.0005511388354699966, 0.9994488611430958], None), ([0.0, 3.889060813269987e-08, 0.9999999611093918, 0.0], None)], ('top right corner', 'top right corner', 'top right corner', 'oranges'))}
orange in top right corner of oranges
predicate correct
This is the original CLIP result:
tensor([114.1250, 117.0625, 118.0000, 119.5000], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([114.1250, 117.0625, 118.0000, 119.5000], device='cuda:0',
       dtype=torch.float16)
This is the original CLIP result:
tensor([114.1250, 117.0625, 118.0000, 119.5000], device='cuda:0',
       dtype=torch.float16)

 This is the parser result:
CLIP result:  [0.00352124 0.06644085 0.16966267 0.7603753 ]
parser result:  [0.00352124 0.06644085 0.16966267 0.7603753 ]
clip * parser result:  [1.2399107e-05 4.4143866e-03 2.8785421e-02 5.7817066e-01]
CLIP result after softmax:  [1.2399107e-05 4.4143866e-03 2.8785421e-02 5.7817066e-01]
predicts:  3
The Final Result:  {'probs': array([1.2399107e-05, 4.4143866e-03, 2.8785421e-02, 5.7817066e-01],
      dtype=float32), 'pred': 3, 'box': Box(x=45.18, y=37.65, w=182.21, h=192.75), 'texts': (['upper right hand orange in a group of three'], [([0.003521236591041088, 0.06644085049629211, 0.16966266930103302, 0.7603753209114075], [0.003521236591041088, 0.06644085049629211, 0.16966266930103302, 0.7603753209114075])], ('upper right hand orange', 'upper right hand orange', 'upper right hand orange', 'upper right hand orange', 'a group', 'a group'))}
upper right hand orange in a group of three
  2%|████▍                                                                                                                                                                                                             | 105/5023 [01:45<1:14:52,  1.09it/s]This is the original CLIP result:
tensor([117.2500,  99.5000,  96.3750], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.000000e+00 1.955568e-08 8.592166e-10]
predicts:  0
The Final Result:  {'probs': array([1.000000e+00, 1.955568e-08, 8.592166e-10], dtype=float32), 'pred': 0, 'box': Box(x=49.5, y=0.38, w=443.25, h=328.5), 'texts': ['sunglass wear woman bite something']}
sunglass wear woman bite something
predicate correct
This is the original CLIP result:
tensor([112.5000,  95.0625,  90.5000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [1.0000000e+00 2.6729447e-08 2.7894681e-10]
predicts:  0
The Final Result:  {'probs': array([1.0000000e+00, 2.6729447e-08, 2.7894681e-10], dtype=float32), 'pred': 0, 'box': Box(x=49.5, y=0.38, w=443.25, h=328.5), 'texts': ['the woman wearing the tortoise shell glasses.']}
the woman wearing the tortoise shell glasses.
predicate correct
  2%|████▍                                                                                                                                                                                                             | 106/5023 [01:45<1:00:28,  1.36it/s]This is the original CLIP result:
tensor([ 92.3750,  94.8750,  92.7500, 118.2500,  79.7500,  72.2500,  69.5625,
         65.2500,  73.0625,  65.1875,  64.2500,  69.6875,  85.5625,  69.6875,
         69.5000,  65.2500,  73.0000,  70.5000], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [5.78935641e-12 7.05287911e-11 8.42346418e-12 1.00000000e+00
 1.90398018e-17 1.05306175e-20 7.16617503e-22 9.60267995e-24
 2.37311122e-20 9.02088320e-24 3.53262839e-24 8.12033978e-22
 6.36794245e-15 8.12033978e-22 6.73199811e-22 9.60267995e-24
 2.22933156e-20 1.82994707e-21]
predicts:  3
The Final Result:  {'probs': array([5.78935641e-12, 7.05287911e-11, 8.42346418e-12, 1.00000000e+00,
       1.90398018e-17, 1.05306175e-20, 7.16617503e-22, 9.60267995e-24,
       2.37311122e-20, 9.02088320e-24, 3.53262839e-24, 8.12033978e-22,
       6.36794245e-15, 8.12033978e-22, 6.73199811e-22, 9.60267995e-24,
       2.22933156e-20, 1.82994707e-21], dtype=float32), 'pred': 3, 'box': Box(x=3.23, y=9.3, w=115.63, h=175.46), 'texts': ['the vespa that is parked up on the sidewalk on this side of the rainy street.']}
the vespa that is parked up on the sidewalk on this side of the rainy street.
predicate correct
This is the original CLIP result:
tensor([ 96.8750,  91.7500,  91.3750, 113.0000,  80.1250,  83.8750,  82.3125,
         76.7500,  84.2500,  76.2500,  74.1250,  80.3750,  88.3750,  80.2500,
         80.8125,  76.2500,  86.3750,  82.3750], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [9.93119187e-08 5.90530347e-10 4.05865147e-10 9.99999881e-01
 5.27920908e-15 2.24477663e-13 4.70530766e-14 1.80644599e-16
 3.26613113e-13 1.09566484e-16 1.30858509e-17 6.77863823e-15
 2.02068379e-11 5.98212741e-15 1.04989607e-14 1.09566484e-16
 2.73469767e-12 5.00877382e-14]
predicts:  3
The Final Result:  {'probs': array([9.93119187e-08, 5.90530347e-10, 4.05865147e-10, 9.99999881e-01,
       5.27920908e-15, 2.24477663e-13, 4.70530766e-14, 1.80644599e-16,
       3.26613113e-13, 1.09566484e-16, 1.30858509e-17, 6.77863823e-15,
       2.02068379e-11, 5.98212741e-15, 1.04989607e-14, 1.09566484e-16,
       2.73469767e-12, 5.00877382e-14], dtype=float32), 'pred': 3, 'box': Box(x=3.23, y=9.3, w=115.63, h=175.46), 'texts': ['scooter sitting unattended on the street']}
scooter sitting unattended on the street
predicate correct
  2%|████▍                                                                                                                                                                                                             | 107/5023 [01:47<1:20:03,  1.02it/s]This is the original CLIP result:
tensor([130.7500, 135.5000], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.00857748 0.9914225 ]
predicts:  1
The Final Result:  {'probs': array([0.00857748, 0.9914225 ], dtype=float32), 'pred': 1, 'box': Box(x=261.24, y=3.91, w=259.24, h=406.09), 'texts': ['a white cockatoo is scratching its head.']}
a white cockatoo is scratching its head.
predicate correct
This is the original CLIP result:
tensor([121.7500, 116.6250], device='cuda:0', dtype=torch.float16)
CLIP result after softmax:  [0.994089   0.00591107]
predicts:  0
The Final Result:  {'probs': array([0.994089  , 0.00591107], dtype=float32), 'pred': 0, 'box': Box(x=125.82, y=57.19, w=175.08, h=344.01), 'texts': ['the bird with its head turned to the side.']}
the bird with its head turned to the side.
  2%|████▌                                                                                                                                                                                                             | 108/5023 [01:47<1:04:22,  1.27it/s]This is the original CLIP result:
tensor([100.0625,  75.5625, 111.8750,  95.6250], device='cuda:0',
       dtype=torch.float16)
CLIP result after softmax:  [7.4112795e-06 1.6969864e-16 9.9999249e-01 8.7641823e-08]
predicts:  2
The Final Result:  {'probs': array([7.4112795e-06, 1.6969864e-16, 9.9999249e-01, 8.7641823e-08],
      dtype=float32), 'pred': 2, 'box': Box(x=440.29, y=255.71, w=102.47, h=224.29), 'texts': ['a girl with dark blue party dress']}
a girl with dark blue party dress
predicate correct
  2%|████▌                                                                                                                                                                                                             | 108/5023 [01:48<1:21:55,  1.00s/it]
Traceback (most recent call last):
  File "main.py", line 188, in <module>
    result = method.execute(sentence["raw"].lower(), env)
  File "/home/lhxiao/pcl_experiment_202203/reclip/methods/parse.py", line 69, in execute
    probs = env.filter(caption, area_threshold=self.box_area_threshold, softmax=True)
  File "/home/lhxiao/pcl_experiment_202203/reclip/interpreter.py", line 177, in filter
    result_partial = self.executor(caption, self.image, boxes, image_name=self.image_name)
  File "/home/lhxiao/pcl_experiment_202203/reclip/executor.py", line 339, in __call__
    result = super().__call__(caption, image, boxes, image_name)
  File "/home/lhxiao/anaconda3/envs/pytorch_clip/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/home/lhxiao/pcl_experiment_202203/reclip/executor.py", line 139, in __call__
    images, text_tensor = self.tensorize_inputs(caption, image, boxes, image_name)
  File "/home/lhxiao/pcl_experiment_202203/reclip/executor.py", line 103, in tensorize_inputs
    preprocessed_images = self.preprocess_image(blurred)
  File "/home/lhxiao/pcl_experiment_202203/reclip/executor.py", line 46, in preprocess_image
    return [preprocess(image) for preprocess in self.preprocesses]
  File "/home/lhxiao/pcl_experiment_202203/reclip/executor.py", line 46, in <listcomp>
    return [preprocess(image) for preprocess in self.preprocesses]
  File "/home/lhxiao/anaconda3/envs/pytorch_clip/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 61, in __call__
    img = t(img)
  File "/home/lhxiao/anaconda3/envs/pytorch_clip/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 98, in __call__
    return F.to_tensor(pic)
  File "/home/lhxiao/anaconda3/envs/pytorch_clip/lib/python3.8/site-packages/torchvision/transforms/functional.py", line 148, in to_tensor
    img = img.permute((2, 0, 1)).contiguous()
KeyboardInterrupt

